{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"BART_vanilla_350k_0526.ipynb","provenance":[{"file_id":"1QgRyM88awASlAPO7J792XCD_HRKcntPp","timestamp":1618321373337},{"file_id":"156la7XMlsDHf6JyALQ8a9bnBJpDKDu-7","timestamp":1618320594131},{"file_id":"106-WwsEeegU3XWb0rAvWS76hh2oqfZnz","timestamp":1618304894749},{"file_id":"1CMIjLRonRnkYlMzJTihBM4v7t-i6zNcm","timestamp":1618297597259},{"file_id":"1-cVulcdL5Bogd1DZCwJwwTlCDhZlcM60","timestamp":1615804628554}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c96b4389cbf64e158d9abae55f05ad77":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b7fb6c49258349c0a9bc5ca2b616a1a8","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_90a4d8aee76744fa89f68c69c8d5960c","IPY_MODEL_e2e1f7635aea480684f590e85eef2df5"]}},"b7fb6c49258349c0a9bc5ca2b616a1a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"90a4d8aee76744fa89f68c69c8d5960c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_93ce52d1a8b94dd089a1c95a420cd635","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":898823,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":898823,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4b587fd1f4e44078847a45687ad71751"}},"e2e1f7635aea480684f590e85eef2df5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_66ef2e48fb354f5e82e29495caa2e455","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 899k/899k [00:01&lt;00:00, 527kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b62b6c30852140ec8f36b1e701cb82d3"}},"93ce52d1a8b94dd089a1c95a420cd635":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4b587fd1f4e44078847a45687ad71751":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"66ef2e48fb354f5e82e29495caa2e455":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b62b6c30852140ec8f36b1e701cb82d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b1cbbc89ba374fc5bb0b0ec2953afedb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7e379a4a6ed341dbaf4ac0a9ed8071b2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0cbadc145fc246eeba298b79a9f91bf9","IPY_MODEL_53306b5f28824ec4b581e3bfe853d26e"]}},"7e379a4a6ed341dbaf4ac0a9ed8071b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0cbadc145fc246eeba298b79a9f91bf9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d4bb853ea4764dad8b507829969261d4","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8d9e1e2bd27c40e2adfaf178ca08e3d6"}},"53306b5f28824ec4b581e3bfe853d26e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_350bcb8ee1ea41c5ba754df4cb893310","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [00:04&lt;00:00, 96.5kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a0993fc0c1614148b32c411490b181e8"}},"d4bb853ea4764dad8b507829969261d4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8d9e1e2bd27c40e2adfaf178ca08e3d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"350bcb8ee1ea41c5ba754df4cb893310":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a0993fc0c1614148b32c411490b181e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d25111b79e2942b3a8c7cce831755c49":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f2dabd8c840443389d0079e16990be43","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3c505b4082814c7a96c459d2b253433e","IPY_MODEL_754f6ddca26842b5a20fa198100412e6"]}},"f2dabd8c840443389d0079e16990be43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3c505b4082814c7a96c459d2b253433e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c1493c73b0dd49b7b2c25c6621883d39","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1355863,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1355863,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_026a8a4d86334e8b8b378a25fce1f6fa"}},"754f6ddca26842b5a20fa198100412e6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1e2212d457e0456a892e7bf10c4e5f30","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.36M/1.36M [00:00&lt;00:00, 1.81MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_46ccb925b6b0464cb71580f4596dd735"}},"c1493c73b0dd49b7b2c25c6621883d39":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"026a8a4d86334e8b8b378a25fce1f6fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1e2212d457e0456a892e7bf10c4e5f30":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"46ccb925b6b0464cb71580f4596dd735":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"860a11fe47d348a08e6bed575c630e28":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d54f29430de843e7b7bf990d35d8a259","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4a926434aead4ec38488c472773b3080","IPY_MODEL_ea992c9b9056415882715564622965db"]}},"d54f29430de843e7b7bf990d35d8a259":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4a926434aead4ec38488c472773b3080":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9ed076a999b145c292ae830c95bb7e55","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1553,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1553,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f957a5cd129d4cfd90f33482a03f43ef"}},"ea992c9b9056415882715564622965db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c46933ee4b134663bfa58de78a265be7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.55k/1.55k [00:00&lt;00:00, 44.7kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8bb7ff5b7f814d75b0a66414f56eed28"}},"9ed076a999b145c292ae830c95bb7e55":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f957a5cd129d4cfd90f33482a03f43ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c46933ee4b134663bfa58de78a265be7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8bb7ff5b7f814d75b0a66414f56eed28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"88c09cf04f3c48b7aa49f73e64d0084d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_77b7b356a862469cadb1396239c27dff","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4c00395b1eb246fb9b0dbafa07c3cd2a","IPY_MODEL_6f7943ed008d4b7bab13b5683286a7e2"]}},"77b7b356a862469cadb1396239c27dff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4c00395b1eb246fb9b0dbafa07c3cd2a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_57a49f068dde496a928809260ad722ef","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":557941479,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":557941479,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9f4afc2b055149e9aca6b099bcabc06f"}},"6f7943ed008d4b7bab13b5683286a7e2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c2bfe493a7f54250a1f259170848e37f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 558M/558M [00:38&lt;00:00, 14.4MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_35e1cc9eb9674918aa5a42885e23cb13"}},"57a49f068dde496a928809260ad722ef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9f4afc2b055149e9aca6b099bcabc06f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c2bfe493a7f54250a1f259170848e37f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"35e1cc9eb9674918aa5a42885e23cb13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"dX60u8dY-bIi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622206417314,"user_tz":-60,"elapsed":27888,"user":{"displayName":"Keyue Jiang","photoUrl":"","userId":"10513797217442927849"}},"outputId":"36497b5d-1492-4a51-c9ee-54bf5f005393"},"source":["# Divine beast bless no bug here! \n","#         ┌─┐    ┌─┐\n","#      ┌─┘ ┴───┘ ┴──┐\n","#      │                   │\n","#      │       ───       │\n","#      │  ─┬┘     └┬─  │\n","#      │                   │\n","#      │       ─┴─       │\n","#      │                   │\n","#      └─┐         ┌───┘\n","#          │         │\n","#          │         │\n","#          │         │\n","#          │         └──────────────┐\n","#          │                                  │\n","#          │                                  ├─┐\n","#          │                                  ┌─┘\n","#          │                                  │\n","#          └─┐  ┐  ┌──────┬──┐  ┌──┘\n","#            │  ─┤ ─┤         │  ─┤ ─┤\n","#            └──┴──┘         └──┴──┘\n","\n","!pip install transformers\n","!pip install boto3\n","!git clone https://github.com/NVIDIA/apex\n","%cd apex\n","!pip install -v --no-cache-dir ./\n","%cd ..  \n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 4.9MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Collecting huggingface-hub==0.0.8\n","  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 24.0MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 33.2MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Installing collected packages: huggingface-hub, tokenizers, sacremoses, transformers\n","Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n","Collecting boto3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/fb/695bde21f34b6bd52db30278d6fdc63b9ce54b27d6ef3369444f621c98e2/boto3-1.17.83-py2.py3-none-any.whl (131kB)\n","\u001b[K     |████████████████████████████████| 133kB 5.3MB/s \n","\u001b[?25hCollecting s3transfer<0.5.0,>=0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n","\u001b[K     |████████████████████████████████| 81kB 5.0MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n","Collecting botocore<1.21.0,>=1.20.83\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cb/46/8a9db3126e2390cb0a551344a237b5bc5162478b04f56a96cbe1cac5d5a8/botocore-1.20.83-py2.py3-none-any.whl (7.6MB)\n","\u001b[K     |████████████████████████████████| 7.6MB 8.5MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.83->boto3) (2.8.1)\n","Collecting urllib3<1.27,>=1.25.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/cd/1e2ec680ec7b09846dc6e605f5a7709dfb9d7128e51a026e7154e18a234e/urllib3-1.26.5-py2.py3-none-any.whl (138kB)\n","\u001b[K     |████████████████████████████████| 143kB 39.9MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.83->boto3) (1.15.0)\n","\u001b[31mERROR: requests 2.23.0 has requirement urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you'll have urllib3 1.26.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","Installing collected packages: jmespath, urllib3, botocore, s3transfer, boto3\n","  Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed boto3-1.17.83 botocore-1.20.83 jmespath-0.10.0 s3transfer-0.4.2 urllib3-1.26.5\n","Cloning into 'apex'...\n","remote: Enumerating objects: 8048, done.\u001b[K\n","remote: Counting objects: 100% (135/135), done.\u001b[K\n","remote: Compressing objects: 100% (102/102), done.\u001b[K\n","remote: Total 8048 (delta 66), reused 65 (delta 28), pack-reused 7913\u001b[K\n","Receiving objects: 100% (8048/8048), 14.11 MiB | 13.68 MiB/s, done.\n","Resolving deltas: 100% (5467/5467), done.\n","/content/apex\n","Created temporary directory: /tmp/pip-ephem-wheel-cache-4mtk1t__\n","Created temporary directory: /tmp/pip-req-tracker-0w48gmt6\n","Created requirements tracker '/tmp/pip-req-tracker-0w48gmt6'\n","Created temporary directory: /tmp/pip-install-t8if_315\n","Processing /content/apex\n","  Created temporary directory: /tmp/pip-req-build-f2orl4qd\n","  Added file:///content/apex to build tracker '/tmp/pip-req-tracker-0w48gmt6'\n","    Running setup.py (path:/tmp/pip-req-build-f2orl4qd/setup.py) egg_info for package from file:///content/apex\n","    Running command python setup.py egg_info\n","\n","\n","    torch.__version__  = 1.8.1+cu101\n","\n","\n","    running egg_info\n","    creating /tmp/pip-req-build-f2orl4qd/pip-egg-info/apex.egg-info\n","    writing /tmp/pip-req-build-f2orl4qd/pip-egg-info/apex.egg-info/PKG-INFO\n","    writing dependency_links to /tmp/pip-req-build-f2orl4qd/pip-egg-info/apex.egg-info/dependency_links.txt\n","    writing top-level names to /tmp/pip-req-build-f2orl4qd/pip-egg-info/apex.egg-info/top_level.txt\n","    writing manifest file '/tmp/pip-req-build-f2orl4qd/pip-egg-info/apex.egg-info/SOURCES.txt'\n","    adding license file 'LICENSE' (matched pattern 'LICEN[CS]E*')\n","    writing manifest file '/tmp/pip-req-build-f2orl4qd/pip-egg-info/apex.egg-info/SOURCES.txt'\n","    /tmp/pip-req-build-f2orl4qd/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n","      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n","  Source in /tmp/pip-req-build-f2orl4qd has version 0.1, which satisfies requirement apex==0.1 from file:///content/apex\n","  Removed apex==0.1 from file:///content/apex from build tracker '/tmp/pip-req-tracker-0w48gmt6'\n","Building wheels for collected packages: apex\n","  Created temporary directory: /tmp/pip-wheel-27v5dyuk\n","  Building wheel for apex (setup.py) ... \u001b[?25l  Destination directory: /tmp/pip-wheel-27v5dyuk\n","  Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-f2orl4qd/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-f2orl4qd/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-27v5dyuk --python-tag cp37\n","\n","\n","  torch.__version__  = 1.8.1+cu101\n","\n","\n","  /tmp/pip-req-build-f2orl4qd/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n","    warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n","  running bdist_wheel\n","  running build\n","  running build_py\n","  creating build\n","  creating build/lib\n","  creating build/lib/apex\n","  copying apex/__init__.py -> build/lib/apex\n","  creating build/lib/apex/contrib\n","  copying apex/contrib/__init__.py -> build/lib/apex/contrib\n","  creating build/lib/apex/fp16_utils\n","  copying apex/fp16_utils/fp16_optimizer.py -> build/lib/apex/fp16_utils\n","  copying apex/fp16_utils/loss_scaler.py -> build/lib/apex/fp16_utils\n","  copying apex/fp16_utils/fp16util.py -> build/lib/apex/fp16_utils\n","  copying apex/fp16_utils/__init__.py -> build/lib/apex/fp16_utils\n","  creating build/lib/apex/amp\n","  copying apex/amp/_initialize.py -> build/lib/apex/amp\n","  copying apex/amp/wrap.py -> build/lib/apex/amp\n","  copying apex/amp/__version__.py -> build/lib/apex/amp\n","  copying apex/amp/amp.py -> build/lib/apex/amp\n","  copying apex/amp/_process_optimizer.py -> build/lib/apex/amp\n","  copying apex/amp/_amp_state.py -> build/lib/apex/amp\n","  copying apex/amp/handle.py -> build/lib/apex/amp\n","  copying apex/amp/utils.py -> build/lib/apex/amp\n","  copying apex/amp/opt.py -> build/lib/apex/amp\n","  copying apex/amp/__init__.py -> build/lib/apex/amp\n","  copying apex/amp/rnn_compat.py -> build/lib/apex/amp\n","  copying apex/amp/scaler.py -> build/lib/apex/amp\n","  copying apex/amp/frontend.py -> build/lib/apex/amp\n","  copying apex/amp/compat.py -> build/lib/apex/amp\n","  creating build/lib/apex/mlp\n","  copying apex/mlp/mlp.py -> build/lib/apex/mlp\n","  copying apex/mlp/__init__.py -> build/lib/apex/mlp\n","  creating build/lib/apex/optimizers\n","  copying apex/optimizers/fused_adam.py -> build/lib/apex/optimizers\n","  copying apex/optimizers/fused_sgd.py -> build/lib/apex/optimizers\n","  copying apex/optimizers/fused_adagrad.py -> build/lib/apex/optimizers\n","  copying apex/optimizers/__init__.py -> build/lib/apex/optimizers\n","  copying apex/optimizers/fused_novograd.py -> build/lib/apex/optimizers\n","  copying apex/optimizers/fused_lamb.py -> build/lib/apex/optimizers\n","  creating build/lib/apex/RNN\n","  copying apex/RNN/RNNBackend.py -> build/lib/apex/RNN\n","  copying apex/RNN/cells.py -> build/lib/apex/RNN\n","  copying apex/RNN/__init__.py -> build/lib/apex/RNN\n","  copying apex/RNN/models.py -> build/lib/apex/RNN\n","  creating build/lib/apex/parallel\n","  copying apex/parallel/multiproc.py -> build/lib/apex/parallel\n","  copying apex/parallel/optimized_sync_batchnorm.py -> build/lib/apex/parallel\n","  copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib/apex/parallel\n","  copying apex/parallel/__init__.py -> build/lib/apex/parallel\n","  copying apex/parallel/sync_batchnorm_kernel.py -> build/lib/apex/parallel\n","  copying apex/parallel/distributed.py -> build/lib/apex/parallel\n","  copying apex/parallel/LARC.py -> build/lib/apex/parallel\n","  copying apex/parallel/sync_batchnorm.py -> build/lib/apex/parallel\n","  creating build/lib/apex/normalization\n","  copying apex/normalization/fused_layer_norm.py -> build/lib/apex/normalization\n","  copying apex/normalization/__init__.py -> build/lib/apex/normalization\n","  creating build/lib/apex/multi_tensor_apply\n","  copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib/apex/multi_tensor_apply\n","  copying apex/multi_tensor_apply/__init__.py -> build/lib/apex/multi_tensor_apply\n","  creating build/lib/apex/pyprof\n","  copying apex/pyprof/__init__.py -> build/lib/apex/pyprof\n","  creating build/lib/apex/reparameterization\n","  copying apex/reparameterization/__init__.py -> build/lib/apex/reparameterization\n","  copying apex/reparameterization/reparameterization.py -> build/lib/apex/reparameterization\n","  copying apex/reparameterization/weight_norm.py -> build/lib/apex/reparameterization\n","  creating build/lib/apex/contrib/xentropy\n","  copying apex/contrib/xentropy/__init__.py -> build/lib/apex/contrib/xentropy\n","  copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib/apex/contrib/xentropy\n","  creating build/lib/apex/contrib/optimizers\n","  copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib/apex/contrib/optimizers\n","  copying apex/contrib/optimizers/fused_adam.py -> build/lib/apex/contrib/optimizers\n","  copying apex/contrib/optimizers/fused_sgd.py -> build/lib/apex/contrib/optimizers\n","  copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib/apex/contrib/optimizers\n","  copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib/apex/contrib/optimizers\n","  copying apex/contrib/optimizers/__init__.py -> build/lib/apex/contrib/optimizers\n","  copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib/apex/contrib/optimizers\n","  copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib/apex/contrib/optimizers\n","  copying apex/contrib/optimizers/fused_lamb.py -> build/lib/apex/contrib/optimizers\n","  creating build/lib/apex/contrib/sparsity\n","  copying apex/contrib/sparsity/sparse_masklib.py -> build/lib/apex/contrib/sparsity\n","  copying apex/contrib/sparsity/asp.py -> build/lib/apex/contrib/sparsity\n","  copying apex/contrib/sparsity/__init__.py -> build/lib/apex/contrib/sparsity\n","  creating build/lib/apex/contrib/groupbn\n","  copying apex/contrib/groupbn/__init__.py -> build/lib/apex/contrib/groupbn\n","  copying apex/contrib/groupbn/batch_norm.py -> build/lib/apex/contrib/groupbn\n","  creating build/lib/apex/contrib/fmha\n","  copying apex/contrib/fmha/fmha.py -> build/lib/apex/contrib/fmha\n","  copying apex/contrib/fmha/__init__.py -> build/lib/apex/contrib/fmha\n","  creating build/lib/apex/contrib/bottleneck\n","  copying apex/contrib/bottleneck/bottleneck.py -> build/lib/apex/contrib/bottleneck\n","  copying apex/contrib/bottleneck/__init__.py -> build/lib/apex/contrib/bottleneck\n","  copying apex/contrib/bottleneck/test.py -> build/lib/apex/contrib/bottleneck\n","  creating build/lib/apex/contrib/layer_norm\n","  copying apex/contrib/layer_norm/layer_norm.py -> build/lib/apex/contrib/layer_norm\n","  copying apex/contrib/layer_norm/__init__.py -> build/lib/apex/contrib/layer_norm\n","  creating build/lib/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/__init__.py -> build/lib/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib/apex/contrib/multihead_attn\n","  creating build/lib/apex/contrib/transducer\n","  copying apex/contrib/transducer/__init__.py -> build/lib/apex/contrib/transducer\n","  copying apex/contrib/transducer/transducer.py -> build/lib/apex/contrib/transducer\n","  creating build/lib/apex/amp/lists\n","  copying apex/amp/lists/tensor_overrides.py -> build/lib/apex/amp/lists\n","  copying apex/amp/lists/__init__.py -> build/lib/apex/amp/lists\n","  copying apex/amp/lists/functional_overrides.py -> build/lib/apex/amp/lists\n","  copying apex/amp/lists/torch_overrides.py -> build/lib/apex/amp/lists\n","  creating build/lib/apex/pyprof/nvtx\n","  copying apex/pyprof/nvtx/__init__.py -> build/lib/apex/pyprof/nvtx\n","  copying apex/pyprof/nvtx/nvmarker.py -> build/lib/apex/pyprof/nvtx\n","  creating build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/loss.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/dropout.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/softmax.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/usage.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/output.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/conv.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/__main__.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/base.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/utility.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/embedding.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/recurrentCell.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/prof.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/pointwise.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/reduction.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/activation.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/__init__.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/pooling.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/normalization.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/misc.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/linear.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/randomSample.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/data.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/convert.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/blas.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/optim.py -> build/lib/apex/pyprof/prof\n","  creating build/lib/apex/pyprof/parse\n","  copying apex/pyprof/parse/db.py -> build/lib/apex/pyprof/parse\n","  copying apex/pyprof/parse/kernel.py -> build/lib/apex/pyprof/parse\n","  copying apex/pyprof/parse/nvvp.py -> build/lib/apex/pyprof/parse\n","  copying apex/pyprof/parse/__main__.py -> build/lib/apex/pyprof/parse\n","  copying apex/pyprof/parse/__init__.py -> build/lib/apex/pyprof/parse\n","  copying apex/pyprof/parse/parse.py -> build/lib/apex/pyprof/parse\n","  installing to build/bdist.linux-x86_64/wheel\n","  running install\n","  running install_lib\n","  creating build/bdist.linux-x86_64\n","  creating build/bdist.linux-x86_64/wheel\n","  creating build/bdist.linux-x86_64/wheel/apex\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n","  copying build/lib/apex/contrib/xentropy/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n","  copying build/lib/apex/contrib/xentropy/softmax_xentropy.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib/apex/contrib/optimizers/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib/apex/contrib/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib/apex/contrib/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib/apex/contrib/optimizers/distributed_fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib/apex/contrib/optimizers/distributed_fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib/apex/contrib/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib/apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib/apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib/apex/contrib/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n","  copying build/lib/apex/contrib/sparsity/sparse_masklib.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n","  copying build/lib/apex/contrib/sparsity/asp.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n","  copying build/lib/apex/contrib/sparsity/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n","  copying build/lib/apex/contrib/groupbn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n","  copying build/lib/apex/contrib/groupbn/batch_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n","  copying build/lib/apex/contrib/fmha/fmha.py -> build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n","  copying build/lib/apex/contrib/fmha/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n","  copying build/lib/apex/contrib/bottleneck/bottleneck.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n","  copying build/lib/apex/contrib/bottleneck/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n","  copying build/lib/apex/contrib/bottleneck/test.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n","  copying build/lib/apex/contrib/layer_norm/layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n","  copying build/lib/apex/contrib/layer_norm/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n","  copying build/lib/apex/contrib/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib/apex/contrib/multihead_attn/self_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib/apex/contrib/multihead_attn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib/apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n","  copying build/lib/apex/contrib/transducer/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n","  copying build/lib/apex/contrib/transducer/transducer.py -> build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n","  creating build/bdist.linux-x86_64/wheel/apex/fp16_utils\n","  copying build/lib/apex/fp16_utils/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n","  copying build/lib/apex/fp16_utils/loss_scaler.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n","  copying build/lib/apex/fp16_utils/fp16util.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n","  copying build/lib/apex/fp16_utils/__init__.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n","  creating build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib/apex/amp/_initialize.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib/apex/amp/wrap.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib/apex/amp/__version__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib/apex/amp/amp.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib/apex/amp/_process_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib/apex/amp/_amp_state.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib/apex/amp/handle.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib/apex/amp/utils.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib/apex/amp/opt.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib/apex/amp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib/apex/amp/rnn_compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib/apex/amp/scaler.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  creating build/bdist.linux-x86_64/wheel/apex/amp/lists\n","  copying build/lib/apex/amp/lists/tensor_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n","  copying build/lib/apex/amp/lists/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n","  copying build/lib/apex/amp/lists/functional_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n","  copying build/lib/apex/amp/lists/torch_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n","  copying build/lib/apex/amp/frontend.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib/apex/amp/compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  creating build/bdist.linux-x86_64/wheel/apex/mlp\n","  copying build/lib/apex/mlp/mlp.py -> build/bdist.linux-x86_64/wheel/apex/mlp\n","  copying build/lib/apex/mlp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/mlp\n","  creating build/bdist.linux-x86_64/wheel/apex/optimizers\n","  copying build/lib/apex/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n","  copying build/lib/apex/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n","  copying build/lib/apex/optimizers/fused_adagrad.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n","  copying build/lib/apex/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n","  copying build/lib/apex/optimizers/fused_novograd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n","  copying build/lib/apex/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n","  creating build/bdist.linux-x86_64/wheel/apex/RNN\n","  copying build/lib/apex/RNN/RNNBackend.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n","  copying build/lib/apex/RNN/cells.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n","  copying build/lib/apex/RNN/__init__.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n","  copying build/lib/apex/RNN/models.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n","  creating build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib/apex/parallel/multiproc.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib/apex/parallel/optimized_sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib/apex/parallel/optimized_sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib/apex/parallel/__init__.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib/apex/parallel/sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib/apex/parallel/distributed.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib/apex/parallel/LARC.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib/apex/parallel/sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib/apex/__init__.py -> build/bdist.linux-x86_64/wheel/apex\n","  creating build/bdist.linux-x86_64/wheel/apex/normalization\n","  copying build/lib/apex/normalization/fused_layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n","  copying build/lib/apex/normalization/__init__.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n","  creating build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n","  copying build/lib/apex/multi_tensor_apply/multi_tensor_apply.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n","  copying build/lib/apex/multi_tensor_apply/__init__.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n","  creating build/bdist.linux-x86_64/wheel/apex/pyprof\n","  creating build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n","  copying build/lib/apex/pyprof/nvtx/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n","  copying build/lib/apex/pyprof/nvtx/nvmarker.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n","  creating build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/loss.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/dropout.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/softmax.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/usage.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/index_slice_join_mutate.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/output.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/conv.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/__main__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/base.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/utility.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/embedding.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/recurrentCell.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/prof.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/pointwise.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/reduction.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/activation.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/pooling.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/normalization.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/misc.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/linear.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/randomSample.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/data.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/convert.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/blas.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/optim.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  creating build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n","  copying build/lib/apex/pyprof/parse/db.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n","  copying build/lib/apex/pyprof/parse/kernel.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n","  copying build/lib/apex/pyprof/parse/nvvp.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n","  copying build/lib/apex/pyprof/parse/__main__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n","  copying build/lib/apex/pyprof/parse/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n","  copying build/lib/apex/pyprof/parse/parse.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n","  copying build/lib/apex/pyprof/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof\n","  creating build/bdist.linux-x86_64/wheel/apex/reparameterization\n","  copying build/lib/apex/reparameterization/__init__.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n","  copying build/lib/apex/reparameterization/reparameterization.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n","  copying build/lib/apex/reparameterization/weight_norm.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n","  running install_egg_info\n","  running egg_info\n","  creating apex.egg-info\n","  writing apex.egg-info/PKG-INFO\n","  writing dependency_links to apex.egg-info/dependency_links.txt\n","  writing top-level names to apex.egg-info/top_level.txt\n","  writing manifest file 'apex.egg-info/SOURCES.txt'\n","  adding license file 'LICENSE' (matched pattern 'LICEN[CS]E*')\n","  writing manifest file 'apex.egg-info/SOURCES.txt'\n","  Copying apex.egg-info to build/bdist.linux-x86_64/wheel/apex-0.1-py3.7.egg-info\n","  running install_scripts\n","  adding license file \"LICENSE\" (matched pattern \"LICEN[CS]E*\")\n","  creating build/bdist.linux-x86_64/wheel/apex-0.1.dist-info/WHEEL\n","  creating '/tmp/pip-wheel-27v5dyuk/apex-0.1-cp37-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n","  adding 'apex/__init__.py'\n","  adding 'apex/RNN/RNNBackend.py'\n","  adding 'apex/RNN/__init__.py'\n","  adding 'apex/RNN/cells.py'\n","  adding 'apex/RNN/models.py'\n","  adding 'apex/amp/__init__.py'\n","  adding 'apex/amp/__version__.py'\n","  adding 'apex/amp/_amp_state.py'\n","  adding 'apex/amp/_initialize.py'\n","  adding 'apex/amp/_process_optimizer.py'\n","  adding 'apex/amp/amp.py'\n","  adding 'apex/amp/compat.py'\n","  adding 'apex/amp/frontend.py'\n","  adding 'apex/amp/handle.py'\n","  adding 'apex/amp/opt.py'\n","  adding 'apex/amp/rnn_compat.py'\n","  adding 'apex/amp/scaler.py'\n","  adding 'apex/amp/utils.py'\n","  adding 'apex/amp/wrap.py'\n","  adding 'apex/amp/lists/__init__.py'\n","  adding 'apex/amp/lists/functional_overrides.py'\n","  adding 'apex/amp/lists/tensor_overrides.py'\n","  adding 'apex/amp/lists/torch_overrides.py'\n","  adding 'apex/contrib/__init__.py'\n","  adding 'apex/contrib/bottleneck/__init__.py'\n","  adding 'apex/contrib/bottleneck/bottleneck.py'\n","  adding 'apex/contrib/bottleneck/test.py'\n","  adding 'apex/contrib/fmha/__init__.py'\n","  adding 'apex/contrib/fmha/fmha.py'\n","  adding 'apex/contrib/groupbn/__init__.py'\n","  adding 'apex/contrib/groupbn/batch_norm.py'\n","  adding 'apex/contrib/layer_norm/__init__.py'\n","  adding 'apex/contrib/layer_norm/layer_norm.py'\n","  adding 'apex/contrib/multihead_attn/__init__.py'\n","  adding 'apex/contrib/multihead_attn/encdec_multihead_attn.py'\n","  adding 'apex/contrib/multihead_attn/encdec_multihead_attn_func.py'\n","  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py'\n","  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py'\n","  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_func.py'\n","  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py'\n","  adding 'apex/contrib/multihead_attn/mask_softmax_dropout_func.py'\n","  adding 'apex/contrib/multihead_attn/self_multihead_attn.py'\n","  adding 'apex/contrib/multihead_attn/self_multihead_attn_func.py'\n","  adding 'apex/contrib/optimizers/__init__.py'\n","  adding 'apex/contrib/optimizers/distributed_fused_adam.py'\n","  adding 'apex/contrib/optimizers/distributed_fused_adam_v2.py'\n","  adding 'apex/contrib/optimizers/distributed_fused_adam_v3.py'\n","  adding 'apex/contrib/optimizers/distributed_fused_lamb.py'\n","  adding 'apex/contrib/optimizers/fp16_optimizer.py'\n","  adding 'apex/contrib/optimizers/fused_adam.py'\n","  adding 'apex/contrib/optimizers/fused_lamb.py'\n","  adding 'apex/contrib/optimizers/fused_sgd.py'\n","  adding 'apex/contrib/sparsity/__init__.py'\n","  adding 'apex/contrib/sparsity/asp.py'\n","  adding 'apex/contrib/sparsity/sparse_masklib.py'\n","  adding 'apex/contrib/transducer/__init__.py'\n","  adding 'apex/contrib/transducer/transducer.py'\n","  adding 'apex/contrib/xentropy/__init__.py'\n","  adding 'apex/contrib/xentropy/softmax_xentropy.py'\n","  adding 'apex/fp16_utils/__init__.py'\n","  adding 'apex/fp16_utils/fp16_optimizer.py'\n","  adding 'apex/fp16_utils/fp16util.py'\n","  adding 'apex/fp16_utils/loss_scaler.py'\n","  adding 'apex/mlp/__init__.py'\n","  adding 'apex/mlp/mlp.py'\n","  adding 'apex/multi_tensor_apply/__init__.py'\n","  adding 'apex/multi_tensor_apply/multi_tensor_apply.py'\n","  adding 'apex/normalization/__init__.py'\n","  adding 'apex/normalization/fused_layer_norm.py'\n","  adding 'apex/optimizers/__init__.py'\n","  adding 'apex/optimizers/fused_adagrad.py'\n","  adding 'apex/optimizers/fused_adam.py'\n","  adding 'apex/optimizers/fused_lamb.py'\n","  adding 'apex/optimizers/fused_novograd.py'\n","  adding 'apex/optimizers/fused_sgd.py'\n","  adding 'apex/parallel/LARC.py'\n","  adding 'apex/parallel/__init__.py'\n","  adding 'apex/parallel/distributed.py'\n","  adding 'apex/parallel/multiproc.py'\n","  adding 'apex/parallel/optimized_sync_batchnorm.py'\n","  adding 'apex/parallel/optimized_sync_batchnorm_kernel.py'\n","  adding 'apex/parallel/sync_batchnorm.py'\n","  adding 'apex/parallel/sync_batchnorm_kernel.py'\n","  adding 'apex/pyprof/__init__.py'\n","  adding 'apex/pyprof/nvtx/__init__.py'\n","  adding 'apex/pyprof/nvtx/nvmarker.py'\n","  adding 'apex/pyprof/parse/__init__.py'\n","  adding 'apex/pyprof/parse/__main__.py'\n","  adding 'apex/pyprof/parse/db.py'\n","  adding 'apex/pyprof/parse/kernel.py'\n","  adding 'apex/pyprof/parse/nvvp.py'\n","  adding 'apex/pyprof/parse/parse.py'\n","  adding 'apex/pyprof/prof/__init__.py'\n","  adding 'apex/pyprof/prof/__main__.py'\n","  adding 'apex/pyprof/prof/activation.py'\n","  adding 'apex/pyprof/prof/base.py'\n","  adding 'apex/pyprof/prof/blas.py'\n","  adding 'apex/pyprof/prof/conv.py'\n","  adding 'apex/pyprof/prof/convert.py'\n","  adding 'apex/pyprof/prof/data.py'\n","  adding 'apex/pyprof/prof/dropout.py'\n","  adding 'apex/pyprof/prof/embedding.py'\n","  adding 'apex/pyprof/prof/index_slice_join_mutate.py'\n","  adding 'apex/pyprof/prof/linear.py'\n","  adding 'apex/pyprof/prof/loss.py'\n","  adding 'apex/pyprof/prof/misc.py'\n","  adding 'apex/pyprof/prof/normalization.py'\n","  adding 'apex/pyprof/prof/optim.py'\n","  adding 'apex/pyprof/prof/output.py'\n","  adding 'apex/pyprof/prof/pointwise.py'\n","  adding 'apex/pyprof/prof/pooling.py'\n","  adding 'apex/pyprof/prof/prof.py'\n","  adding 'apex/pyprof/prof/randomSample.py'\n","  adding 'apex/pyprof/prof/recurrentCell.py'\n","  adding 'apex/pyprof/prof/reduction.py'\n","  adding 'apex/pyprof/prof/softmax.py'\n","  adding 'apex/pyprof/prof/usage.py'\n","  adding 'apex/pyprof/prof/utility.py'\n","  adding 'apex/reparameterization/__init__.py'\n","  adding 'apex/reparameterization/reparameterization.py'\n","  adding 'apex/reparameterization/weight_norm.py'\n","  adding 'apex-0.1.dist-info/LICENSE'\n","  adding 'apex-0.1.dist-info/METADATA'\n","  adding 'apex-0.1.dist-info/WHEEL'\n","  adding 'apex-0.1.dist-info/top_level.txt'\n","  adding 'apex-0.1.dist-info/RECORD'\n","  removing build/bdist.linux-x86_64/wheel\n","\u001b[?25hdone\n","  Created wheel for apex: filename=apex-0.1-cp37-none-any.whl size=204691 sha256=190f52d1557272679f555d5e9d52d3f26936b17c1add4438b7c9a1511fcb3ea5\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-4mtk1t__/wheels/b1/3a/aa/d84906eaab780ae580c7a5686a33bf2820d8590ac3b60d5967\n","  Removing source in /tmp/pip-req-build-f2orl4qd\n","Successfully built apex\n","Installing collected packages: apex\n","\n","Successfully installed apex-0.1\n","Cleaning up...\n","Removed build tracker '/tmp/pip-req-tracker-0w48gmt6'\n","/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dsmxZM0-x7fF","executionInfo":{"status":"ok","timestamp":1622099135340,"user_tz":-60,"elapsed":15160,"user":{"displayName":"Keyue Jiang","photoUrl":"","userId":"10513797217442927849"}},"outputId":"2456ad2a-dbc7-4bdb-b111-679478366795"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vGx7BB_dqPbS"},"source":["# %%writefile setup.sh\n","# export CUDA_HOME=/usr/local/cuda-10.1\n","# git clone https://github.com/NVIDIA/apex\n","# pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vcaz1gMYbmt1"},"source":["# !sh setup.sh"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j3gLMKblgV2b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622206420144,"user_tz":-60,"elapsed":2834,"user":{"displayName":"Keyue Jiang","photoUrl":"","userId":"10513797217442927849"}},"outputId":"7d91fe88-4961-4774-fd46-9b74d7765482"},"source":["# data preprocessing\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import re\n","import numpy as np\n","import json\n","import h5py\n","\n","# control\n","import argparse\n","import logging\n","from tqdm import trange\n","\n","# pytorch\n","import torch\n","print(torch.__version__)\n","import torch.nn.functional as F\n","\n","# transformers\n","from transformers import GPT2Config\n","from transformers import AutoTokenizer, AutoModelWithLMHead\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","from transformers import BartForCausalLM, BartTokenizer,BartConfig"],"execution_count":2,"outputs":[{"output_type":"stream","text":["1.8.1+cu101\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.5) or chardet (3.0.4) doesn't match a supported version!\n","  RequestsDependencyWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"dr3GLmeRgslI"},"source":["# the original dataframe\n","df_ori = pd.read_csv(\"./gdrive/MyDrive/COMP0087/full_dataset.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wajqYvcFedhK"},"source":["np.random.seed(10)\n","train_len = 600000\n","test_len = 200\n","subset_idx = np.random.choice(range(len(df_ori)),train_len+test_len,replace=False)\n","train_idx = subset_idx[0:train_len]\n","test_idx = subset_idx[train_len:]\n","df = df_ori.loc[subset_idx ,:]\n","# df_test = df_ori.loc[subset_idx[-100:],:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BxIQiIoQobMb"},"source":["# data preprocessing\n","remove1 = df.loc[df.title.map(lambda x: len(x)<4 )]\n","remove2 = df.loc[df.ingredients.map(lambda x: len(x)<2)]\n","remove3 = df.loc[df.directions.map(lambda x: len(x) < 2 or len(''.join(x)) < 30)]\n","remove4 = df.loc[df.directions.map(lambda x: re.search('(step|mix all)', ''.join(str(x)), re.IGNORECASE)!=None)]\n","len(remove3)+len(remove2)+len(remove1)+len(remove4)\n","df.drop(df[df.title.map(lambda x: len(x)<4)].index, inplace=True)\n","df.drop(df[df.ingredients.map(lambda x: len(x)<2)].index, inplace=True)\n","df.drop(df[df.directions.map(lambda x: len(x) < 2 or len(''.join(x)) < 30)].index, inplace=True)\n","df.drop(df[df.directions.map(lambda x: re.search('(step|mix all)', ''.join(str(x)), re.IGNORECASE)!=None)].index, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vogi-NsDgd1z"},"source":["df.drop(df[df.title.map(lambda x: len(x)<4)].index, inplace=True)\n","df.drop(df[df.ingredients.map(lambda x: len(x)<2)].index, inplace=True)\n","df.drop(df[df.directions.map(lambda x: len(x) < 2 or len(''.join(x)) < 30)].index, inplace=True)\n","df.drop(df[df.directions.map(lambda x: re.search('(step|mix all)', ''.join(str(x)), re.IGNORECASE)!=None)].index, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2h0MbRQken9a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622099246239,"user_tz":-60,"elapsed":21,"user":{"displayName":"Keyue Jiang","photoUrl":"","userId":"10513797217442927849"}},"outputId":"9166498c-b655-4be7-97f2-1b51a02f801e"},"source":["len(df)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["565090"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"tyIpD-Apgh7s"},"source":["df.reset_index(inplace=True)\n","train, test = train_test_split(df, test_size=0.05) #use 5% for test set\n","# we only want first 10000 and 100 for train/test\n","# this has an error: train[75400:75600]\n","# train = train[50000:400000]\n","test = test[0:100]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vuytage9gjzH"},"source":["train_size = 500000\n","test_size = 100\n","\n","def df_to_plaintext_file(input_df, output_file, train = True):\n","    print(\"Writing to\", output_file)\n","    count = 0\n","    with open(output_file, 'w') as f:\n","        for index, row in input_df.iterrows():\n","            if index%100000==0:\n","                print(index)\n","            if type(row.NER)!=str:\n","                continue\n","            title = row.title\n","            directions = json.loads(row.directions)\n","            if len(directions) <= 1 and train:\n","              continue\n","            # print(len(directions))\n","            ingredients = json.loads(row.ingredients)\n","            ner = json.loads(row.NER)\n","            res = \"<RECIPE_START> <INPUT_START> \" + \" <NEXT_INPUT> \".join(ner) + \" <INPUT_END> <INGR_START> \" + \\\n","              \" <NEXT_INGR> \".join(ingredients) + \" <INGR_END> <INSTR_START> \" + \\\n","              \" <NEXT_INSTR> \".join(directions) + \" <INSTR_END> <TITLE_START> \" + title + \" <TITLE_END> <RECIPE_END>\"\n","            f.write(\"{}\\n\".format(res))\n","\n","            count += 1\n","            if count == train_size and train:\n","              print(\"training sample enough:\",train_size)\n","              break\n","            if count == test_size and not train:\n","              print(\"testing sample enough\",test_size)\n","              break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1mpW4paENyVv","executionInfo":{"status":"ok","timestamp":1622099312961,"user_tz":-60,"elapsed":66349,"user":{"displayName":"Keyue Jiang","photoUrl":"","userId":"10513797217442927849"}},"outputId":"78898f37-e617-4aa1-89f9-066897f5a5cc"},"source":["df_to_plaintext_file(train, 'unsupervised_train.txt')\n","df_to_plaintext_file(test, 'unsupervised_test.txt',train = False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Writing to unsupervised_train.txt\n","400000\n","0\n","200000\n","300000\n","100000\n","500000\n","Writing to unsupervised_test.txt\n","testing sample enough 100\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zzINFGF4JnrG"},"source":["#from transformers import GPT2Tokenizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4_KK9iNaCVTn","executionInfo":{"status":"ok","timestamp":1622206435677,"user_tz":-60,"elapsed":1163,"user":{"displayName":"Keyue Jiang","photoUrl":"","userId":"10513797217442927849"}},"outputId":"8fd563fd-d665-40bf-d269-228c9d967c93"},"source":["tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n","tokenizer.encode(['butter'])"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0, 3, 2]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"4UORyE8CCeuN","executionInfo":{"status":"ok","timestamp":1622206459356,"user_tz":-60,"elapsed":132,"user":{"displayName":"Keyue Jiang","photoUrl":"","userId":"10513797217442927849"}},"outputId":"a202f8fb-c9ff-4551-e8d5-2de546baa49f"},"source":["tokenizer.decode([3])"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'<unk>'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["c96b4389cbf64e158d9abae55f05ad77","b7fb6c49258349c0a9bc5ca2b616a1a8","90a4d8aee76744fa89f68c69c8d5960c","e2e1f7635aea480684f590e85eef2df5","93ce52d1a8b94dd089a1c95a420cd635","4b587fd1f4e44078847a45687ad71751","66ef2e48fb354f5e82e29495caa2e455","b62b6c30852140ec8f36b1e701cb82d3","b1cbbc89ba374fc5bb0b0ec2953afedb","7e379a4a6ed341dbaf4ac0a9ed8071b2","0cbadc145fc246eeba298b79a9f91bf9","53306b5f28824ec4b581e3bfe853d26e","d4bb853ea4764dad8b507829969261d4","8d9e1e2bd27c40e2adfaf178ca08e3d6","350bcb8ee1ea41c5ba754df4cb893310","a0993fc0c1614148b32c411490b181e8","d25111b79e2942b3a8c7cce831755c49","f2dabd8c840443389d0079e16990be43","3c505b4082814c7a96c459d2b253433e","754f6ddca26842b5a20fa198100412e6","c1493c73b0dd49b7b2c25c6621883d39","026a8a4d86334e8b8b378a25fce1f6fa","1e2212d457e0456a892e7bf10c4e5f30","46ccb925b6b0464cb71580f4596dd735"]},"id":"4wqzp-seoHsw","executionInfo":{"status":"ok","timestamp":1622100141407,"user_tz":-60,"elapsed":828451,"user":{"displayName":"Keyue Jiang","photoUrl":"","userId":"10513797217442927849"}},"outputId":"15f28437-022c-4d2d-afd9-070164cd395c"},"source":["tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n","# tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","special_tokens = {\n","    \"additional_special_tokens\": [\n","        \"<TITLE_START>\",\n","        \"<TITLE_END>\",\n","        \"<INSTR_START>\",\n","        \"<NEXT_INSTR>\",\n","        \"<INSTR_END>\",\n","        \"<INGR_START>\",\n","        \"<NEXT_INGR>\",\n","        \"<INGR_END>\",\n","        \"<RECIPE_START>\",\n","        \"<RECIPE_END>\",\n","        \"<INPUT_START>\",\n","        \"<INPUT_END>\",\n","        \"<NEXT_INPUT>\"\n","    ]\n","}\n","\n","tokenizer.add_special_tokens(special_tokens)\n","\n","end_token_id = tokenizer.convert_tokens_to_ids([\"<RECIPE_END>\"])[0]\n","\n","hf = h5py.File(\"unsupervised.h5\", \"w\")\n","for filename in [\"test\", \"train\"]:\n","    out_np = []\n","    data = open(\"unsupervised_\"+filename+\".txt\", \"r\")\n","    num = 0\n","    rows = 0\n","    last=[]\n","    for line in data:\n","        num+=1\n","        if num%10000 == 0:\n","            print(\"Read \"+str(num)+\" Written: \"+str(rows))\n","        # print(line)\n","        text_tokens = tokenizer(line)['input_ids']\n","        # print(text_tokens[0:5])\n","        if len(text_tokens) > 1024: #Recipe won't fit the model\n","            continue\n","\n","        # text_tokens_ids = tokenizer.convert_tokens_to_ids(text_tokens)\n","        text_tokens_ids = text_tokens\n","        # print(text_tokens_ids[0:5])\n","\n","        if (len(last) + len(text_tokens_ids)) <= 1024:\n","            last+=text_tokens_ids\n","        else:\n","            while len(last) < 1024:\n","                last.append(end_token_id)\n","            out_np.append(last)\n","            last=text_tokens_ids\n","            rows+=1\n","    out_mat = np.matrix(out_np)\n","    print(out_mat.shape)\n","    # print(out_mat)\n","    hf.create_dataset(filename, data=out_mat)\n","hf.close()\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c96b4389cbf64e158d9abae55f05ad77","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b1cbbc89ba374fc5bb0b0ec2953afedb","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d25111b79e2942b3a8c7cce831755c49","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355863.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1227 > 1024). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["(27, 1024)\n","Read 10000 Written: 2774\n","Read 20000 Written: 5518\n","Read 30000 Written: 8253\n","Read 40000 Written: 10998\n","Read 50000 Written: 13768\n","Read 60000 Written: 16513\n","Read 70000 Written: 19301\n","Read 80000 Written: 22004\n","Read 90000 Written: 24756\n","Read 100000 Written: 27493\n","Read 110000 Written: 30207\n","Read 120000 Written: 32948\n","Read 130000 Written: 35729\n","Read 140000 Written: 38480\n","Read 150000 Written: 41245\n","Read 160000 Written: 43974\n","Read 170000 Written: 46710\n","Read 180000 Written: 49465\n","Read 190000 Written: 52195\n","Read 200000 Written: 54996\n","Read 210000 Written: 57762\n","Read 220000 Written: 60519\n","Read 230000 Written: 63234\n","Read 240000 Written: 65972\n","Read 250000 Written: 68724\n","Read 260000 Written: 71499\n","Read 270000 Written: 74180\n","Read 280000 Written: 76929\n","Read 290000 Written: 79653\n","Read 300000 Written: 82397\n","Read 310000 Written: 85136\n","Read 320000 Written: 87877\n","Read 330000 Written: 90617\n","Read 340000 Written: 93362\n","Read 350000 Written: 96038\n","Read 360000 Written: 98768\n","Read 370000 Written: 101502\n","Read 380000 Written: 104241\n","Read 390000 Written: 107012\n","Read 400000 Written: 109770\n","Read 410000 Written: 112482\n","Read 420000 Written: 115247\n","Read 430000 Written: 118007\n","Read 440000 Written: 120805\n","Read 450000 Written: 123550\n","Read 460000 Written: 126332\n","Read 470000 Written: 129114\n","Read 480000 Written: 131813\n","Read 490000 Written: 134543\n","Read 500000 Written: 137235\n","(138140, 1024)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HdAk4Kh1McgZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622206545007,"user_tz":-60,"elapsed":140,"user":{"displayName":"Keyue Jiang","photoUrl":"","userId":"10513797217442927849"}},"outputId":"bbfb6c3b-5378-4e30-bb02-de8df95fde66"},"source":["tokenizer"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PreTrainedTokenizer(name_or_path='facebook/bart-base', vocab_size=50265, model_max_len=1024, is_fast=False, padding_side='right', special_tokens={'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'sep_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'cls_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True)})"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"L9ZBTWh6hKqa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622206734868,"user_tz":-60,"elapsed":147,"user":{"displayName":"Keyue Jiang","photoUrl":"","userId":"10513797217442927849"}},"outputId":"a3210fd2-d288-43c6-aeb2-87f8b4dc9041"},"source":["toke_result = tokenizer(\"water,butter\")\n","toke_result"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [0, 5412, 6, 4297, 1334, 2], 'attention_mask': [1, 1, 1, 1, 1, 1]}"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4_NCvjEiCuxI","executionInfo":{"status":"ok","timestamp":1622206735855,"user_tz":-60,"elapsed":4,"user":{"displayName":"Keyue Jiang","photoUrl":"","userId":"10513797217442927849"}},"outputId":"fb351df4-98fe-417b-eefa-fa588586c05a"},"source":["print(tokenizer.decode([4297]), tokenizer.decode([1334]))\n","print(tokenizer.decode([4297,1334]))"],"execution_count":29,"outputs":[{"output_type":"stream","text":["but ter\n","butter\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3nNMjzxKhx8R","colab":{"base_uri":"https://localhost:8080/","height":311},"executionInfo":{"status":"error","timestamp":1622206521204,"user_tz":-60,"elapsed":227,"user":{"displayName":"Keyue Jiang","photoUrl":"","userId":"10513797217442927849"}},"outputId":"fcb29229-9910-4a2d-816b-e3aa14674ca7"},"source":["tokenizer.decode([50274])"],"execution_count":8,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-e9edb24d2a0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50274\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3087\u001b[0m             \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3088\u001b[0m             \u001b[0mclean_up_tokenization_spaces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclean_up_tokenization_spaces\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3089\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3090\u001b[0m         )\n\u001b[1;32m   3091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, spaces_between_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    759\u001b[0m                 \u001b[0mcurrent_sub_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcurrent_sub_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0msub_texts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_sub_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mspaces_between_special_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/tokenization_gpt2.py\u001b[0m in \u001b[0;36mconvert_tokens_to_string\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert_tokens_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;34m\"\"\"Converts a sequence of tokens (string) in a single string.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyte_decoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, NoneType found"]}]},{"cell_type":"code","metadata":{"id":"IMvXzbLcIIC-"},"source":["#raw_text = 'tomato,egg'\n","#prepared_input = ' <RECIPE_START> <INPUT_START> ' + raw_text.replace(',', ' <NEXT_INPUT> ').replace(';', ' <INPUT_END>')\n","# tokenizer.encode(prepared_input)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lnVQ59V4FdiF"},"source":["# fine-tune with BART"]},{"cell_type":"code","metadata":{"id":"Kz7e2PoybaiE"},"source":["# fine-tuning model with bart\n","# logging info\n","import logging\n","logger = logging.getLogger(__name__)\n","\n","import glob\n","import logging\n","import random\n","import gc\n","import boto3\n","import shutil"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D5MKxGg8bhj4"},"source":["import torch\n","from torch.utils.data import DataLoader, Dataset, SequentialSampler, RandomSampler\n","from torch.utils.data.distributed import DistributedSampler\n","from torch.utils.tensorboard import SummaryWriter\n","from tqdm import tqdm, trange\n","import logging\n","import math\n","import os\n","from dataclasses import dataclass, field\n","from typing import Optional\n","from torch.utils.data import Dataset\n","import h5py\n","import torch\n","\n","from transformers import WEIGHTS_NAME, AdamW, get_linear_schedule_with_warmup\n","from transformers import BartForCausalLM, BartTokenizer,BartConfig,BartForConditionalGeneration"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dm4SBl8hbqj3"},"source":["# data loading\n","class TextDataset(Dataset):\n","    def __init__(self, tokenizer, file_path='train', block_size=512):\n","        cached_features_file = \"unsupervised.h5\"\n","\n","        logger.info(\"Loading features from cached file %s\", cached_features_file)\n","        with h5py.File(cached_features_file, 'r') as f:\n","            if file_path=='test':\n","                self.examples = f[file_path][:] #this is a dev set, 10% of a test set\n","            else:\n","                self.examples = f[file_path][:]\n","\n","    def __len__(self):\n","        return len(self.examples)\n","\n","    def __getitem__(self, item):\n","        return torch.tensor(self.examples[item])\n","\n","def load_and_cache_examples(args, tokenizer, evaluate=False):\n","    dataset = TextDataset(tokenizer, file_path=\"test\" if evaluate else \"train\", block_size=args.block_size)\n","    print(dataset[0:5])\n","    return dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6grSGLbPb4Cm"},"source":["parser = argparse.ArgumentParser()\n","## Required parameters\n","parser.add_argument(\"--train_data_file\", default=\"unsupervised.h5\", type=str, required=False,\n","                        help=\"The input training data file (a text file).\")\n","parser.add_argument(\"--output_dir\", default=\"./gdrive/MyDrive/COMP0087/BartGru_CP_350k\", type=str, required=False,\n","                        help=\"The output directory where the model predictions and checkpoints will be written.\")\n","\n","## Other parameters\n","parser.add_argument(\"--model_type\", default=\"facebook/bart-base\" ,type=str,   #\"facebook/bart-base\"\n","                        help=\"The model architecture to be fine-tuned.\")\n","parser.add_argument(\"--model_name_or_path\", default=\"facebook/bart-base\", type=str,\n","                        help=\"The model checkpoint for weights initialization.\")\n","\n","parser.add_argument(\"--eval_data_file\", default=None, type=str,\n","                        help=\"An optional input evaluation data file to evaluate the perplexity on (a text file).\")\n","\n","parser.add_argument(\"--config_name\", default=\"\", type=str,\n","                        help=\"Optional pretrained config name or path if not the same as model_name_or_path\")\n","parser.add_argument(\"--tokenizer_name\", default=\"\", type=str,\n","                        help=\"Optional pretrained tokenizer name or path if not the same as model_name_or_path\")\n","parser.add_argument(\"--cache_dir\", default=\"\", type=str,\n","                        help=\"Optional directory to store the pre-trained models downloaded from s3 (instread of the default one)\")\n","parser.add_argument(\"--block_size\", default=-1, type=int,\n","                        help=\"Optional input sequence length after tokenization.\"\n","                             \"The training dataset will be truncated in block of this size for training.\"\n","                             \"Default to the model max input length for single sentence inputs (take into account special tokens).\")\n","parser.add_argument(\"--do_train\", action='store_true',\n","                        help=\"Whether to run training.\")\n","parser.add_argument(\"--do_eval\", action='store_true',\n","                        help=\"Whether to run eval on the dev set.\")\n","parser.add_argument(\"--evaluate_during_training\", action='store_true',\n","                        help=\"Run evaluation during training at each logging step.\")\n","parser.add_argument(\"--do_lower_case\", action='store_true',\n","                        help=\"Set this flag if you are using an uncased model.\")\n","\n","parser.add_argument(\"--per_gpu_train_batch_size\", default=8, type=int,\n","                        help=\"Batch size per GPU/CPU for training.\")\n","parser.add_argument(\"--per_gpu_eval_batch_size\", default=4, type=int,\n","                        help=\"Batch size per GPU/CPU for evaluation.\")\n","parser.add_argument('--gradient_accumulation_steps', type=int, default=1,\n","                        help=\"Number of updates steps to accumulate before performing a backward/update pass.\")\n","parser.add_argument(\"--learning_rate\", default=5e-5, type=float,\n","                        help=\"The initial learning rate for Adam.\")\n","parser.add_argument(\"--weight_decay\", default=0.0, type=float,\n","                        help=\"Weight deay if we apply some.\")\n","parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float,\n","                        help=\"Epsilon for Adam optimizer.\")\n","parser.add_argument(\"--max_grad_norm\", default=1.0, type=float,\n","                        help=\"Max gradient norm.\")\n","parser.add_argument(\"--num_train_epochs\", default=1, type=float,\n","                        help=\"Total number of training epochs to perform.\")\n","parser.add_argument(\"--max_steps\", default=-1, type=int,\n","                        help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\")\n","parser.add_argument(\"--warmup_steps\", default=0, type=int,\n","                        help=\"Linear warmup over warmup_steps.\")\n","\n","parser.add_argument('--logging_steps', type=int, default=50,\n","                        help=\"Log every X updates steps.\")\n","parser.add_argument('--save_steps', type=int, default=50,\n","                        help=\"Save checkpoint every X updates steps.\")\n","parser.add_argument(\"--eval_all_checkpoints\", action='store_true',\n","                        help=\"Evaluate all checkpoints starting with the same prefix as model_name_or_path ending and ending with step number\")\n","parser.add_argument(\"--no_cuda\", action='store_true',\n","                        help=\"Avoid using CUDA when available\")\n","parser.add_argument('--overwrite_output_dir', action='store_true',\n","                        help=\"Overwrite the content of the output directory\")\n","parser.add_argument('--overwrite_cache', action='store_true',\n","                        help=\"Overwrite the cached training and evaluation sets\")\n","parser.add_argument(\"--aws_bucket\", default=\"\", type=str,\n","                        help=\"Whether to upload to specified bucket.\")\n","args, unknown = parser.parse_known_args()\n","\n","def setup_args_for_model(args):\n","  args.model_type =\"facebook/bart-base\" # \"facebook/bart-base\"\n","  args.model_type = \"\"\n","  \n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x8yhJigCwuTM"},"source":["import random\n","\n","def shuffle_instruction(this_batch,ins_element_id,recipe_end_id):\n","  end_index = (this_batch == recipe_end_id).nonzero()[0]\n","  # ins_element_id = tokenizer.convert_tokens_to_ids([\"<NEXT_INSTR>\"])[0]\n","  ing_index = (this_batch == ins_element_id).nonzero()\n","  ing_index = ing_index[ing_index<end_index]\n","  if len(ing_index) > 1:\n","    split_result = torch.tensor_split(this_batch, ing_index.squeeze())\n","    split_list = list(split_result[1:-1])\n","    random.shuffle(split_list)\n","    shuffle_batch = torch.cat((split_result[0],torch.cat(split_list),split_result[-1]))\n","    return shuffle_batch\n","  else: \n","    return this_batch\n","\n","\n","def ins_token_idf(this_batch,ins_element_id,recipe_end_id):\n","  end_index = (this_batch == recipe_end_id).nonzero()[0]\n","  ing_index = (this_batch == ins_element_id).nonzero()\n","  # print(torch.hstack((torch.full_like(ing_index,0),ing_index)))\n","  ing_index = ing_index[ing_index<end_index]\n","  if len(ing_index) > 0:\n","    return ing_index\n","  else: \n","    return None\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UhM1mHTCgaqf"},"source":["import torch\n","import torch.nn as nn\n","# from transformer import AlbertTokenizer, AlbertForMultipleChoice\n","from transformers import BartModel, BartTokenizer, BartConfig, BartForCausalLM\n","from torch.nn import CrossEntropyLoss, MSELoss, GRU\n","from torch.nn.utils.rnn import pad_sequence\n","\n","\n","class bartWithGRU(nn.Module):\n","    def __init__(self, tokenizer, token_size=1024):\n","        super(bartWithGRU, self).__init__()\n","\n","        # device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n","        self.bart = BartForCausalLM.from_pretrained(\"facebook/bart-base\")\n","        self.bart.resize_token_embeddings(len(tokenizer))\n","        # self.lm_head = nn.Linear(self.bart.config.d_model, self.bart.config.vocab_size, bias=False)\n","\n","        # add an module for consistency checking\n","        print(self.bart.config.d_model)\n","        self.emb_size = 64\n","        self.sentence_emb = nn.Linear(self.bart.config.d_model, self.emb_size)\n","        self.gru = nn.GRU(self.emb_size, 32 , 1 ,batch_first = False)\n","        self.gru_head = nn.Linear(32, 1)\n","        self.linear_activation = nn.Sigmoid()\n","        self.cuda()\n","\n","    def forward(self, batch, inst_pos, labels=None):\n","      # inst_pos: the position of token <NEXT_INSTR>, as a index list.\n","        # print(batch.shape)\n","        outputs = self.bart(batch,output_hidden_states=True)\n","        last_hidden = outputs[\"hidden_states\"][-1]\n","        # gru_input = torch.zeros(batch.size()[0],max_length,self.bart.config.d_model)\n","        # print(gru_input.shape)\n","        # print(last_hidden.shape)\n","        tokens_list = []\n","        for i in range(batch.size()[0]):\n","          batch_hidden = last_hidden[inst_pos[i][:,0],inst_pos[i][:,1],:]\n","          # print(batch_hidden.shape)\n","          tokens_list.append(batch_hidden)\n","        gru_input = pad_sequence(tokens_list)\n","        # print(gru_input.shape)\n","        gru_input = self.sentence_emb(gru_input)\n","        gru_output,_ = self.gru(gru_input)\n","        # print(gru_output.shape)\n","        \n","\n","        # print(ins_subvector.shape)\n","        # consist_output = self.consist_logit(ins_subvector.half().to(args.device))\n","        consist_output = self.gru_head(gru_output[-1])\n","        # print(consist_output.shape)\n","        consist_output = self.linear_activation(consist_output)\n","\n","        logits = outputs[\"logits\"]\n","\n","        return logits, consist_output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dg5IblFRBET8"},"source":["def save_model(args,model,tokenizer,model_class,tokenizer_class):\n","  # Create output directory if neede\n","  if not os.path.exists(args.output_dir):\n","    os.makedirs(args.output_dir)\n","\n","  logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n","  # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","  # They can then be reloaded using `from_pretrained()`\n","  model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","  model_to_save.save_pretrained(args.output_dir)\n","  tokenizer.save_pretrained(args.output_dir)\n","\n","  # Good practice: save your training arguments together with the trained model\n","  torch.save(args, os.path.join(args.output_dir, 'training_args.bin'))\n","\n","  # Load a trained model and vocabulary that you have fine-tuned\n","  model = model_class.from_pretrained(args.output_dir)\n","  tokenizer = tokenizer_class.from_pretrained(args.output_dir, do_lower_case=args.do_lower_case)\n","  # model.to(args.device)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gcMyNMy_3gUO"},"source":["from torch.nn import CrossEntropyLoss, MSELoss\n","\n","\n","def train_seq(args, train_dataset, model, tokenizer):\n","    \"\"\" Train the model \"\"\"\n","\n","    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n","    train_sampler = RandomSampler(train_dataset)\n","    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.train_batch_size)\n","\n","    if args.max_steps > 0:\n","        t_total = args.max_steps\n","        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n","    else:\n","        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n","\n","    # Prepare optimizer and schedule (linear warmup and decay)\n","    no_decay = ['bias', 'LayerNorm.weight']\n","    optimizer_grouped_parameters = [\n","        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","         'weight_decay': args.weight_decay},\n","        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","    ]\n","    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n","    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=args.warmup_steps,\n","                                                num_training_steps=t_total)\n","\n","    try:\n","        from apex import amp\n","    except ImportError:\n","        raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n","\n","    model, optimizer = amp.initialize(model, optimizer, opt_level=\"O2\")\n","\n","    # Train!\n","    global_step = 0\n","    epoch = 0\n","    tr_loss, logging_loss = 0.0, 0.0\n","    model.zero_grad()\n","\n","    train_iterator = trange(int(args.num_train_epochs), desc=\"Epoch\", disable=True)\n","    for _ in train_iterator:\n","        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=True)\n","        \n","\n","        if epoch == 1:\n","          # print(\"start discriminative part\")\n","          # second step: fix the discriminative part \n","          fix_layers = [model.gru, model.gru_head, model.linear_activation,model.sentence_emb]\n","                # mybart.units_logit, mybart.units_activation]\n","          for layer in fix_layers:\n","            for parameter in layer.parameters():\n","              parameter.requires_grad = False\n","\n","\n","        epoch +=1\n","        for step, batch in enumerate(epoch_iterator):\n","\n","            batch_drop = 0\n","            token_list = tokenizer.convert_tokens_to_ids([\"<INSTR_START>\",\n","                                                          \"<INGR_START>\",\n","                                                          \"<NEXT_INSTR>\",\n","                                                          \"<RECIPE_END>\"])\n","            ins_start_id = token_list[0]\n","            ing_start_id = token_list[1]\n","            ins_element_id = token_list[2]\n","            recipe_end_id = token_list[3]\n","\n","\n","            \"\"\"\n","            # random_shuffle = torch.randint(2, (batch.size()[0], 1),device = args.device)\n","            random_shuffle = torch.randint(1, (batch.size()[0], 1),device = args.device)\n","            # print(random_shuffle)\n","            \n","            # shuffle_instruction(batch[1],ins_element_id,recipe_end_id).shape\n","\n","            # ins_tokens_list = []\n","            tokens_list = []\n","            max_length = 0\n","\n","            for batch_no in range(len(batch)):\n","              # print((batch[batch_no] == ins_start_id).nonzero())\n","              if (batch[batch_no] == ins_start_id).nonzero().size()[0] == 0:\n","                print(\"An error happens, break\")\n","                batch_drop = 1\n","                break\n","\n","              if random_shuffle[batch_no] == 1:\n","                # print(batch[batch_no])\n","                batch[batch_no] = shuffle_instruction(batch[batch_no],\n","                                                      ins_start_id,ing_start_id)\n","              \n","              ins_pos = ins_token_idf(batch[batch_no],\n","                                      ins_element_id, recipe_end_id)\n","              if ins_pos == None:\n","                batch_drop = 1\n","                break\n","              ins_pos = ins_pos.reshape(-1,1)\n","\n","              if ins_pos.size()[0] > max_length:\n","                max_length = ins_pos.size()[0]\n","              ins_idx = torch.hstack((torch.full_like(ins_pos,batch_no),ins_pos))\n","              tokens_list.append(ins_idx)\n","              \n","            if batch_drop == 1:\n","              print(\"An error in this batch, break\")\n","              torch.cuda.empty_cache()\n","              continue\n","            \"\"\"\n","            # print(batch.shape)\n","            inputs, labels = (batch[:, 0:-1], batch[:, 1:])\n","            inputs = inputs.to(args.device)\n","            labels = labels.to(args.device)\n","            # label_seq = torch.zeros(batch.size()[0],1).to(args.device)\n","\n","            model.train()\n","\n","            loss_CE = CrossEntropyLoss()\n","            loss_MSE = MSELoss()\n","\n","            # model feed-forward\n","            # logits, consist_output = model(inputs,tokens_list)\n","\n","            outputs = model(inputs)\n","            logits = outputs['logits']\n","\n","            # loss adjustment\n","            bart_vocab_size = 50278\n","            loss = loss_CE(logits.reshape(-1, bart_vocab_size), labels.reshape(-1))\n","            # loss2 = loss_MSE(consist_output, random_shuffle.float())\n","            # loss = loss1 + loss2\n","            # print(\"loss comp: \", loss, outputs['loss'])\n","            if global_step % 50 == 0:\n","              logger.info(step)\n","              print(\"step\", global_step)\n","              print(\"loss:\",loss.item())\n","\n","            if global_step % 10000 == 0 and global_step !=0:\n","              model_checkpoint = model\n","              model_class = BartForCausalLM\n","              tokenizer_class = BartTokenizer\n","              save_model(args,model_checkpoint,tokenizer,model_class,tokenizer_class)\n","\n","            if args.gradient_accumulation_steps > 1:\n","                loss = loss / args.gradient_accumulation_steps\n","\n","            with amp.scale_loss(loss, optimizer) as scaled_loss:\n","                # print(scaled_loss)\n","                scaled_loss.backward()\n","\n","            tr_loss += loss.item()\n","            if (step) % args.gradient_accumulation_steps == 0:\n","                torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\n","                optimizer.step()\n","                scheduler.step()  # Update learning rate schedule\n","                model.zero_grad()\n","                global_step += 1\n","\n","                # if args.logging_steps > 0 and global_step % args.logging_steps == 0:\n","                    # Log metrics\n","                    # tb_writer.add_scalar('lr', scheduler.get_lr()[0], global_step)\n","                    # tb_writer.add_scalar('loss', (tr_loss - logging_loss) / args.logging_steps, global_step)\n","                    # logging_loss = tr_loss\n","\n","            if args.max_steps > 0 and global_step > 2:\n","                epoch_iterator.close()\n","                break\n","            del inputs, labels,logits, outputs, loss\n","            torch.cuda.empty_cache()\n","            # break\n","\n","    return global_step, tr_loss / global_step, batch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bRCAG6cGh-oc"},"source":["def model_init(args,logger, model_class, tokenizer):\n","  if args.eval_data_file is None and args.do_eval:\n","    raise ValueError(\"Cannot do evaluation without an evaluation data file. Either supply a file to --eval_data_file \"\n","                         \"or remove the --do_eval argument.\")\n","  if os.path.exists(args.output_dir) and os.listdir(args.output_dir) and args.do_train and not args.overwrite_output_dir:\n","    raise ValueError(\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(args.output_dir))\n","  device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n","  args.n_gpu = torch.cuda.device_count()\n","  args.device = device\n","\n","  # Setup logging\n","  logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n","                        datefmt = '%m/%d/%Y %H:%M:%S',\n","                        level = logging.INFO)\n","\n","  model = BartForCausalLM.from_pretrained(\"facebook/bart-base\")\n","  model.resize_token_embeddings(len(tokenizer))\n","\n","  if args.block_size <= 0:\n","    args.block_size = tokenizer.max_len_single_sentence  # Our input block size will be the max possible for the model\n","  args.block_size = min(args.block_size, tokenizer.max_len_single_sentence)\n","  model.to(args.device)\n","\n","  logger.info(\"Training/evaluation parameters %s\", args)\n","  return model, logger"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["860a11fe47d348a08e6bed575c630e28","d54f29430de843e7b7bf990d35d8a259","4a926434aead4ec38488c472773b3080","ea992c9b9056415882715564622965db","9ed076a999b145c292ae830c95bb7e55","f957a5cd129d4cfd90f33482a03f43ef","c46933ee4b134663bfa58de78a265be7","8bb7ff5b7f814d75b0a66414f56eed28","88c09cf04f3c48b7aa49f73e64d0084d","77b7b356a862469cadb1396239c27dff","4c00395b1eb246fb9b0dbafa07c3cd2a","6f7943ed008d4b7bab13b5683286a7e2","57a49f068dde496a928809260ad722ef","9f4afc2b055149e9aca6b099bcabc06f","c2bfe493a7f54250a1f259170848e37f","35e1cc9eb9674918aa5a42885e23cb13"]},"id":"OOAth1Vp5ucw","executionInfo":{"status":"ok","timestamp":1622116777925,"user_tz":-60,"elapsed":16636037,"user":{"displayName":"Keyue Jiang","photoUrl":"","userId":"10513797217442927849"}},"outputId":"f811b1c8-b623-4d41-8dc5-030689b0a9b2"},"source":["torch.manual_seed(0)\n","train_dataset = load_and_cache_examples(args, tokenizer, evaluate=False)\n","mybart, logger = model_init(args,logger,BartForCausalLM,tokenizer)\n","global_step, tr_loss, batch = train_seq(args, train_dataset, mybart, tokenizer)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([[    0, 50273, 50275,  ..., 50274, 50274, 50274],\n","        [    0, 50273, 50275,  ..., 50274, 50274, 50274],\n","        [    0, 50273, 50275,  ..., 50274, 50274, 50274],\n","        [    0, 50273, 50275,  ..., 50274, 50274, 50274],\n","        [    0, 50273, 50275,  ..., 50274, 50274, 50274]])\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:22:23 - INFO - filelock -   Lock 139805726643024 acquired on /root/.cache/huggingface/transformers/f5310d276a6d1648d00c32fadc8bf7b4607e0fbd5b404fc4a0045960aa2bdfdb.3c4e938c08a46506ff9a4be12e0f858cd714b9a5c76090d571e7a4aa95cae853.lock\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"860a11fe47d348a08e6bed575c630e28","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1553.0, style=ProgressStyle(description…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["05/27/2021 07:22:23 - INFO - filelock -   Lock 139805726643024 released on /root/.cache/huggingface/transformers/f5310d276a6d1648d00c32fadc8bf7b4607e0fbd5b404fc4a0045960aa2bdfdb.3c4e938c08a46506ff9a4be12e0f858cd714b9a5c76090d571e7a4aa95cae853.lock\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:22:24 - INFO - filelock -   Lock 139805726605392 acquired on /root/.cache/huggingface/transformers/486355ec722ef05fd480e999d4c763be56549ae930f6a3742ee721a5d2a05647.9faea28a6782a9589c09b1942c039943df02232d83d2ac288a69ddfa928eae22.lock\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"88c09cf04f3c48b7aa49f73e64d0084d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=557941479.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["05/27/2021 07:23:03 - INFO - filelock -   Lock 139805726605392 released on /root/.cache/huggingface/transformers/486355ec722ef05fd480e999d4c763be56549ae930f6a3742ee721a5d2a05647.9faea28a6782a9589c09b1942c039943df02232d83d2ac288a69ddfa928eae22.lock\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at facebook/bart-base were not used when initializing BartForCausalLM: ['model.encoder.layers.0.self_attn.v_proj.weight', 'model.encoder.layers.0.fc2.weight', 'model.encoder.layers.5.self_attn_layer_norm.weight', 'model.encoder.layers.5.self_attn.out_proj.bias', 'model.encoder.layers.0.self_attn_layer_norm.bias', 'model.encoder.layers.1.fc1.bias', 'model.encoder.layers.5.self_attn.q_proj.weight', 'model.encoder.layers.4.self_attn.out_proj.weight', 'model.encoder.layers.2.self_attn.v_proj.weight', 'model.encoder.layers.3.self_attn.k_proj.weight', 'model.encoder.layers.0.self_attn_layer_norm.weight', 'model.shared.weight', 'model.encoder.layers.1.fc1.weight', 'model.encoder.layers.4.self_attn.out_proj.bias', 'model.encoder.layers.1.self_attn.q_proj.weight', 'model.encoder.layers.4.final_layer_norm.weight', 'model.encoder.layers.2.fc1.bias', 'model.encoder.layers.0.final_layer_norm.bias', 'model.encoder.layers.2.fc2.weight', 'model.encoder.layers.0.self_attn.v_proj.bias', 'model.encoder.layers.5.self_attn.v_proj.bias', 'model.encoder.layers.2.self_attn.k_proj.weight', 'model.encoder.layers.5.self_attn.k_proj.bias', 'model.encoder.layers.4.self_attn_layer_norm.weight', 'model.encoder.embed_tokens.weight', 'model.encoder.layers.2.self_attn_layer_norm.bias', 'model.encoder.layers.0.fc2.bias', 'model.encoder.embed_positions.weight', 'model.encoder.layers.3.self_attn.q_proj.bias', 'final_logits_bias', 'model.encoder.layers.4.final_layer_norm.bias', 'model.encoder.layers.1.self_attn.out_proj.bias', 'model.encoder.layers.3.fc2.bias', 'model.encoder.layers.1.fc2.weight', 'model.encoder.layers.3.self_attn.out_proj.weight', 'model.encoder.layers.5.self_attn.q_proj.bias', 'model.encoder.layers.4.self_attn.v_proj.bias', 'model.encoder.layers.2.self_attn.out_proj.weight', 'model.encoder.layers.2.fc1.weight', 'model.encoder.layers.4.self_attn.k_proj.bias', 'model.encoder.layers.4.self_attn_layer_norm.bias', 'model.encoder.layers.2.self_attn.k_proj.bias', 'model.encoder.layers.3.self_attn.v_proj.weight', 'model.encoder.layers.2.fc2.bias', 'model.encoder.layers.0.fc1.bias', 'model.encoder.layers.3.final_layer_norm.weight', 'model.encoder.layers.3.self_attn_layer_norm.weight', 'model.encoder.layers.3.final_layer_norm.bias', 'model.encoder.layers.1.self_attn_layer_norm.bias', 'model.encoder.layers.4.self_attn.q_proj.bias', 'model.encoder.layers.1.self_attn.k_proj.bias', 'model.encoder.layernorm_embedding.weight', 'model.encoder.layernorm_embedding.bias', 'model.encoder.layers.4.fc1.weight', 'model.encoder.layers.1.self_attn.q_proj.bias', 'model.encoder.layers.5.self_attn_layer_norm.bias', 'model.encoder.layers.5.self_attn.v_proj.weight', 'model.encoder.layers.3.fc1.weight', 'model.encoder.layers.1.self_attn.v_proj.weight', 'model.encoder.layers.5.fc1.weight', 'model.encoder.layers.5.fc2.weight', 'model.encoder.layers.1.self_attn.v_proj.bias', 'model.encoder.layers.3.self_attn.out_proj.bias', 'model.encoder.layers.2.self_attn.out_proj.bias', 'model.encoder.layers.4.self_attn.q_proj.weight', 'model.encoder.layers.0.self_attn.k_proj.bias', 'model.encoder.layers.2.self_attn.q_proj.weight', 'model.encoder.layers.0.self_attn.out_proj.weight', 'model.encoder.layers.3.self_attn.q_proj.weight', 'model.encoder.layers.3.fc1.bias', 'model.encoder.layers.5.self_attn.k_proj.weight', 'model.encoder.layers.5.fc1.bias', 'model.encoder.layers.3.self_attn_layer_norm.bias', 'model.encoder.layers.0.fc1.weight', 'model.encoder.layers.2.self_attn.q_proj.bias', 'model.encoder.layers.4.fc1.bias', 'model.encoder.layers.4.self_attn.v_proj.weight', 'model.encoder.layers.5.final_layer_norm.weight', 'model.encoder.layers.2.final_layer_norm.bias', 'model.encoder.layers.3.self_attn.k_proj.bias', 'model.encoder.layers.1.self_attn.k_proj.weight', 'model.encoder.layers.5.self_attn.out_proj.weight', 'model.encoder.layers.0.self_attn.q_proj.bias', 'model.encoder.layers.3.fc2.weight', 'model.encoder.layers.5.final_layer_norm.bias', 'model.encoder.layers.5.fc2.bias', 'model.encoder.layers.1.final_layer_norm.bias', 'model.encoder.layers.2.final_layer_norm.weight', 'model.encoder.layers.1.self_attn.out_proj.weight', 'model.encoder.layers.0.self_attn.k_proj.weight', 'model.encoder.layers.3.self_attn.v_proj.bias', 'model.encoder.layers.0.final_layer_norm.weight', 'model.encoder.layers.4.self_attn.k_proj.weight', 'model.encoder.layers.1.fc2.bias', 'model.encoder.layers.2.self_attn_layer_norm.weight', 'model.encoder.layers.4.fc2.bias', 'model.encoder.layers.4.fc2.weight', 'model.encoder.layers.0.self_attn.q_proj.weight', 'model.encoder.layers.1.self_attn_layer_norm.weight', 'model.encoder.layers.2.self_attn.v_proj.bias', 'model.encoder.layers.0.self_attn.out_proj.bias', 'model.encoder.layers.1.final_layer_norm.weight']\n","- This IS expected if you are initializing BartForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BartForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BartForCausalLM were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['lm_head.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","05/27/2021 07:23:11 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, aws_bucket='', block_size=1022, cache_dir='', config_name='', device=device(type='cuda'), do_eval=False, do_lower_case=False, do_train=False, eval_all_checkpoints=False, eval_data_file=None, evaluate_during_training=False, gradient_accumulation_steps=1, learning_rate=5e-05, logging_steps=50, max_grad_norm=1.0, max_steps=-1, model_name_or_path='facebook/bart-base', model_type='facebook/bart-base', n_gpu=1, no_cuda=False, num_train_epochs=1, output_dir='./gdrive/MyDrive/COMP0087/BartGru_CP_350k', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=8, save_steps=50, tokenizer_name='', train_data_file='unsupervised.h5', warmup_steps=0, weight_decay=0.0)\n","05/27/2021 07:23:11 - INFO - __main__ -   0\n"],"name":"stderr"},{"output_type":"stream","text":["Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n","step 0\n","loss: 15.779479026794434\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:125: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:24:00 - INFO - __main__ -   50\n"],"name":"stderr"},{"output_type":"stream","text":["step 50\n","loss: 4.659463882446289\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:24:48 - INFO - __main__ -   100\n"],"name":"stderr"},{"output_type":"stream","text":["step 100\n","loss: 3.20512056350708\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:25:36 - INFO - __main__ -   150\n"],"name":"stderr"},{"output_type":"stream","text":["step 150\n","loss: 2.859930992126465\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:26:24 - INFO - __main__ -   200\n"],"name":"stderr"},{"output_type":"stream","text":["step 200\n","loss: 2.86849308013916\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:27:12 - INFO - __main__ -   250\n"],"name":"stderr"},{"output_type":"stream","text":["step 250\n","loss: 2.6660478115081787\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:28:00 - INFO - __main__ -   300\n"],"name":"stderr"},{"output_type":"stream","text":["step 300\n","loss: 2.2690367698669434\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:28:48 - INFO - __main__ -   350\n"],"name":"stderr"},{"output_type":"stream","text":["step 350\n","loss: 2.542421817779541\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:29:36 - INFO - __main__ -   400\n"],"name":"stderr"},{"output_type":"stream","text":["step 400\n","loss: 2.453010082244873\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:30:24 - INFO - __main__ -   450\n"],"name":"stderr"},{"output_type":"stream","text":["step 450\n","loss: 2.0805647373199463\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:31:12 - INFO - __main__ -   500\n"],"name":"stderr"},{"output_type":"stream","text":["step 500\n","loss: 2.150104284286499\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:32:00 - INFO - __main__ -   550\n"],"name":"stderr"},{"output_type":"stream","text":["step 550\n","loss: 2.152076005935669\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:32:48 - INFO - __main__ -   600\n"],"name":"stderr"},{"output_type":"stream","text":["step 600\n","loss: 2.0982961654663086\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:33:36 - INFO - __main__ -   650\n"],"name":"stderr"},{"output_type":"stream","text":["step 650\n","loss: 2.092198133468628\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:34:24 - INFO - __main__ -   700\n"],"name":"stderr"},{"output_type":"stream","text":["step 700\n","loss: 2.060293197631836\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:35:12 - INFO - __main__ -   750\n"],"name":"stderr"},{"output_type":"stream","text":["step 750\n","loss: 1.9974652528762817\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:36:00 - INFO - __main__ -   800\n"],"name":"stderr"},{"output_type":"stream","text":["step 800\n","loss: 2.174971342086792\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:36:48 - INFO - __main__ -   850\n"],"name":"stderr"},{"output_type":"stream","text":["step 850\n","loss: 2.061661958694458\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:37:36 - INFO - __main__ -   900\n"],"name":"stderr"},{"output_type":"stream","text":["step 900\n","loss: 2.0219249725341797\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:38:24 - INFO - __main__ -   950\n"],"name":"stderr"},{"output_type":"stream","text":["step 950\n","loss: 2.0549004077911377\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:39:12 - INFO - __main__ -   1000\n"],"name":"stderr"},{"output_type":"stream","text":["step 1000\n","loss: 1.8908305168151855\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:40:01 - INFO - __main__ -   1050\n"],"name":"stderr"},{"output_type":"stream","text":["step 1050\n","loss: 2.032078981399536\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:40:49 - INFO - __main__ -   1100\n"],"name":"stderr"},{"output_type":"stream","text":["step 1100\n","loss: 2.0890378952026367\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:41:37 - INFO - __main__ -   1150\n"],"name":"stderr"},{"output_type":"stream","text":["step 1150\n","loss: 2.0180232524871826\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:42:25 - INFO - __main__ -   1200\n"],"name":"stderr"},{"output_type":"stream","text":["step 1200\n","loss: 1.9609885215759277\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:43:13 - INFO - __main__ -   1250\n"],"name":"stderr"},{"output_type":"stream","text":["step 1250\n","loss: 1.8359826803207397\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:44:01 - INFO - __main__ -   1300\n"],"name":"stderr"},{"output_type":"stream","text":["step 1300\n","loss: 1.9244550466537476\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:44:49 - INFO - __main__ -   1350\n"],"name":"stderr"},{"output_type":"stream","text":["step 1350\n","loss: 1.9914523363113403\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:45:37 - INFO - __main__ -   1400\n"],"name":"stderr"},{"output_type":"stream","text":["step 1400\n","loss: 1.891646385192871\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:46:25 - INFO - __main__ -   1450\n"],"name":"stderr"},{"output_type":"stream","text":["step 1450\n","loss: 1.8489067554473877\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:47:13 - INFO - __main__ -   1500\n"],"name":"stderr"},{"output_type":"stream","text":["step 1500\n","loss: 2.012251377105713\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:48:01 - INFO - __main__ -   1550\n"],"name":"stderr"},{"output_type":"stream","text":["step 1550\n","loss: 1.8770387172698975\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:48:49 - INFO - __main__ -   1600\n"],"name":"stderr"},{"output_type":"stream","text":["step 1600\n","loss: 1.7902358770370483\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:49:37 - INFO - __main__ -   1650\n"],"name":"stderr"},{"output_type":"stream","text":["step 1650\n","loss: 1.7586129903793335\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:50:25 - INFO - __main__ -   1700\n"],"name":"stderr"},{"output_type":"stream","text":["step 1700\n","loss: 1.9009438753128052\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:51:13 - INFO - __main__ -   1750\n"],"name":"stderr"},{"output_type":"stream","text":["step 1750\n","loss: 1.5524237155914307\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:52:01 - INFO - __main__ -   1800\n"],"name":"stderr"},{"output_type":"stream","text":["step 1800\n","loss: 1.9770643711090088\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:52:49 - INFO - __main__ -   1850\n"],"name":"stderr"},{"output_type":"stream","text":["step 1850\n","loss: 2.002539873123169\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:53:37 - INFO - __main__ -   1900\n"],"name":"stderr"},{"output_type":"stream","text":["step 1900\n","loss: 1.8067139387130737\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:54:25 - INFO - __main__ -   1950\n"],"name":"stderr"},{"output_type":"stream","text":["step 1950\n","loss: 1.7892557382583618\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:55:13 - INFO - __main__ -   2000\n"],"name":"stderr"},{"output_type":"stream","text":["step 2000\n","loss: 1.8978140354156494\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:56:01 - INFO - __main__ -   2050\n"],"name":"stderr"},{"output_type":"stream","text":["step 2050\n","loss: 1.8094457387924194\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:56:49 - INFO - __main__ -   2100\n"],"name":"stderr"},{"output_type":"stream","text":["step 2100\n","loss: 1.7181421518325806\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:57:37 - INFO - __main__ -   2150\n"],"name":"stderr"},{"output_type":"stream","text":["step 2150\n","loss: 1.7828706502914429\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:58:25 - INFO - __main__ -   2200\n"],"name":"stderr"},{"output_type":"stream","text":["step 2200\n","loss: 1.6803678274154663\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 07:59:13 - INFO - __main__ -   2250\n"],"name":"stderr"},{"output_type":"stream","text":["step 2250\n","loss: 1.8334065675735474\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:00:01 - INFO - __main__ -   2300\n"],"name":"stderr"},{"output_type":"stream","text":["step 2300\n","loss: 1.7868223190307617\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:00:49 - INFO - __main__ -   2350\n"],"name":"stderr"},{"output_type":"stream","text":["step 2350\n","loss: 1.9629724025726318\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:01:37 - INFO - __main__ -   2400\n"],"name":"stderr"},{"output_type":"stream","text":["step 2400\n","loss: 1.8774309158325195\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:02:25 - INFO - __main__ -   2450\n"],"name":"stderr"},{"output_type":"stream","text":["step 2450\n","loss: 1.7938355207443237\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:03:13 - INFO - __main__ -   2500\n"],"name":"stderr"},{"output_type":"stream","text":["step 2500\n","loss: 1.748349666595459\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:04:01 - INFO - __main__ -   2550\n"],"name":"stderr"},{"output_type":"stream","text":["step 2550\n","loss: 1.7241710424423218\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:04:49 - INFO - __main__ -   2600\n"],"name":"stderr"},{"output_type":"stream","text":["step 2600\n","loss: 1.8296449184417725\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:05:37 - INFO - __main__ -   2650\n"],"name":"stderr"},{"output_type":"stream","text":["step 2650\n","loss: 1.6101628541946411\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:06:25 - INFO - __main__ -   2700\n"],"name":"stderr"},{"output_type":"stream","text":["step 2700\n","loss: 1.6351138353347778\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:07:13 - INFO - __main__ -   2750\n"],"name":"stderr"},{"output_type":"stream","text":["step 2750\n","loss: 1.4600032567977905\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:08:01 - INFO - __main__ -   2800\n"],"name":"stderr"},{"output_type":"stream","text":["step 2800\n","loss: 1.4489775896072388\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:08:49 - INFO - __main__ -   2850\n"],"name":"stderr"},{"output_type":"stream","text":["step 2850\n","loss: 1.7392656803131104\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:09:37 - INFO - __main__ -   2900\n"],"name":"stderr"},{"output_type":"stream","text":["step 2900\n","loss: 1.8877067565917969\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:10:25 - INFO - __main__ -   2950\n"],"name":"stderr"},{"output_type":"stream","text":["step 2950\n","loss: 1.457938551902771\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:11:13 - INFO - __main__ -   3000\n"],"name":"stderr"},{"output_type":"stream","text":["step 3000\n","loss: 1.7658164501190186\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:12:01 - INFO - __main__ -   3050\n"],"name":"stderr"},{"output_type":"stream","text":["step 3050\n","loss: 1.9955739974975586\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:12:49 - INFO - __main__ -   3100\n"],"name":"stderr"},{"output_type":"stream","text":["step 3100\n","loss: 1.5758397579193115\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:13:37 - INFO - __main__ -   3150\n"],"name":"stderr"},{"output_type":"stream","text":["step 3150\n","loss: 1.8137913942337036\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:14:25 - INFO - __main__ -   3200\n"],"name":"stderr"},{"output_type":"stream","text":["step 3200\n","loss: 1.6466330289840698\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:15:13 - INFO - __main__ -   3250\n"],"name":"stderr"},{"output_type":"stream","text":["step 3250\n","loss: 1.643094539642334\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:16:01 - INFO - __main__ -   3300\n"],"name":"stderr"},{"output_type":"stream","text":["step 3300\n","loss: 1.730869174003601\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:16:49 - INFO - __main__ -   3350\n"],"name":"stderr"},{"output_type":"stream","text":["step 3350\n","loss: 1.7590925693511963\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:17:37 - INFO - __main__ -   3400\n"],"name":"stderr"},{"output_type":"stream","text":["step 3400\n","loss: 1.460504174232483\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:18:25 - INFO - __main__ -   3450\n"],"name":"stderr"},{"output_type":"stream","text":["step 3450\n","loss: 1.759612798690796\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:19:13 - INFO - __main__ -   3500\n"],"name":"stderr"},{"output_type":"stream","text":["step 3500\n","loss: 1.8569674491882324\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:20:01 - INFO - __main__ -   3550\n"],"name":"stderr"},{"output_type":"stream","text":["step 3550\n","loss: 1.687813401222229\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:20:49 - INFO - __main__ -   3600\n"],"name":"stderr"},{"output_type":"stream","text":["step 3600\n","loss: 1.6576573848724365\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:21:36 - INFO - __main__ -   3650\n"],"name":"stderr"},{"output_type":"stream","text":["step 3650\n","loss: 1.723970651626587\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:22:24 - INFO - __main__ -   3700\n"],"name":"stderr"},{"output_type":"stream","text":["step 3700\n","loss: 1.9337389469146729\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:23:12 - INFO - __main__ -   3750\n"],"name":"stderr"},{"output_type":"stream","text":["step 3750\n","loss: 1.5204136371612549\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:24:00 - INFO - __main__ -   3800\n"],"name":"stderr"},{"output_type":"stream","text":["step 3800\n","loss: 1.767508625984192\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:24:48 - INFO - __main__ -   3850\n"],"name":"stderr"},{"output_type":"stream","text":["step 3850\n","loss: 1.5511856079101562\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:25:36 - INFO - __main__ -   3900\n"],"name":"stderr"},{"output_type":"stream","text":["step 3900\n","loss: 1.5768682956695557\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:26:24 - INFO - __main__ -   3950\n"],"name":"stderr"},{"output_type":"stream","text":["step 3950\n","loss: 1.7521400451660156\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:27:12 - INFO - __main__ -   4000\n"],"name":"stderr"},{"output_type":"stream","text":["step 4000\n","loss: 1.753902792930603\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:28:00 - INFO - __main__ -   4050\n"],"name":"stderr"},{"output_type":"stream","text":["step 4050\n","loss: 1.6858566999435425\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:28:48 - INFO - __main__ -   4100\n"],"name":"stderr"},{"output_type":"stream","text":["step 4100\n","loss: 1.4356050491333008\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:29:36 - INFO - __main__ -   4150\n"],"name":"stderr"},{"output_type":"stream","text":["step 4150\n","loss: 1.754368543624878\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:30:24 - INFO - __main__ -   4200\n"],"name":"stderr"},{"output_type":"stream","text":["step 4200\n","loss: 1.5786813497543335\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:31:12 - INFO - __main__ -   4250\n"],"name":"stderr"},{"output_type":"stream","text":["step 4250\n","loss: 1.7606043815612793\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:32:00 - INFO - __main__ -   4300\n"],"name":"stderr"},{"output_type":"stream","text":["step 4300\n","loss: 1.728491187095642\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:32:48 - INFO - __main__ -   4350\n"],"name":"stderr"},{"output_type":"stream","text":["step 4350\n","loss: 1.547224521636963\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:33:36 - INFO - __main__ -   4400\n"],"name":"stderr"},{"output_type":"stream","text":["step 4400\n","loss: 1.6600143909454346\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:34:24 - INFO - __main__ -   4450\n"],"name":"stderr"},{"output_type":"stream","text":["step 4450\n","loss: 1.8280255794525146\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:35:12 - INFO - __main__ -   4500\n"],"name":"stderr"},{"output_type":"stream","text":["step 4500\n","loss: 1.7469433546066284\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:36:00 - INFO - __main__ -   4550\n"],"name":"stderr"},{"output_type":"stream","text":["step 4550\n","loss: 1.7208675146102905\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:36:48 - INFO - __main__ -   4600\n"],"name":"stderr"},{"output_type":"stream","text":["step 4600\n","loss: 1.7439340353012085\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:37:36 - INFO - __main__ -   4650\n"],"name":"stderr"},{"output_type":"stream","text":["step 4650\n","loss: 1.7465273141860962\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:38:24 - INFO - __main__ -   4700\n"],"name":"stderr"},{"output_type":"stream","text":["step 4700\n","loss: 1.6145026683807373\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:39:12 - INFO - __main__ -   4750\n"],"name":"stderr"},{"output_type":"stream","text":["step 4750\n","loss: 1.602317452430725\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:40:00 - INFO - __main__ -   4800\n"],"name":"stderr"},{"output_type":"stream","text":["step 4800\n","loss: 1.6888577938079834\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:40:48 - INFO - __main__ -   4850\n"],"name":"stderr"},{"output_type":"stream","text":["step 4850\n","loss: 1.7017289400100708\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:41:36 - INFO - __main__ -   4900\n"],"name":"stderr"},{"output_type":"stream","text":["step 4900\n","loss: 1.5624998807907104\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:42:24 - INFO - __main__ -   4950\n"],"name":"stderr"},{"output_type":"stream","text":["step 4950\n","loss: 1.6241151094436646\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:43:12 - INFO - __main__ -   5000\n"],"name":"stderr"},{"output_type":"stream","text":["step 5000\n","loss: 1.5486911535263062\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:44:00 - INFO - __main__ -   5050\n"],"name":"stderr"},{"output_type":"stream","text":["step 5050\n","loss: 1.7164918184280396\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:44:48 - INFO - __main__ -   5100\n"],"name":"stderr"},{"output_type":"stream","text":["step 5100\n","loss: 1.6793197393417358\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:45:36 - INFO - __main__ -   5150\n"],"name":"stderr"},{"output_type":"stream","text":["step 5150\n","loss: 1.5069934129714966\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:46:23 - INFO - __main__ -   5200\n"],"name":"stderr"},{"output_type":"stream","text":["step 5200\n","loss: 1.4292693138122559\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:47:11 - INFO - __main__ -   5250\n"],"name":"stderr"},{"output_type":"stream","text":["step 5250\n","loss: 1.5115509033203125\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:47:59 - INFO - __main__ -   5300\n"],"name":"stderr"},{"output_type":"stream","text":["step 5300\n","loss: 1.7528702020645142\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:48:47 - INFO - __main__ -   5350\n"],"name":"stderr"},{"output_type":"stream","text":["step 5350\n","loss: 1.6785674095153809\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:49:35 - INFO - __main__ -   5400\n"],"name":"stderr"},{"output_type":"stream","text":["step 5400\n","loss: 1.5531489849090576\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:50:23 - INFO - __main__ -   5450\n"],"name":"stderr"},{"output_type":"stream","text":["step 5450\n","loss: 1.707932710647583\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:51:11 - INFO - __main__ -   5500\n"],"name":"stderr"},{"output_type":"stream","text":["step 5500\n","loss: 1.7436810731887817\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:51:59 - INFO - __main__ -   5550\n"],"name":"stderr"},{"output_type":"stream","text":["step 5550\n","loss: 1.5885578393936157\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:52:47 - INFO - __main__ -   5600\n"],"name":"stderr"},{"output_type":"stream","text":["step 5600\n","loss: 1.6668858528137207\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:53:35 - INFO - __main__ -   5650\n"],"name":"stderr"},{"output_type":"stream","text":["step 5650\n","loss: 1.894162654876709\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:54:23 - INFO - __main__ -   5700\n"],"name":"stderr"},{"output_type":"stream","text":["step 5700\n","loss: 1.455358862876892\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:55:11 - INFO - __main__ -   5750\n"],"name":"stderr"},{"output_type":"stream","text":["step 5750\n","loss: 1.6178803443908691\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:55:59 - INFO - __main__ -   5800\n"],"name":"stderr"},{"output_type":"stream","text":["step 5800\n","loss: 1.8482654094696045\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:56:47 - INFO - __main__ -   5850\n"],"name":"stderr"},{"output_type":"stream","text":["step 5850\n","loss: 1.5753916501998901\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:57:35 - INFO - __main__ -   5900\n"],"name":"stderr"},{"output_type":"stream","text":["step 5900\n","loss: 1.7216746807098389\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:58:23 - INFO - __main__ -   5950\n"],"name":"stderr"},{"output_type":"stream","text":["step 5950\n","loss: 1.5862668752670288\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:59:11 - INFO - __main__ -   6000\n"],"name":"stderr"},{"output_type":"stream","text":["step 6000\n","loss: 1.8218921422958374\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 08:59:59 - INFO - __main__ -   6050\n"],"name":"stderr"},{"output_type":"stream","text":["step 6050\n","loss: 1.613148808479309\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:00:47 - INFO - __main__ -   6100\n"],"name":"stderr"},{"output_type":"stream","text":["step 6100\n","loss: 1.5819758176803589\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:01:35 - INFO - __main__ -   6150\n"],"name":"stderr"},{"output_type":"stream","text":["step 6150\n","loss: 1.535571813583374\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:02:23 - INFO - __main__ -   6200\n"],"name":"stderr"},{"output_type":"stream","text":["step 6200\n","loss: 1.6497392654418945\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:03:11 - INFO - __main__ -   6250\n"],"name":"stderr"},{"output_type":"stream","text":["step 6250\n","loss: 1.4102035760879517\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:03:59 - INFO - __main__ -   6300\n"],"name":"stderr"},{"output_type":"stream","text":["step 6300\n","loss: 1.7078871726989746\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:04:47 - INFO - __main__ -   6350\n"],"name":"stderr"},{"output_type":"stream","text":["step 6350\n","loss: 1.4585943222045898\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:05:35 - INFO - __main__ -   6400\n"],"name":"stderr"},{"output_type":"stream","text":["step 6400\n","loss: 1.7395833730697632\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:06:23 - INFO - __main__ -   6450\n"],"name":"stderr"},{"output_type":"stream","text":["step 6450\n","loss: 1.5201523303985596\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:07:10 - INFO - __main__ -   6500\n"],"name":"stderr"},{"output_type":"stream","text":["step 6500\n","loss: 1.5270317792892456\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:07:58 - INFO - __main__ -   6550\n"],"name":"stderr"},{"output_type":"stream","text":["step 6550\n","loss: 1.4390536546707153\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:08:46 - INFO - __main__ -   6600\n"],"name":"stderr"},{"output_type":"stream","text":["step 6600\n","loss: 1.6337628364562988\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:09:34 - INFO - __main__ -   6650\n"],"name":"stderr"},{"output_type":"stream","text":["step 6650\n","loss: 1.604164958000183\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:10:22 - INFO - __main__ -   6700\n"],"name":"stderr"},{"output_type":"stream","text":["step 6700\n","loss: 1.6028635501861572\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:11:10 - INFO - __main__ -   6750\n"],"name":"stderr"},{"output_type":"stream","text":["step 6750\n","loss: 1.7519035339355469\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:11:58 - INFO - __main__ -   6800\n"],"name":"stderr"},{"output_type":"stream","text":["step 6800\n","loss: 1.6223121881484985\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:12:46 - INFO - __main__ -   6850\n"],"name":"stderr"},{"output_type":"stream","text":["step 6850\n","loss: 1.380203366279602\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:13:34 - INFO - __main__ -   6900\n"],"name":"stderr"},{"output_type":"stream","text":["step 6900\n","loss: 1.33041512966156\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:14:22 - INFO - __main__ -   6950\n"],"name":"stderr"},{"output_type":"stream","text":["step 6950\n","loss: 1.5818146467208862\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:15:10 - INFO - __main__ -   7000\n"],"name":"stderr"},{"output_type":"stream","text":["step 7000\n","loss: 1.4475747346878052\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:15:58 - INFO - __main__ -   7050\n"],"name":"stderr"},{"output_type":"stream","text":["step 7050\n","loss: 1.3262431621551514\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:16:46 - INFO - __main__ -   7100\n"],"name":"stderr"},{"output_type":"stream","text":["step 7100\n","loss: 1.8138604164123535\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:17:34 - INFO - __main__ -   7150\n"],"name":"stderr"},{"output_type":"stream","text":["step 7150\n","loss: 1.5275758504867554\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:18:22 - INFO - __main__ -   7200\n"],"name":"stderr"},{"output_type":"stream","text":["step 7200\n","loss: 1.6318532228469849\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:19:10 - INFO - __main__ -   7250\n"],"name":"stderr"},{"output_type":"stream","text":["step 7250\n","loss: 1.346116542816162\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:19:58 - INFO - __main__ -   7300\n"],"name":"stderr"},{"output_type":"stream","text":["step 7300\n","loss: 1.320536732673645\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:20:46 - INFO - __main__ -   7350\n"],"name":"stderr"},{"output_type":"stream","text":["step 7350\n","loss: 1.7192565202713013\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:21:34 - INFO - __main__ -   7400\n"],"name":"stderr"},{"output_type":"stream","text":["step 7400\n","loss: 1.5464950799942017\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:22:22 - INFO - __main__ -   7450\n"],"name":"stderr"},{"output_type":"stream","text":["step 7450\n","loss: 1.7502481937408447\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:23:10 - INFO - __main__ -   7500\n"],"name":"stderr"},{"output_type":"stream","text":["step 7500\n","loss: 1.5135220289230347\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:23:58 - INFO - __main__ -   7550\n"],"name":"stderr"},{"output_type":"stream","text":["step 7550\n","loss: 1.4218547344207764\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:24:46 - INFO - __main__ -   7600\n"],"name":"stderr"},{"output_type":"stream","text":["step 7600\n","loss: 1.4079060554504395\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:25:34 - INFO - __main__ -   7650\n"],"name":"stderr"},{"output_type":"stream","text":["step 7650\n","loss: 1.5950613021850586\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:26:22 - INFO - __main__ -   7700\n"],"name":"stderr"},{"output_type":"stream","text":["step 7700\n","loss: 1.5798643827438354\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:27:10 - INFO - __main__ -   7750\n"],"name":"stderr"},{"output_type":"stream","text":["step 7750\n","loss: 1.6208546161651611\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:27:58 - INFO - __main__ -   7800\n"],"name":"stderr"},{"output_type":"stream","text":["step 7800\n","loss: 1.69817054271698\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:28:46 - INFO - __main__ -   7850\n"],"name":"stderr"},{"output_type":"stream","text":["step 7850\n","loss: 1.677289605140686\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:29:33 - INFO - __main__ -   7900\n"],"name":"stderr"},{"output_type":"stream","text":["step 7900\n","loss: 1.5528979301452637\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:30:21 - INFO - __main__ -   7950\n"],"name":"stderr"},{"output_type":"stream","text":["step 7950\n","loss: 1.6821777820587158\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:31:09 - INFO - __main__ -   8000\n"],"name":"stderr"},{"output_type":"stream","text":["step 8000\n","loss: 1.5856276750564575\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:31:57 - INFO - __main__ -   8050\n"],"name":"stderr"},{"output_type":"stream","text":["step 8050\n","loss: 1.4378678798675537\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:32:45 - INFO - __main__ -   8100\n"],"name":"stderr"},{"output_type":"stream","text":["step 8100\n","loss: 1.647031545639038\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:33:33 - INFO - __main__ -   8150\n"],"name":"stderr"},{"output_type":"stream","text":["step 8150\n","loss: 1.480098843574524\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:34:21 - INFO - __main__ -   8200\n"],"name":"stderr"},{"output_type":"stream","text":["step 8200\n","loss: 1.6481008529663086\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:35:09 - INFO - __main__ -   8250\n"],"name":"stderr"},{"output_type":"stream","text":["step 8250\n","loss: 1.5840367078781128\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:35:57 - INFO - __main__ -   8300\n"],"name":"stderr"},{"output_type":"stream","text":["step 8300\n","loss: 1.569754958152771\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:36:45 - INFO - __main__ -   8350\n"],"name":"stderr"},{"output_type":"stream","text":["step 8350\n","loss: 1.454692006111145\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:37:33 - INFO - __main__ -   8400\n"],"name":"stderr"},{"output_type":"stream","text":["step 8400\n","loss: 1.468892216682434\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:38:21 - INFO - __main__ -   8450\n"],"name":"stderr"},{"output_type":"stream","text":["step 8450\n","loss: 1.611187219619751\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:39:09 - INFO - __main__ -   8500\n"],"name":"stderr"},{"output_type":"stream","text":["step 8500\n","loss: 1.4312927722930908\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:39:57 - INFO - __main__ -   8550\n"],"name":"stderr"},{"output_type":"stream","text":["step 8550\n","loss: 1.4230983257293701\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:40:45 - INFO - __main__ -   8600\n"],"name":"stderr"},{"output_type":"stream","text":["step 8600\n","loss: 1.4330419301986694\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:41:33 - INFO - __main__ -   8650\n"],"name":"stderr"},{"output_type":"stream","text":["step 8650\n","loss: 1.5687695741653442\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:42:21 - INFO - __main__ -   8700\n"],"name":"stderr"},{"output_type":"stream","text":["step 8700\n","loss: 1.5631225109100342\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:43:09 - INFO - __main__ -   8750\n"],"name":"stderr"},{"output_type":"stream","text":["step 8750\n","loss: 1.469308614730835\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:43:57 - INFO - __main__ -   8800\n"],"name":"stderr"},{"output_type":"stream","text":["step 8800\n","loss: 1.2964189052581787\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:44:45 - INFO - __main__ -   8850\n"],"name":"stderr"},{"output_type":"stream","text":["step 8850\n","loss: 1.4632996320724487\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:45:33 - INFO - __main__ -   8900\n"],"name":"stderr"},{"output_type":"stream","text":["step 8900\n","loss: 1.5327540636062622\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:46:21 - INFO - __main__ -   8950\n"],"name":"stderr"},{"output_type":"stream","text":["step 8950\n","loss: 1.4385839700698853\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:47:09 - INFO - __main__ -   9000\n"],"name":"stderr"},{"output_type":"stream","text":["step 9000\n","loss: 1.4267877340316772\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:47:57 - INFO - __main__ -   9050\n"],"name":"stderr"},{"output_type":"stream","text":["step 9050\n","loss: 1.4577654600143433\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:48:45 - INFO - __main__ -   9100\n"],"name":"stderr"},{"output_type":"stream","text":["step 9100\n","loss: 1.3554401397705078\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:49:32 - INFO - __main__ -   9150\n"],"name":"stderr"},{"output_type":"stream","text":["step 9150\n","loss: 1.5644277334213257\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:50:20 - INFO - __main__ -   9200\n"],"name":"stderr"},{"output_type":"stream","text":["step 9200\n","loss: 1.4096876382827759\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:51:08 - INFO - __main__ -   9250\n"],"name":"stderr"},{"output_type":"stream","text":["step 9250\n","loss: 1.4034994840621948\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:51:56 - INFO - __main__ -   9300\n"],"name":"stderr"},{"output_type":"stream","text":["step 9300\n","loss: 1.8009313344955444\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:52:44 - INFO - __main__ -   9350\n"],"name":"stderr"},{"output_type":"stream","text":["step 9350\n","loss: 1.5574766397476196\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:53:32 - INFO - __main__ -   9400\n"],"name":"stderr"},{"output_type":"stream","text":["step 9400\n","loss: 1.4972646236419678\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:54:20 - INFO - __main__ -   9450\n"],"name":"stderr"},{"output_type":"stream","text":["step 9450\n","loss: 1.6527884006500244\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:55:08 - INFO - __main__ -   9500\n"],"name":"stderr"},{"output_type":"stream","text":["step 9500\n","loss: 1.634904146194458\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:55:56 - INFO - __main__ -   9550\n"],"name":"stderr"},{"output_type":"stream","text":["step 9550\n","loss: 1.48623526096344\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:56:44 - INFO - __main__ -   9600\n"],"name":"stderr"},{"output_type":"stream","text":["step 9600\n","loss: 1.438908338546753\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:57:32 - INFO - __main__ -   9650\n"],"name":"stderr"},{"output_type":"stream","text":["step 9650\n","loss: 1.5839354991912842\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:58:20 - INFO - __main__ -   9700\n"],"name":"stderr"},{"output_type":"stream","text":["step 9700\n","loss: 1.5238019227981567\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:59:08 - INFO - __main__ -   9750\n"],"name":"stderr"},{"output_type":"stream","text":["step 9750\n","loss: 1.4554295539855957\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 09:59:56 - INFO - __main__ -   9800\n"],"name":"stderr"},{"output_type":"stream","text":["step 9800\n","loss: 1.5411239862442017\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:00:44 - INFO - __main__ -   9850\n"],"name":"stderr"},{"output_type":"stream","text":["step 9850\n","loss: 1.5090460777282715\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:01:32 - INFO - __main__ -   9900\n"],"name":"stderr"},{"output_type":"stream","text":["step 9900\n","loss: 1.652132272720337\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:02:20 - INFO - __main__ -   9950\n"],"name":"stderr"},{"output_type":"stream","text":["step 9950\n","loss: 1.681625485420227\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:03:08 - INFO - __main__ -   10000\n","05/27/2021 10:03:08 - INFO - __main__ -   Saving model checkpoint to ./gdrive/MyDrive/COMP0087/BartGru_CP_350k\n"],"name":"stderr"},{"output_type":"stream","text":["step 10000\n","loss: 1.4546679258346558\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:04:14 - INFO - __main__ -   10050\n"],"name":"stderr"},{"output_type":"stream","text":["step 10050\n","loss: 1.5688025951385498\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:05:02 - INFO - __main__ -   10100\n"],"name":"stderr"},{"output_type":"stream","text":["step 10100\n","loss: 1.6579583883285522\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:05:50 - INFO - __main__ -   10150\n"],"name":"stderr"},{"output_type":"stream","text":["step 10150\n","loss: 1.6094987392425537\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:06:38 - INFO - __main__ -   10200\n"],"name":"stderr"},{"output_type":"stream","text":["step 10200\n","loss: 1.4586552381515503\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:07:26 - INFO - __main__ -   10250\n"],"name":"stderr"},{"output_type":"stream","text":["step 10250\n","loss: 1.3989335298538208\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:08:14 - INFO - __main__ -   10300\n"],"name":"stderr"},{"output_type":"stream","text":["step 10300\n","loss: 1.39913809299469\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:09:01 - INFO - __main__ -   10350\n"],"name":"stderr"},{"output_type":"stream","text":["step 10350\n","loss: 1.5351594686508179\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:09:49 - INFO - __main__ -   10400\n"],"name":"stderr"},{"output_type":"stream","text":["step 10400\n","loss: 1.4045768976211548\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:10:37 - INFO - __main__ -   10450\n"],"name":"stderr"},{"output_type":"stream","text":["step 10450\n","loss: 1.5174723863601685\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:11:25 - INFO - __main__ -   10500\n"],"name":"stderr"},{"output_type":"stream","text":["step 10500\n","loss: 1.517772912979126\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:12:13 - INFO - __main__ -   10550\n"],"name":"stderr"},{"output_type":"stream","text":["step 10550\n","loss: 1.4394521713256836\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:13:01 - INFO - __main__ -   10600\n"],"name":"stderr"},{"output_type":"stream","text":["step 10600\n","loss: 1.4966124296188354\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:13:49 - INFO - __main__ -   10650\n"],"name":"stderr"},{"output_type":"stream","text":["step 10650\n","loss: 1.5124781131744385\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:14:37 - INFO - __main__ -   10700\n"],"name":"stderr"},{"output_type":"stream","text":["step 10700\n","loss: 1.602166771888733\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:15:25 - INFO - __main__ -   10750\n"],"name":"stderr"},{"output_type":"stream","text":["step 10750\n","loss: 1.5508482456207275\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:16:13 - INFO - __main__ -   10800\n"],"name":"stderr"},{"output_type":"stream","text":["step 10800\n","loss: 1.370240569114685\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:17:01 - INFO - __main__ -   10850\n"],"name":"stderr"},{"output_type":"stream","text":["step 10850\n","loss: 1.5112706422805786\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:17:49 - INFO - __main__ -   10900\n"],"name":"stderr"},{"output_type":"stream","text":["step 10900\n","loss: 1.5678852796554565\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:18:37 - INFO - __main__ -   10950\n"],"name":"stderr"},{"output_type":"stream","text":["step 10950\n","loss: 1.445552945137024\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:19:25 - INFO - __main__ -   11000\n"],"name":"stderr"},{"output_type":"stream","text":["step 11000\n","loss: 1.5049165487289429\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:20:13 - INFO - __main__ -   11050\n"],"name":"stderr"},{"output_type":"stream","text":["step 11050\n","loss: 1.6611348390579224\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:21:01 - INFO - __main__ -   11100\n"],"name":"stderr"},{"output_type":"stream","text":["step 11100\n","loss: 1.5411752462387085\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:21:49 - INFO - __main__ -   11150\n"],"name":"stderr"},{"output_type":"stream","text":["step 11150\n","loss: 1.3317992687225342\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:22:37 - INFO - __main__ -   11200\n"],"name":"stderr"},{"output_type":"stream","text":["step 11200\n","loss: 1.42174232006073\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:23:25 - INFO - __main__ -   11250\n"],"name":"stderr"},{"output_type":"stream","text":["step 11250\n","loss: 1.419806957244873\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:24:13 - INFO - __main__ -   11300\n"],"name":"stderr"},{"output_type":"stream","text":["step 11300\n","loss: 1.5063666105270386\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:25:01 - INFO - __main__ -   11350\n"],"name":"stderr"},{"output_type":"stream","text":["step 11350\n","loss: 1.5315693616867065\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:25:49 - INFO - __main__ -   11400\n"],"name":"stderr"},{"output_type":"stream","text":["step 11400\n","loss: 1.8538364171981812\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:26:37 - INFO - __main__ -   11450\n"],"name":"stderr"},{"output_type":"stream","text":["step 11450\n","loss: 1.5008684396743774\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:27:24 - INFO - __main__ -   11500\n"],"name":"stderr"},{"output_type":"stream","text":["step 11500\n","loss: 1.4594825506210327\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:28:12 - INFO - __main__ -   11550\n"],"name":"stderr"},{"output_type":"stream","text":["step 11550\n","loss: 1.5308828353881836\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:29:00 - INFO - __main__ -   11600\n"],"name":"stderr"},{"output_type":"stream","text":["step 11600\n","loss: 1.2758835554122925\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:29:48 - INFO - __main__ -   11650\n"],"name":"stderr"},{"output_type":"stream","text":["step 11650\n","loss: 1.3614599704742432\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:30:36 - INFO - __main__ -   11700\n"],"name":"stderr"},{"output_type":"stream","text":["step 11700\n","loss: 1.5200129747390747\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:31:24 - INFO - __main__ -   11750\n"],"name":"stderr"},{"output_type":"stream","text":["step 11750\n","loss: 1.3412550687789917\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:32:12 - INFO - __main__ -   11800\n"],"name":"stderr"},{"output_type":"stream","text":["step 11800\n","loss: 1.3563705682754517\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:33:00 - INFO - __main__ -   11850\n"],"name":"stderr"},{"output_type":"stream","text":["step 11850\n","loss: 1.4757487773895264\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:33:48 - INFO - __main__ -   11900\n"],"name":"stderr"},{"output_type":"stream","text":["step 11900\n","loss: 1.6975045204162598\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:34:36 - INFO - __main__ -   11950\n"],"name":"stderr"},{"output_type":"stream","text":["step 11950\n","loss: 1.3974415063858032\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:35:24 - INFO - __main__ -   12000\n"],"name":"stderr"},{"output_type":"stream","text":["step 12000\n","loss: 1.4482929706573486\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:36:12 - INFO - __main__ -   12050\n"],"name":"stderr"},{"output_type":"stream","text":["step 12050\n","loss: 1.6230120658874512\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:37:00 - INFO - __main__ -   12100\n"],"name":"stderr"},{"output_type":"stream","text":["step 12100\n","loss: 1.5554436445236206\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:37:48 - INFO - __main__ -   12150\n"],"name":"stderr"},{"output_type":"stream","text":["step 12150\n","loss: 1.590818166732788\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:38:36 - INFO - __main__ -   12200\n"],"name":"stderr"},{"output_type":"stream","text":["step 12200\n","loss: 1.6077548265457153\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:39:24 - INFO - __main__ -   12250\n"],"name":"stderr"},{"output_type":"stream","text":["step 12250\n","loss: 1.616757869720459\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:40:12 - INFO - __main__ -   12300\n"],"name":"stderr"},{"output_type":"stream","text":["step 12300\n","loss: 1.2461775541305542\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:41:00 - INFO - __main__ -   12350\n"],"name":"stderr"},{"output_type":"stream","text":["step 12350\n","loss: 1.3034507036209106\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:41:48 - INFO - __main__ -   12400\n"],"name":"stderr"},{"output_type":"stream","text":["step 12400\n","loss: 1.4491653442382812\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:42:36 - INFO - __main__ -   12450\n"],"name":"stderr"},{"output_type":"stream","text":["step 12450\n","loss: 1.5534080266952515\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:43:24 - INFO - __main__ -   12500\n"],"name":"stderr"},{"output_type":"stream","text":["step 12500\n","loss: 1.1893384456634521\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:44:12 - INFO - __main__ -   12550\n"],"name":"stderr"},{"output_type":"stream","text":["step 12550\n","loss: 1.4920133352279663\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:44:59 - INFO - __main__ -   12600\n"],"name":"stderr"},{"output_type":"stream","text":["step 12600\n","loss: 1.440382480621338\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:45:47 - INFO - __main__ -   12650\n"],"name":"stderr"},{"output_type":"stream","text":["step 12650\n","loss: 1.706345558166504\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:46:35 - INFO - __main__ -   12700\n"],"name":"stderr"},{"output_type":"stream","text":["step 12700\n","loss: 1.526829481124878\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:47:23 - INFO - __main__ -   12750\n"],"name":"stderr"},{"output_type":"stream","text":["step 12750\n","loss: 1.4537032842636108\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:48:11 - INFO - __main__ -   12800\n"],"name":"stderr"},{"output_type":"stream","text":["step 12800\n","loss: 1.694912314414978\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:48:59 - INFO - __main__ -   12850\n"],"name":"stderr"},{"output_type":"stream","text":["step 12850\n","loss: 1.4841151237487793\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:49:47 - INFO - __main__ -   12900\n"],"name":"stderr"},{"output_type":"stream","text":["step 12900\n","loss: 1.383191466331482\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:50:35 - INFO - __main__ -   12950\n"],"name":"stderr"},{"output_type":"stream","text":["step 12950\n","loss: 1.5022234916687012\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:51:23 - INFO - __main__ -   13000\n"],"name":"stderr"},{"output_type":"stream","text":["step 13000\n","loss: 1.6060587167739868\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:52:11 - INFO - __main__ -   13050\n"],"name":"stderr"},{"output_type":"stream","text":["step 13050\n","loss: 1.4431226253509521\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:52:59 - INFO - __main__ -   13100\n"],"name":"stderr"},{"output_type":"stream","text":["step 13100\n","loss: 1.5620230436325073\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:53:47 - INFO - __main__ -   13150\n"],"name":"stderr"},{"output_type":"stream","text":["step 13150\n","loss: 1.3512306213378906\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:54:35 - INFO - __main__ -   13200\n"],"name":"stderr"},{"output_type":"stream","text":["step 13200\n","loss: 1.4735885858535767\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:55:23 - INFO - __main__ -   13250\n"],"name":"stderr"},{"output_type":"stream","text":["step 13250\n","loss: 1.3485034704208374\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:56:11 - INFO - __main__ -   13300\n"],"name":"stderr"},{"output_type":"stream","text":["step 13300\n","loss: 1.5210505723953247\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:56:59 - INFO - __main__ -   13350\n"],"name":"stderr"},{"output_type":"stream","text":["step 13350\n","loss: 1.447261929512024\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:57:47 - INFO - __main__ -   13400\n"],"name":"stderr"},{"output_type":"stream","text":["step 13400\n","loss: 1.4423538446426392\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:58:35 - INFO - __main__ -   13450\n"],"name":"stderr"},{"output_type":"stream","text":["step 13450\n","loss: 1.4138914346694946\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 10:59:23 - INFO - __main__ -   13500\n"],"name":"stderr"},{"output_type":"stream","text":["step 13500\n","loss: 1.648573637008667\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:00:11 - INFO - __main__ -   13550\n"],"name":"stderr"},{"output_type":"stream","text":["step 13550\n","loss: 1.387486457824707\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:00:59 - INFO - __main__ -   13600\n"],"name":"stderr"},{"output_type":"stream","text":["step 13600\n","loss: 1.5171529054641724\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:01:46 - INFO - __main__ -   13650\n"],"name":"stderr"},{"output_type":"stream","text":["step 13650\n","loss: 1.484539270401001\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:02:34 - INFO - __main__ -   13700\n"],"name":"stderr"},{"output_type":"stream","text":["step 13700\n","loss: 1.5814356803894043\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:03:22 - INFO - __main__ -   13750\n"],"name":"stderr"},{"output_type":"stream","text":["step 13750\n","loss: 1.6532522439956665\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:04:10 - INFO - __main__ -   13800\n"],"name":"stderr"},{"output_type":"stream","text":["step 13800\n","loss: 1.6268820762634277\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:04:58 - INFO - __main__ -   13850\n"],"name":"stderr"},{"output_type":"stream","text":["step 13850\n","loss: 1.4754785299301147\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:05:46 - INFO - __main__ -   13900\n"],"name":"stderr"},{"output_type":"stream","text":["step 13900\n","loss: 1.455451488494873\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:06:34 - INFO - __main__ -   13950\n"],"name":"stderr"},{"output_type":"stream","text":["step 13950\n","loss: 1.428737759590149\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:07:22 - INFO - __main__ -   14000\n"],"name":"stderr"},{"output_type":"stream","text":["step 14000\n","loss: 1.355307936668396\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:08:10 - INFO - __main__ -   14050\n"],"name":"stderr"},{"output_type":"stream","text":["step 14050\n","loss: 1.1665492057800293\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:08:58 - INFO - __main__ -   14100\n"],"name":"stderr"},{"output_type":"stream","text":["step 14100\n","loss: 1.3483856916427612\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:09:46 - INFO - __main__ -   14150\n"],"name":"stderr"},{"output_type":"stream","text":["step 14150\n","loss: 1.5447713136672974\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:10:34 - INFO - __main__ -   14200\n"],"name":"stderr"},{"output_type":"stream","text":["step 14200\n","loss: 1.7094216346740723\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:11:22 - INFO - __main__ -   14250\n"],"name":"stderr"},{"output_type":"stream","text":["step 14250\n","loss: 1.5015138387680054\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:12:10 - INFO - __main__ -   14300\n"],"name":"stderr"},{"output_type":"stream","text":["step 14300\n","loss: 1.3805679082870483\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:12:58 - INFO - __main__ -   14350\n"],"name":"stderr"},{"output_type":"stream","text":["step 14350\n","loss: 1.466578722000122\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:13:46 - INFO - __main__ -   14400\n"],"name":"stderr"},{"output_type":"stream","text":["step 14400\n","loss: 1.3588790893554688\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:14:34 - INFO - __main__ -   14450\n"],"name":"stderr"},{"output_type":"stream","text":["step 14450\n","loss: 1.5473084449768066\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:15:22 - INFO - __main__ -   14500\n"],"name":"stderr"},{"output_type":"stream","text":["step 14500\n","loss: 1.4294360876083374\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:16:10 - INFO - __main__ -   14550\n"],"name":"stderr"},{"output_type":"stream","text":["step 14550\n","loss: 1.6209005117416382\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:16:58 - INFO - __main__ -   14600\n"],"name":"stderr"},{"output_type":"stream","text":["step 14600\n","loss: 1.3152073621749878\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:17:46 - INFO - __main__ -   14650\n"],"name":"stderr"},{"output_type":"stream","text":["step 14650\n","loss: 1.2990344762802124\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:18:34 - INFO - __main__ -   14700\n"],"name":"stderr"},{"output_type":"stream","text":["step 14700\n","loss: 1.4606621265411377\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:19:22 - INFO - __main__ -   14750\n"],"name":"stderr"},{"output_type":"stream","text":["step 14750\n","loss: 1.4718190431594849\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:20:10 - INFO - __main__ -   14800\n"],"name":"stderr"},{"output_type":"stream","text":["step 14800\n","loss: 1.4781756401062012\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:20:58 - INFO - __main__ -   14850\n"],"name":"stderr"},{"output_type":"stream","text":["step 14850\n","loss: 1.5070624351501465\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:21:46 - INFO - __main__ -   14900\n"],"name":"stderr"},{"output_type":"stream","text":["step 14900\n","loss: 1.5399551391601562\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:22:34 - INFO - __main__ -   14950\n"],"name":"stderr"},{"output_type":"stream","text":["step 14950\n","loss: 1.469338059425354\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:23:22 - INFO - __main__ -   15000\n"],"name":"stderr"},{"output_type":"stream","text":["step 15000\n","loss: 1.5754423141479492\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:24:10 - INFO - __main__ -   15050\n"],"name":"stderr"},{"output_type":"stream","text":["step 15050\n","loss: 1.3859189748764038\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:24:58 - INFO - __main__ -   15100\n"],"name":"stderr"},{"output_type":"stream","text":["step 15100\n","loss: 1.4367631673812866\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:25:46 - INFO - __main__ -   15150\n"],"name":"stderr"},{"output_type":"stream","text":["step 15150\n","loss: 1.366397500038147\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:26:34 - INFO - __main__ -   15200\n"],"name":"stderr"},{"output_type":"stream","text":["step 15200\n","loss: 1.442848801612854\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:27:22 - INFO - __main__ -   15250\n"],"name":"stderr"},{"output_type":"stream","text":["step 15250\n","loss: 1.2765806913375854\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:28:10 - INFO - __main__ -   15300\n"],"name":"stderr"},{"output_type":"stream","text":["step 15300\n","loss: 1.2035664319992065\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:28:58 - INFO - __main__ -   15350\n"],"name":"stderr"},{"output_type":"stream","text":["step 15350\n","loss: 1.5059105157852173\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:29:45 - INFO - __main__ -   15400\n"],"name":"stderr"},{"output_type":"stream","text":["step 15400\n","loss: 1.7530299425125122\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:30:33 - INFO - __main__ -   15450\n"],"name":"stderr"},{"output_type":"stream","text":["step 15450\n","loss: 1.4554792642593384\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:31:21 - INFO - __main__ -   15500\n"],"name":"stderr"},{"output_type":"stream","text":["step 15500\n","loss: 1.6701163053512573\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:32:09 - INFO - __main__ -   15550\n"],"name":"stderr"},{"output_type":"stream","text":["step 15550\n","loss: 1.4082597494125366\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:32:57 - INFO - __main__ -   15600\n"],"name":"stderr"},{"output_type":"stream","text":["step 15600\n","loss: 1.462084174156189\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:33:45 - INFO - __main__ -   15650\n"],"name":"stderr"},{"output_type":"stream","text":["step 15650\n","loss: 1.4992272853851318\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:34:33 - INFO - __main__ -   15700\n"],"name":"stderr"},{"output_type":"stream","text":["step 15700\n","loss: 1.4737046957015991\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:35:21 - INFO - __main__ -   15750\n"],"name":"stderr"},{"output_type":"stream","text":["step 15750\n","loss: 1.4487465620040894\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:36:09 - INFO - __main__ -   15800\n"],"name":"stderr"},{"output_type":"stream","text":["step 15800\n","loss: 1.3427149057388306\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:36:57 - INFO - __main__ -   15850\n"],"name":"stderr"},{"output_type":"stream","text":["step 15850\n","loss: 1.7240087985992432\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:37:45 - INFO - __main__ -   15900\n"],"name":"stderr"},{"output_type":"stream","text":["step 15900\n","loss: 1.429905652999878\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:38:33 - INFO - __main__ -   15950\n"],"name":"stderr"},{"output_type":"stream","text":["step 15950\n","loss: 1.446318507194519\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:39:21 - INFO - __main__ -   16000\n"],"name":"stderr"},{"output_type":"stream","text":["step 16000\n","loss: 1.4859726428985596\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:40:09 - INFO - __main__ -   16050\n"],"name":"stderr"},{"output_type":"stream","text":["step 16050\n","loss: 1.6006187200546265\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:40:57 - INFO - __main__ -   16100\n"],"name":"stderr"},{"output_type":"stream","text":["step 16100\n","loss: 1.5258055925369263\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:41:45 - INFO - __main__ -   16150\n"],"name":"stderr"},{"output_type":"stream","text":["step 16150\n","loss: 1.4926621913909912\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:42:33 - INFO - __main__ -   16200\n"],"name":"stderr"},{"output_type":"stream","text":["step 16200\n","loss: 1.5744696855545044\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:43:21 - INFO - __main__ -   16250\n"],"name":"stderr"},{"output_type":"stream","text":["step 16250\n","loss: 1.5637873411178589\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:44:09 - INFO - __main__ -   16300\n"],"name":"stderr"},{"output_type":"stream","text":["step 16300\n","loss: 1.4451794624328613\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:44:57 - INFO - __main__ -   16350\n"],"name":"stderr"},{"output_type":"stream","text":["step 16350\n","loss: 1.4904568195343018\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:45:45 - INFO - __main__ -   16400\n"],"name":"stderr"},{"output_type":"stream","text":["step 16400\n","loss: 1.662416934967041\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:46:33 - INFO - __main__ -   16450\n"],"name":"stderr"},{"output_type":"stream","text":["step 16450\n","loss: 1.2818437814712524\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:47:21 - INFO - __main__ -   16500\n"],"name":"stderr"},{"output_type":"stream","text":["step 16500\n","loss: 1.4043136835098267\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:48:08 - INFO - __main__ -   16550\n"],"name":"stderr"},{"output_type":"stream","text":["step 16550\n","loss: 1.686357855796814\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:48:56 - INFO - __main__ -   16600\n"],"name":"stderr"},{"output_type":"stream","text":["step 16600\n","loss: 1.4089306592941284\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:49:44 - INFO - __main__ -   16650\n"],"name":"stderr"},{"output_type":"stream","text":["step 16650\n","loss: 1.4889533519744873\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:50:32 - INFO - __main__ -   16700\n"],"name":"stderr"},{"output_type":"stream","text":["step 16700\n","loss: 1.3537969589233398\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:51:20 - INFO - __main__ -   16750\n"],"name":"stderr"},{"output_type":"stream","text":["step 16750\n","loss: 1.2431946992874146\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:52:08 - INFO - __main__ -   16800\n"],"name":"stderr"},{"output_type":"stream","text":["step 16800\n","loss: 1.3971370458602905\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:52:56 - INFO - __main__ -   16850\n"],"name":"stderr"},{"output_type":"stream","text":["step 16850\n","loss: 1.5197139978408813\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:53:44 - INFO - __main__ -   16900\n"],"name":"stderr"},{"output_type":"stream","text":["step 16900\n","loss: 1.6232695579528809\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:54:32 - INFO - __main__ -   16950\n"],"name":"stderr"},{"output_type":"stream","text":["step 16950\n","loss: 1.6014057397842407\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:55:20 - INFO - __main__ -   17000\n"],"name":"stderr"},{"output_type":"stream","text":["step 17000\n","loss: 1.4466235637664795\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:56:08 - INFO - __main__ -   17050\n"],"name":"stderr"},{"output_type":"stream","text":["step 17050\n","loss: 1.2999067306518555\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:56:56 - INFO - __main__ -   17100\n"],"name":"stderr"},{"output_type":"stream","text":["step 17100\n","loss: 1.4934182167053223\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:57:44 - INFO - __main__ -   17150\n"],"name":"stderr"},{"output_type":"stream","text":["step 17150\n","loss: 1.1892366409301758\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:58:32 - INFO - __main__ -   17200\n"],"name":"stderr"},{"output_type":"stream","text":["step 17200\n","loss: 1.1857709884643555\n"],"name":"stdout"},{"output_type":"stream","text":["05/27/2021 11:59:20 - INFO - __main__ -   17250\n"],"name":"stderr"},{"output_type":"stream","text":["step 17250\n","loss: 1.5437912940979004\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IXzoNYpwlYz0"},"source":["## evaluation"]},{"cell_type":"code","metadata":{"id":"FpKZFikiiyaE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622116794199,"user_tz":-60,"elapsed":16290,"user":{"displayName":"Keyue Jiang","photoUrl":"","userId":"10513797217442927849"}},"outputId":"d7dc952f-8183-4d82-eaff-ba05f2afeacf"},"source":["model = mybart\n","model_class = BartForCausalLM\n","tokenizer_class = BartTokenizer\n","save_model(args,model,tokenizer,model_class,tokenizer_class)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["05/27/2021 11:59:36 - INFO - __main__ -   Saving model checkpoint to ./gdrive/MyDrive/COMP0087/BartGru_CP_350k\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"mks92fFx8vfS"},"source":["# model = BartForCausalLM.from_pretrained(args.output_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oa-gH4egxBBD"},"source":["def evaluate(args, model, tokenizer, prefix=\"\"):\n","    # Loop to handle MNLI double evaluation (matched, mis-matched)\n","    eval_output_dir = args.output_dir\n","\n","    eval_dataset = load_and_cache_examples(args, tokenizer, evaluate=True)\n","\n","    if not os.path.exists(eval_output_dir):\n","        os.makedirs(eval_output_dir)\n","\n","    args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n","    # Note that DistributedSampler samples randomly\n","    eval_sampler = SequentialSampler(eval_dataset)\n","    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size)\n","\n","    # Eval!\n","    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n","    logger.info(\"  Num examples = %d\", len(eval_dataset))\n","    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n","    eval_loss = 0.0\n","    nb_eval_steps = 0\n","    model.eval()\n","\n","    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n","        batch = batch.to(args.device)\n","\n","        with torch.no_grad():\n","            outputs = model(batch, labels=batch)\n","            lm_loss = outputs[0]\n","            eval_loss += lm_loss.mean().item()\n","        nb_eval_steps += 1\n","\n","    eval_loss = eval_loss / nb_eval_steps\n","    perplexity = torch.exp(torch.tensor(eval_loss))\n","\n","    result = {\n","        \"perplexity\": perplexity\n","    }\n","\n","    output_eval_file = os.path.join(eval_output_dir, \"eval_results.txt\")\n","    with open(output_eval_file, \"w\") as writer:\n","        logger.info(\"***** Eval results {} *****\".format(prefix))\n","        for key in sorted(result.keys()):\n","            logger.info(\"  %s = %s\", key, str(result[key]))\n","            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n","\n","    return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tvYkcy_EmF_M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622116796903,"user_tz":-60,"elapsed":2710,"user":{"displayName":"Keyue Jiang","photoUrl":"","userId":"10513797217442927849"}},"outputId":"ddb936c1-b9e9-4d0c-9c3c-3eca9e56dfff"},"source":["# Evaluation\n","results = {}\n","checkpoints = [args.output_dir]\n","if args.eval_all_checkpoints:\n","  checkpoints = list(os.path.dirname(c) for c in sorted(glob.glob(args.output_dir + '/**/' + WEIGHTS_NAME, recursive=True)))\n","  logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n","logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n","for checkpoint in checkpoints:\n","  global_step = checkpoint.split('-')[-1] if len(checkpoints) > 1 else \"\"\n","  model_class = BartForCausalLM#BartForConditionalGeneration#GPT2LMHeadModel # BartForCausalLM\n","  model = model_class.from_pretrained(checkpoint)\n","  model.to(args.device)\n","  result = evaluate(args, model, tokenizer, prefix=global_step)\n","  result = dict((k + '_{}'.format(global_step), v) for k, v in result.items())\n","  results.update(result)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["05/27/2021 11:59:53 - INFO - __main__ -   Evaluate the following checkpoints: ['./gdrive/MyDrive/COMP0087/BartGru_CP_350k']\n","05/27/2021 11:59:54 - INFO - __main__ -   Loading features from cached file unsupervised.h5\n","05/27/2021 11:59:54 - INFO - __main__ -   ***** Running evaluation  *****\n","05/27/2021 11:59:54 - INFO - __main__ -     Num examples = 27\n","05/27/2021 11:59:54 - INFO - __main__ -     Batch size = 4\n","Evaluating:  14%|█▍        | 1/7 [00:00<00:00,  6.53it/s]"],"name":"stderr"},{"output_type":"stream","text":["tensor([[    0, 50273, 50275,  ..., 50274, 50274, 50274],\n","        [    0, 50273, 50275,  ..., 50274, 50274, 50274],\n","        [    0, 50273, 50275,  ..., 50274, 50274, 50274],\n","        [    0, 50273, 50275,  ..., 50274, 50274, 50274],\n","        [    0, 50273, 50275,  ..., 50274, 50274, 50274]])\n"],"name":"stdout"},{"output_type":"stream","text":["Evaluating: 100%|██████████| 7/7 [00:00<00:00,  7.27it/s]\n","05/27/2021 11:59:56 - INFO - __main__ -   ***** Eval results  *****\n","05/27/2021 11:59:56 - INFO - __main__ -     perplexity = tensor(8983.8066)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"MXpDix2yd3lB"},"source":["# generation"]},{"cell_type":"code","metadata":{"id":"yX9UqNILeAvK"},"source":["#model loading\n","#tokenizer = AutoTokenizer.from_pretrained(\"mbien/recipenlg\")\n","#model = AutoModelWithLMHead.from_pretrained(\"mbien/recipenlg\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MPi6Xwt5GrvO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622116796904,"user_tz":-60,"elapsed":12,"user":{"displayName":"Keyue Jiang","photoUrl":"","userId":"10513797217442927849"}},"outputId":"39f980f0-96e3-47e8-9ecc-1201f9a3be6a"},"source":["raw_text = 'tomato,egg'\n","prepared_input = ' <RECIPE_START> <INPUT_START> ' + raw_text.replace(',', ' <NEXT_INPUT> ').replace(';', ' <INPUT_END>')\n","tokenizer.encode(prepared_input)[0:-1]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0, 50273, 50275, 33063, 3938, 50277, 38299]"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"b8ea0cb0AdLu"},"source":["#new_model = BartForCausalLM.from_pretrained(args.output_dir)\n","#new_tokenizer = BartTokenizer.from_pretrained(args.output_dir)\n","#new_model = GPT2LMHeadModel.from_pretrained(args.output_dir)\n","#new_tokenizer = GPT2LMHeadModel.from_pretrained(args.output_dir)\n","#new_model = BartForConditionalGeneration.from_pretrained(args.output_dir)\n","#new_tokenizer= BartForConditionalGeneration.from_pretrained(args.output_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ofrfJDXw_iqf"},"source":["def set_seed(args):\n","    np.random.seed(args.seed)\n","    torch.manual_seed(args.seed)\n","    if args.n_gpu > 0:\n","        torch.cuda.manual_seed_all(args.seed)\n","\n","\n","def top_k_top_p_filtering(logits, top_k=0, top_p=0.0, filter_value=-float('Inf')):\n","    \"\"\" Filter a distribution of logits using top-k and/or nucleus (top-p) filtering\n","        Args:\n","            logits: logits distribution shape (vocabulary size)\n","            top_k > 0: keep only top k tokens with highest probability (top-k filtering).\n","            top_p > 0.0: keep the top tokens with cumulative probability >= top_p (nucleus filtering).\n","                Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)\n","        From: https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317\n","    \"\"\"\n","    assert logits.dim() == 1  # batch size 1 for now - could be updated for more but the code would be less clear\n","    top_k = min(top_k, logits.size(-1))  # Safety check\n","    if top_k > 0:\n","        # Remove all tokens with a probability less than the last token of the top-k\n","        indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n","        logits[indices_to_remove] = filter_value\n","\n","    if top_p > 0.0:\n","        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n","        cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n","\n","        # Remove tokens with cumulative probability above the threshold\n","        sorted_indices_to_remove = cumulative_probs > top_p\n","        # Shift the indices to the right to keep also the first token above the threshold\n","        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n","        sorted_indices_to_remove[..., 0] = 0\n","\n","        indices_to_remove = sorted_indices[sorted_indices_to_remove]\n","        logits[indices_to_remove] = filter_value\n","    return logits\n","\n","\n","def sample_sequence(model, length, context, tokenizer, num_samples=1, temperature=1, top_k=0, top_p=0.0, device='cpu'):\n","    end_token = tokenizer.convert_tokens_to_ids([\"<RECIPE_END>\"])[0]\n","    context = torch.tensor(context, dtype=torch.long, device=device)\n","    context = context.unsqueeze(0).repeat(num_samples, 1)\n","    generated = context\n","    with torch.no_grad():\n","        for _ in range(length):\n","            inputs = {'input_ids': generated}\n","            outputs = model(**inputs)  # Note: we could also use 'past' with GPT-2/Transfo-XL/XLNet (cached hidden-states)\n","            # print(outputs)\n","            next_token_logits = outputs[\"logits\"][0, -1, :] / temperature\n","            \n","            filtered_logits = top_k_top_p_filtering(next_token_logits, top_k=top_k, top_p=top_p)\n","            next_token = torch.multinomial(F.softmax(filtered_logits, dim=-1), num_samples=1)\n","            generated = torch.cat((generated, next_token.unsqueeze(0)), dim=1)\n","            #print(next_token)\n","            if next_token.item() == end_token:\n","                break\n","    return generated"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r74JE5TVjNNx"},"source":["model = BartForCausalLM.from_pretrained(args.output_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z6VNmuOzd4vW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622116799755,"user_tz":-60,"elapsed":754,"user":{"displayName":"Keyue Jiang","photoUrl":"","userId":"10513797217442927849"}},"outputId":"8303e24c-1666-4fdb-e3ed-278095100e4f"},"source":["# raw_text = args.prompt if args.prompt else input(\"Comma-separated ingredients, semicolon to close the list >>> \")\n","model.to(\"cuda\")\n","raw_text = 'potato;'\n","\n","prepared_input = ' <RECIPE_START> <INPUT_START> ' + raw_text.replace(',', ' <NEXT_INPUT> ').replace(';', ' <INPUT_END>')\n","context_tokens = tokenizer.encode(prepared_input)[0:-1]\n","out = sample_sequence(\n","            model=model,\n","            context=context_tokens,\n","            tokenizer=tokenizer,\n","            length=512,\n","            device = \"cuda\"\n","        )\n","out = out[0, len(context_tokens):].tolist()\n","text = tokenizer.decode(out, clean_up_tokenization_spaces=True)\n","if \"<RECIPE_END>\" not in text:\n","  print(text)\n","  print(\"Failed to generate, recipe's too long\")\n","  full_text = prepared_input + text\n","  print(full_text)\n","else:\n","  full_text = prepared_input + text\n","  print(full_text)\n","  markdown = re.sub(\"<RECIPE_(START|END)>\", \"\", full_text)\n","  recipe_n_title = markdown.split(\"<TITLE_START>\")\n","  title = \"# \" + recipe_n_title[1].replace(\"<TITLE_END>\", \"\") + \" #\\n\"\n","  markdown = recipe_n_title[0].replace(\"<INPUT_START>\", \"## Input ingredients ##\\n`\").replace(\"<INPUT_END>\", \"`\\n\")\n","  markdown = markdown.replace(\"<NEXT_INPUT>\", \"`\\n`\").replace(\"<INGR_START>\", \"## Ingredients ##\\n* \").replace(\"<NEXT_INGR>\", \"\\n* \").replace(\"<INGR_END>\", \"\\n\")\n","  markdown = markdown.replace(\"<INSTR_START>\", \"## Instructions ##\\n1) \").replace(\"<NEXT_INSTR>\", \"\\n1) \").replace(\"<INSTR_END>\", \"\\n\")\n","  markdown = re.sub(\"$ +#\", \"#\", markdown)\n","  markdown = re.sub(\"( +`|` +)\", \"`\", markdown)\n","  print(title+markdown)#\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" <RECIPE_START> <INPUT_START> potato <INPUT_END><INGR_START> 1 large potato (about 4 cups) or 1 large apple (about 4 cups) <INGR_END> <INSTR_START> Place potatoes in large, deep casserole dish and cover with hot water as you want. Pour boiling water over potatoes and bake in 350F oven until fork-tender, about 25 to 30 minutes. Microwave sweet potato in boiling water until fork-tender, about 5 minutes. Slice into 1 inch cubes. Knead, folding jelly beans above potatoes, allowing enough steam to escape then transfer potato gelatin to bowl with mashed potatoes (leave skin on). <NEXT_INSTR> Drain cooked potato slices on paper towels. Slice into wedges about 1/4 inch thick with sharp knife, and place on microwave-safe plate. Add boiling water to eggs, and cook until eggs are set. Drain, return to microwave, and rinse. <INSTR_END> <TITLE_START> Potato And Sweet Potato Dip <TITLE_END> <RECIPE_END>\n","#  Potato And Sweet Potato Dip   #\n","  ## Input ingredients ##\n","`potato`\n","## Ingredients ##\n","*  1 large potato (about 4 cups) or 1 large apple (about 4 cups) \n"," ## Instructions ##\n","1)  Place potatoes in large, deep casserole dish and cover with hot water as you want. Pour boiling water over potatoes and bake in 350F oven until fork-tender, about 25 to 30 minutes. Microwave sweet potato in boiling water until fork-tender, about 5 minutes. Slice into 1 inch cubes. Knead, folding jelly beans above potatoes, allowing enough steam to escape then transfer potato gelatin to bowl with mashed potatoes (leave skin on). \n","1)  Drain cooked potato slices on paper towels. Slice into wedges about 1/4 inch thick with sharp knife, and place on microwave-safe plate. Add boiling water to eggs, and cook until eggs are set. Drain, return to microwave, and rinse. \n"," \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9KoPaCB2vVej"},"source":["# gold standard\n","#df_eval = gold_st\n","model.to(args.device)\n","test_input = test.reset_index()\n","df_eval_ner = test_input[\"NER\"]  #NER\n","df_eval_dir = test_input[\"directions\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TY78AVj4vcEU"},"source":["def get_raw_input(NER):\n","    test_str = NER\n","    test_str = test_str.replace(\"[\",\"\")\n","    test_str = test_str.replace(\"]\",\"\")\n","    test_str = test_str.replace(\"\\\"\",\"\")\n","\n","    return test_str\n","\n","def get_instr(markdown):\n","  markdown = markdown.split(\"\\n\")\n","  if ' ## Instructions ##' in markdown:\n","    instr_index = markdown.index(' ## Instructions ##')\n","    \n","    output = [i for i in markdown[instr_index+1:]]\n","\n","    if \" \" in output:\n","        output.remove(\" \")\n","\n","    if \"\" in output:\n","        output.remove(\"\")    \n","    \n","    return output\n","\n","  elif '## Instructions ##' in markdown:\n","    instr_index = markdown.index('## Instructions ##')\n","\n","    output = [i for i in markdown[instr_index+1:]]\n","\n","    if \" \" in output:\n","        output.remove(\" \")\n","        \n","    if \"\" in output:\n","        output.remove(\"\")    \n","\n","    return output\n","    \n","  else:\n","    return [\"failed to generate\"]\n","\n","\n","def generate_recipe(raw_text):\n","\n","    prepared_input = ' <RECIPE_START> <INPUT_START> ' + raw_text.replace(',', ' <NEXT_INPUT> ').replace(';', ' <INPUT_END>')\n","    context_tokens = tokenizer.encode(prepared_input)[0:-1]\n","    out = sample_sequence(\n","                model=model,\n","                context=context_tokens,\n","                tokenizer=tokenizer,\n","                length=800,\n","                device = args.device\n","            )\n","    out = out[0, len(context_tokens):].tolist()\n","    text = tokenizer.decode(out, clean_up_tokenization_spaces=True)\n","    if \"<RECIPE_END>\" not in text:\n","      # print(text)\n","      print(\"Failed to generate, recipe's too long\")\n","      full_text = prepared_input + text\n","      # print(full_text)\n","      return generate_recipe(raw_text)\n","    else:\n","      full_text = prepared_input + text\n","      # print(full_text)\n","      markdown = re.sub(\"<RECIPE_(START|END)>\", \"\", full_text)\n","      recipe_n_title = markdown.split(\"<TITLE_START>\")\n","      if len(recipe_n_title)<=1:\n","        return generate_recipe(raw_text)\n","      title = \"# \" + recipe_n_title[1].replace(\"<TITLE_END>\", \"\") + \" #\\n\"\n","      markdown = recipe_n_title[0].replace(\"<INPUT_START>\", \"## Input ingredients ##\\n`\").replace(\"<INPUT_END>\", \"`\\n\")\n","      markdown = markdown.replace(\"<NEXT_INPUT>\", \"`\\n`\").replace(\"<INGR_START>\", \"## Ingredients ##\\n* \").replace(\"<NEXT_INGR>\", \"\\n* \").replace(\"<INGR_END>\", \"\\n\")\n","      #markdown = markdown.replace(\"<INSTR_START>\", \"## Instructions ##\\n\\\"\").replace(\"<NEXT_INSTR>\", \"\\n\\\"\").replace(\"<INSTR_END>\", \"\\n\")\n","      markdown = markdown.replace(\"<INSTR_START>\", \"## Instructions ##\\n\").replace(\"<NEXT_INSTR>\", \"\\n\").replace(\"<INSTR_END>\", \"\\n\")\n","      markdown = re.sub(\"$ +#\", \"#\", markdown)\n","      markdown = re.sub(\"( +`|` +)\", \"`\", markdown)\n","  \n","      return markdown"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h84dStu7vegL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622124963160,"user_tz":-60,"elapsed":6,"user":{"displayName":"Keyue Jiang","photoUrl":"","userId":"10513797217442927849"}},"outputId":"d0ff824c-dda8-4538-8685-3c6b3a4e92c4"},"source":["df_eval_dir"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0     [\"Arrange a layer of biscuits at the bottom of...\n","1     [\"Mix cake mix, sour cream, oil and eggs toget...\n","2     [\"Bring a pot of salted water to a boil.\", \"Ad...\n","3     [\"Make \\\"Peanut Butter and Banana\\\" Sandwiches...\n","4     [\"Place the chicken in a bowl and combine with...\n","                            ...                        \n","95    [\"Preheat oven to 400 degrees, prepare pans.\",...\n","96    [\"Add all ingredients in order specified in ma...\n","97    [\"Place fish in the bottom of a 7 X 11 inch ca...\n","98    [\"Clean the trout.\", \"The incision in the bell...\n","99    [\"Sift flour, baking powder and salt together....\n","Name: directions, Length: 100, dtype: object"]},"metadata":{"tags":[]},"execution_count":78}]},{"cell_type":"code","metadata":{"id":"-w_xrYOqvgkE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622127374661,"user_tz":-60,"elapsed":2404896,"user":{"displayName":"Keyue Jiang","photoUrl":"","userId":"10513797217442927849"}},"outputId":"464af3e2-4894-440d-b152-9cc97a635062"},"source":["torch.manual_seed(1)\n","# generate recipes derived from gold standard ones\n","test_size = 100\n","replicated_size = 10\n","directions =  [[] for i in range(test_size)]\n","\n","for i in range(test_size):\n","  raw_text = get_raw_input(df_eval_ner[i])\n","  print(\"\\n Generating the recipe: \",i)\n","\n","  for j in range(replicated_size):\n","    print(\"recipe: \",j)\n","    md = generate_recipe(raw_text)\n","    directions[i].append(get_instr(md))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n"," Generating the recipe:  0\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  1\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  2\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  3\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  4\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  5\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  6\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  7\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  8\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","Failed to generate, recipe's too long\n","\n"," Generating the recipe:  9\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  10\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  11\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","Failed to generate, recipe's too long\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  12\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","Failed to generate, recipe's too long\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  13\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  14\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  15\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  16\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  17\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  18\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  19\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  20\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  21\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  22\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  23\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","Failed to generate, recipe's too long\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","Failed to generate, recipe's too long\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  24\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  25\n","recipe:  0\n","recipe:  1\n","Failed to generate, recipe's too long\n","recipe:  2\n","Failed to generate, recipe's too long\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  26\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","Failed to generate, recipe's too long\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  27\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  28\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  29\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  30\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  31\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  32\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  33\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  34\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  35\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  36\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","Failed to generate, recipe's too long\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  37\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  38\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","Failed to generate, recipe's too long\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  39\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  40\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  41\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  42\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  43\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  44\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  45\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  46\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  47\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  48\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  49\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  50\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  51\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  52\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  53\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  54\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","Failed to generate, recipe's too long\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  55\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  56\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  57\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  58\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  59\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  60\n","recipe:  0\n","recipe:  1\n","Failed to generate, recipe's too long\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  61\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","Failed to generate, recipe's too long\n","recipe:  3\n","Failed to generate, recipe's too long\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","Failed to generate, recipe's too long\n","recipe:  7\n","Failed to generate, recipe's too long\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  62\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  63\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  64\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  65\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","Failed to generate, recipe's too long\n","recipe:  9\n","\n"," Generating the recipe:  66\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  67\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  68\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  69\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  70\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  71\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  72\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  73\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  74\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  75\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  76\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  77\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  78\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  79\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  80\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  81\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  82\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  83\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  84\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  85\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  86\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  87\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  88\n","recipe:  0\n","recipe:  1\n","Failed to generate, recipe's too long\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  89\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  90\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  91\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  92\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  93\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  94\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  95\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  96\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  97\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  98\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n","\n"," Generating the recipe:  99\n","recipe:  0\n","recipe:  1\n","recipe:  2\n","recipe:  3\n","recipe:  4\n","recipe:  5\n","recipe:  6\n","recipe:  7\n","recipe:  8\n","recipe:  9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fY7IJP1tvtDY"},"source":["#func of cos_sim\n","import re\n","import math\n","from collections import Counter\n","\n","\n","def get_cosine(vec1, vec2):\n","    intersection = set(vec1.keys()) & set(vec2.keys())\n","    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n","\n","    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n","    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n","    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n","\n","    if not denominator:\n","        return 0.0\n","    else:\n","        return float(numerator) / denominator\n","\n","\n","def text_to_vector(text):\n","    word = re.compile(r'\\w+')\n","    words = word.findall(text)\n","    return Counter(words)\n","\n","\n","def get_result(content_a, content_b):\n","    text1 = content_a\n","    text2 = content_b\n","\n","    vector1 = text_to_vector(text1)\n","    vector2 = text_to_vector(text2)\n","\n","    cosine_result = get_cosine(vector1, vector2)\n","    return cosine_result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RA6mX6-bvzes"},"source":["#cosine_similarity\n","\n","def COS_SIM(df_eval_dir,directions):\n","  \"\"\"\n","  df_eval_dir := gold_standard recipes\n","  directions  := corresponding recipes \"\"\"\n","\n","  avg = 0\n","\n","  for i in range(len(directions)):\n","    best = 0\n","    for j in range(len(directions[i])):\n","      cos = get_result(\" \".join(eval(df_eval_dir[i])),\n","                      \" \".join(directions[i][j]))\n","      best = max(best, cos)\n","\n","    avg += best\n","\n","  avg = avg/len(directions)\n","\n","  print(\"avg:\", avg)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d8nbUd8qvzqd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622127374666,"user_tz":-60,"elapsed":12,"user":{"displayName":"Keyue Jiang","photoUrl":"","userId":"10513797217442927849"}},"outputId":"5d0d2fa5-7466-4790-c904-0f6abca8ea19"},"source":["COS_SIM(df_eval_dir,directions)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["avg: 0.5447834709231942\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ASj6tFpXv4MZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622127379495,"user_tz":-60,"elapsed":4837,"user":{"displayName":"Keyue Jiang","photoUrl":"","userId":"10513797217442927849"}},"outputId":"7488d7c3-0cd1-4374-f22d-8a5bf66afc80"},"source":["!pip install jiwer==2.2.0\n","!pip install -U nltk"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: jiwer==2.2.0 in /usr/local/lib/python3.7/dist-packages (2.2.0)\n","Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.7/dist-packages (from jiwer==2.2.0) (0.12.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from jiwer==2.2.0) (1.19.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein->jiwer==2.2.0) (56.1.0)\n","Requirement already up-to-date: nltk in /usr/local/lib/python3.7/dist-packages (3.6.2)\n","Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.7/dist-packages (from nltk) (2019.12.20)\n","Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.41.1)\n","Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n","Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.0.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BhmPW8Jvv4Oq"},"source":["import nltk\n","import nltk.translate.bleu_score as bleu\n","from nltk.translate.bleu_score import SmoothingFunction\n","\n","import nltk.translate.gleu_score as gleu\n","import nltk.translate.meteor_score as meteor"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"39CPJFonv4SC"},"source":["# Helper Func.\n","def list_to_words(recipe):\n","  words = []\n","  for i in recipe:\n","    words += i.split()\n","\n","  return words\n","\n","# New BLEU/GLEU\n","def bleu_score(recipe, refer):\n","    hyp = list_to_words(eval(recipe))\n","    refs = []\n","    for i in refer:\n","        # print(list_to_words(i))\n","        refs.append(list_to_words(i))\n","\n","    smoothie = SmoothingFunction().method5\n","    score_ref_a = bleu.sentence_bleu(refs, hyp, smoothing_function=smoothie, weights=(1,0,0,0))\n","    return score_ref_a\n","\n","def gleu_score(recipe, refer):\n","    hyp = list_to_words(eval(recipe))\n","    refs = []\n","    for i in refer:\n","        refs.append(list_to_words(i))\n","\n","    score_ref_a = gleu.sentence_gleu(refs, hyp)\n","    return score_ref_a"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IjOFqH23v4Um","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622127379930,"user_tz":-60,"elapsed":438,"user":{"displayName":"Keyue Jiang","photoUrl":"","userId":"10513797217442927849"}},"outputId":"3c915e72-0926-47fb-af9e-d85a3d74ee10"},"source":["bleu_avg = []\n","gleu_avg = []\n","\n","for i in range(len(directions)):\n","  # print(bleu_score(df_eval_dir[i], directions[i]))\n","  bleu_avg.append(bleu_score(df_eval_dir[i], directions[i]))\n","\n","for i in range(len(directions)):\n","  gleu_avg.append(gleu_score(df_eval_dir[i], directions[i]))\n","print(np.mean(bleu_avg))\n","print(np.mean(gleu_avg))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.7804978214716344\n","0.09278317921499697\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PFxAgVNc0zOO"},"source":[""],"execution_count":null,"outputs":[]}]}