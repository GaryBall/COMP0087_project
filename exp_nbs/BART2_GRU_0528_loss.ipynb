{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BART2_CDM_0528_loss.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f17bca08e8944c50bd881858e5069a48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3c258992b77c4b1385f814a17906940e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0f1592204d7d47338f31d7cf76f8312f",
              "IPY_MODEL_c437a7d8ea424f51b11515d697b404ef"
            ]
          }
        },
        "3c258992b77c4b1385f814a17906940e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f1592204d7d47338f31d7cf76f8312f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8c7c9318ada641368ac95da2e422a9c8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9f680ff84d6343579c25bf0dbe413639"
          }
        },
        "c437a7d8ea424f51b11515d697b404ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3c70adccee1e4ab9afaec73f4cb13e32",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:01&lt;00:00, 494kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cd66650853eb43be956d8b4f39e6bbe6"
          }
        },
        "8c7c9318ada641368ac95da2e422a9c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9f680ff84d6343579c25bf0dbe413639": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c70adccee1e4ab9afaec73f4cb13e32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cd66650853eb43be956d8b4f39e6bbe6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7316f30992ab488f8bb955d61a842644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_00521e72d0f74c3cb2239046f67224d2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_08421bef70544c8c9ef217ac49cfa897",
              "IPY_MODEL_d174c701e29e42cd96e6b6c1f5871773"
            ]
          }
        },
        "00521e72d0f74c3cb2239046f67224d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08421bef70544c8c9ef217ac49cfa897": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bac54a5036a64f11803654a5d6988a06",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_87141aec1727497a9b15c01b2cf5ae18"
          }
        },
        "d174c701e29e42cd96e6b6c1f5871773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_22b6d6e8e7294e94813f8b1d97c432a4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:04&lt;00:00, 96.9kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4fc50e32bebf41a7b1b9b2fb6f2a56dd"
          }
        },
        "bac54a5036a64f11803654a5d6988a06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "87141aec1727497a9b15c01b2cf5ae18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "22b6d6e8e7294e94813f8b1d97c432a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4fc50e32bebf41a7b1b9b2fb6f2a56dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "319b3dd7e4f94d7596e1d512a9eff1cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a9fe2bc59af441878bda2e7c78d288cf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c139a51b70ad42edb36e77f80ed14550",
              "IPY_MODEL_bb83a0eb06744ee2a02e9f4e638acd8f"
            ]
          }
        },
        "a9fe2bc59af441878bda2e7c78d288cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c139a51b70ad42edb36e77f80ed14550": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1dc8f4700a8e4dd2b90e11034543dd0d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1355863,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1355863,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e2c04b3835e4b72ad49c00f0c29588b"
          }
        },
        "bb83a0eb06744ee2a02e9f4e638acd8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_42c28e6548d541d9822a90fb5e07ba64",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 1.83MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ca65089b4ef94cf881f9bd83e0948e31"
          }
        },
        "1dc8f4700a8e4dd2b90e11034543dd0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e2c04b3835e4b72ad49c00f0c29588b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "42c28e6548d541d9822a90fb5e07ba64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ca65089b4ef94cf881f9bd83e0948e31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f80a3b9dd744b78ae017678f1d91ad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2aecbaa837894f638b007ac92cef2636",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_23bd9134d6744c39b354bd4677316ae7",
              "IPY_MODEL_71cb13b9fdc34d06b408fcdc03466db5"
            ]
          }
        },
        "2aecbaa837894f638b007ac92cef2636": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "23bd9134d6744c39b354bd4677316ae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c1c7c32024224094b05bc8b2ac1aa2c2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1553,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1553,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_12cf0a1350bd4a2aa559049e88cb5dd1"
          }
        },
        "71cb13b9fdc34d06b408fcdc03466db5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8bbd9473079a40cc832dab20acc1b744",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.55k/1.55k [00:00&lt;00:00, 3.31kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b8f8532d77cb43a4b9586f35e07572f2"
          }
        },
        "c1c7c32024224094b05bc8b2ac1aa2c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "12cf0a1350bd4a2aa559049e88cb5dd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8bbd9473079a40cc832dab20acc1b744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b8f8532d77cb43a4b9586f35e07572f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "853f30bd4fa54d63988e864d29a7885b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4d5873c3b6a445b4869b4181a8f3dfd7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0957ce4e345047c8b0d4ccff3b0d4008",
              "IPY_MODEL_ad5103df3778474ea89c0424e1ac8955"
            ]
          }
        },
        "4d5873c3b6a445b4869b4181a8f3dfd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0957ce4e345047c8b0d4ccff3b0d4008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_152d0a39007f4241a5109f2722043b16",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 557941479,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 557941479,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1060d389b60b4a0b8446aa6bc4e8387e"
          }
        },
        "ad5103df3778474ea89c0424e1ac8955": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9af798dc82cf4290b542c12027c4c040",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 558M/558M [00:10&lt;00:00, 53.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d2055c700db943908d16c97b872ea8a9"
          }
        },
        "152d0a39007f4241a5109f2722043b16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1060d389b60b4a0b8446aa6bc4e8387e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9af798dc82cf4290b542c12027c4c040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d2055c700db943908d16c97b872ea8a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbExY_ckafyP"
      },
      "source": [
        "# Necessary environment setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUgPv0jXacc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f4241b8-78f0-4272-f09d-0c22960734ae"
      },
      "source": [
        "# Divine beast bless no bug here! \n",
        "#         ┌─┐    ┌─┐\n",
        "#      ┌─┘ ┴───┘ ┴──┐\n",
        "#      │                   │\n",
        "#      │       ───       │\n",
        "#      │  ─┬┘     └┬─  │\n",
        "#      │                   │\n",
        "#      │       ─┴─       │\n",
        "#      │                   │\n",
        "#      └─┐         ┌───┘\n",
        "#          │         │\n",
        "#          │         │\n",
        "#          │         │\n",
        "#          │         └──────────────┐\n",
        "#          │                                  │\n",
        "#          │                                  ├─┐\n",
        "#          │                                  ┌─┘\n",
        "#          │                                  │\n",
        "#          └─┐  ┐  ┌──────┬──┐  ┌──┘\n",
        "#            │  ─┤ ─┤         │  ─┤ ─┤\n",
        "#            └──┴──┘         └──┴──┘\n",
        "\n",
        "!pip install transformers\n",
        "!pip install boto3\n",
        "!git clone https://github.com/NVIDIA/apex\n",
        "!pip install jiwer==2.2.0\n",
        "!pip install -U nltk\n",
        "%cd apex\n",
        "!pip install -v --no-cache-dir ./\n",
        "%cd .. \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 19.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 33.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/20/4294e37c3c6936c905f1e9da958c776d7fee54a4512bdb7706d69c8720e6/boto3-1.17.84-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 3.0MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 6.9MB/s \n",
            "\u001b[?25hCollecting botocore<1.21.0,>=1.20.84\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/22/72c81d754bbcb128cba2ad88670c3c320e4594e6ddd8cca6512c3967108c/botocore-1.20.84-py2.py3-none-any.whl (7.6MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6MB 12.0MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.84->boto3) (2.8.1)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/cd/1e2ec680ec7b09846dc6e605f5a7709dfb9d7128e51a026e7154e18a234e/urllib3-1.26.5-py2.py3-none-any.whl (138kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 50.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.84->boto3) (1.15.0)\n",
            "\u001b[31mERROR: requests 2.23.0 has requirement urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you'll have urllib3 1.26.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3\n",
            "  Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed boto3-1.17.84 botocore-1.20.84 jmespath-0.10.0 s3transfer-0.4.2 urllib3-1.26.5\n",
            "Cloning into 'apex'...\n",
            "remote: Enumerating objects: 8048, done.\u001b[K\n",
            "remote: Counting objects: 100% (135/135), done.\u001b[K\n",
            "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
            "remote: Total 8048 (delta 65), reused 97 (delta 44), pack-reused 7913\u001b[K\n",
            "Receiving objects: 100% (8048/8048), 14.11 MiB | 18.67 MiB/s, done.\n",
            "Resolving deltas: 100% (5464/5464), done.\n",
            "Collecting jiwer==2.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8c/cc/fb9d3132cba1f6d393b7d5a9398d9d4c8fc033bc54668cf87e9b197a6d7a/jiwer-2.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from jiwer==2.2.0) (1.19.5)\n",
            "Collecting python-Levenshtein\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/dc/97f2b63ef0fa1fd78dcb7195aca577804f6b2b51e712516cc0e902a9a201/python-Levenshtein-0.12.2.tar.gz (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 1.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein->jiwer==2.2.0) (56.1.0)\n",
            "Building wheels for collected packages: python-Levenshtein\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149811 sha256=065baa0907edce294245d5800c7b1f86ebdaaf16360878905d0ec2e63c677d61\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/26/73/4b48503bac73f01cf18e52cd250947049a7f339e940c5df8fc\n",
            "Successfully built python-Levenshtein\n",
            "Installing collected packages: python-Levenshtein, jiwer\n",
            "Successfully installed jiwer-2.2.0 python-Levenshtein-0.12.2\n",
            "Collecting nltk\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/37/9532ddd4b1bbb619333d5708aaad9bf1742f051a664c3c6fa6632a105fd8/nltk-3.6.2-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.7/dist-packages (from nltk) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Installing collected packages: nltk\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed nltk-3.6.2\n",
            "/content/apex\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-aqfjwfv7\n",
            "Created temporary directory: /tmp/pip-req-tracker-3rvsto29\n",
            "Created requirements tracker '/tmp/pip-req-tracker-3rvsto29'\n",
            "Created temporary directory: /tmp/pip-install-n0vgoirv\n",
            "Processing /content/apex\n",
            "  Created temporary directory: /tmp/pip-req-build-hx5ewj1q\n",
            "  Added file:///content/apex to build tracker '/tmp/pip-req-tracker-3rvsto29'\n",
            "    Running setup.py (path:/tmp/pip-req-build-hx5ewj1q/setup.py) egg_info for package from file:///content/apex\n",
            "    Running command python setup.py egg_info\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.8.1+cu101\n",
            "\n",
            "\n",
            "    running egg_info\n",
            "    creating /tmp/pip-req-build-hx5ewj1q/pip-egg-info/apex.egg-info\n",
            "    writing /tmp/pip-req-build-hx5ewj1q/pip-egg-info/apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-req-build-hx5ewj1q/pip-egg-info/apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to /tmp/pip-req-build-hx5ewj1q/pip-egg-info/apex.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-req-build-hx5ewj1q/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    adding license file 'LICENSE' (matched pattern 'LICEN[CS]E*')\n",
            "    writing manifest file '/tmp/pip-req-build-hx5ewj1q/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    /tmp/pip-req-build-hx5ewj1q/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "  Source in /tmp/pip-req-build-hx5ewj1q has version 0.1, which satisfies requirement apex==0.1 from file:///content/apex\n",
            "  Removed apex==0.1 from file:///content/apex from build tracker '/tmp/pip-req-tracker-3rvsto29'\n",
            "Building wheels for collected packages: apex\n",
            "  Created temporary directory: /tmp/pip-wheel-mrulw5uy\n",
            "  Building wheel for apex (setup.py) ... \u001b[?25l  Destination directory: /tmp/pip-wheel-mrulw5uy\n",
            "  Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-hx5ewj1q/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-hx5ewj1q/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-mrulw5uy --python-tag cp37\n",
            "\n",
            "\n",
            "  torch.__version__  = 1.8.1+cu101\n",
            "\n",
            "\n",
            "  /tmp/pip-req-build-hx5ewj1q/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "    warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib\n",
            "  creating build/lib/apex\n",
            "  copying apex/__init__.py -> build/lib/apex\n",
            "  creating build/lib/apex/contrib\n",
            "  copying apex/contrib/__init__.py -> build/lib/apex/contrib\n",
            "  creating build/lib/apex/fp16_utils\n",
            "  copying apex/fp16_utils/fp16_optimizer.py -> build/lib/apex/fp16_utils\n",
            "  copying apex/fp16_utils/loss_scaler.py -> build/lib/apex/fp16_utils\n",
            "  copying apex/fp16_utils/fp16util.py -> build/lib/apex/fp16_utils\n",
            "  copying apex/fp16_utils/__init__.py -> build/lib/apex/fp16_utils\n",
            "  creating build/lib/apex/amp\n",
            "  copying apex/amp/_initialize.py -> build/lib/apex/amp\n",
            "  copying apex/amp/wrap.py -> build/lib/apex/amp\n",
            "  copying apex/amp/__version__.py -> build/lib/apex/amp\n",
            "  copying apex/amp/amp.py -> build/lib/apex/amp\n",
            "  copying apex/amp/_process_optimizer.py -> build/lib/apex/amp\n",
            "  copying apex/amp/_amp_state.py -> build/lib/apex/amp\n",
            "  copying apex/amp/handle.py -> build/lib/apex/amp\n",
            "  copying apex/amp/utils.py -> build/lib/apex/amp\n",
            "  copying apex/amp/opt.py -> build/lib/apex/amp\n",
            "  copying apex/amp/__init__.py -> build/lib/apex/amp\n",
            "  copying apex/amp/rnn_compat.py -> build/lib/apex/amp\n",
            "  copying apex/amp/scaler.py -> build/lib/apex/amp\n",
            "  copying apex/amp/frontend.py -> build/lib/apex/amp\n",
            "  copying apex/amp/compat.py -> build/lib/apex/amp\n",
            "  creating build/lib/apex/mlp\n",
            "  copying apex/mlp/mlp.py -> build/lib/apex/mlp\n",
            "  copying apex/mlp/__init__.py -> build/lib/apex/mlp\n",
            "  creating build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_adam.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_sgd.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_adagrad.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/__init__.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_novograd.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_lamb.py -> build/lib/apex/optimizers\n",
            "  creating build/lib/apex/RNN\n",
            "  copying apex/RNN/RNNBackend.py -> build/lib/apex/RNN\n",
            "  copying apex/RNN/cells.py -> build/lib/apex/RNN\n",
            "  copying apex/RNN/__init__.py -> build/lib/apex/RNN\n",
            "  copying apex/RNN/models.py -> build/lib/apex/RNN\n",
            "  creating build/lib/apex/parallel\n",
            "  copying apex/parallel/multiproc.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/optimized_sync_batchnorm.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/__init__.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/sync_batchnorm_kernel.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/distributed.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/LARC.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/sync_batchnorm.py -> build/lib/apex/parallel\n",
            "  creating build/lib/apex/normalization\n",
            "  copying apex/normalization/fused_layer_norm.py -> build/lib/apex/normalization\n",
            "  copying apex/normalization/__init__.py -> build/lib/apex/normalization\n",
            "  creating build/lib/apex/multi_tensor_apply\n",
            "  copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib/apex/multi_tensor_apply\n",
            "  copying apex/multi_tensor_apply/__init__.py -> build/lib/apex/multi_tensor_apply\n",
            "  creating build/lib/apex/pyprof\n",
            "  copying apex/pyprof/__init__.py -> build/lib/apex/pyprof\n",
            "  creating build/lib/apex/reparameterization\n",
            "  copying apex/reparameterization/__init__.py -> build/lib/apex/reparameterization\n",
            "  copying apex/reparameterization/reparameterization.py -> build/lib/apex/reparameterization\n",
            "  copying apex/reparameterization/weight_norm.py -> build/lib/apex/reparameterization\n",
            "  creating build/lib/apex/contrib/xentropy\n",
            "  copying apex/contrib/xentropy/__init__.py -> build/lib/apex/contrib/xentropy\n",
            "  copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib/apex/contrib/xentropy\n",
            "  creating build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fused_adam.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fused_sgd.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/__init__.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fused_lamb.py -> build/lib/apex/contrib/optimizers\n",
            "  creating build/lib/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/sparse_masklib.py -> build/lib/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/asp.py -> build/lib/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/__init__.py -> build/lib/apex/contrib/sparsity\n",
            "  creating build/lib/apex/contrib/groupbn\n",
            "  copying apex/contrib/groupbn/__init__.py -> build/lib/apex/contrib/groupbn\n",
            "  copying apex/contrib/groupbn/batch_norm.py -> build/lib/apex/contrib/groupbn\n",
            "  creating build/lib/apex/contrib/fmha\n",
            "  copying apex/contrib/fmha/fmha.py -> build/lib/apex/contrib/fmha\n",
            "  copying apex/contrib/fmha/__init__.py -> build/lib/apex/contrib/fmha\n",
            "  creating build/lib/apex/contrib/bottleneck\n",
            "  copying apex/contrib/bottleneck/bottleneck.py -> build/lib/apex/contrib/bottleneck\n",
            "  copying apex/contrib/bottleneck/__init__.py -> build/lib/apex/contrib/bottleneck\n",
            "  copying apex/contrib/bottleneck/test.py -> build/lib/apex/contrib/bottleneck\n",
            "  creating build/lib/apex/contrib/layer_norm\n",
            "  copying apex/contrib/layer_norm/layer_norm.py -> build/lib/apex/contrib/layer_norm\n",
            "  copying apex/contrib/layer_norm/__init__.py -> build/lib/apex/contrib/layer_norm\n",
            "  creating build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/__init__.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  creating build/lib/apex/contrib/transducer\n",
            "  copying apex/contrib/transducer/__init__.py -> build/lib/apex/contrib/transducer\n",
            "  copying apex/contrib/transducer/transducer.py -> build/lib/apex/contrib/transducer\n",
            "  creating build/lib/apex/amp/lists\n",
            "  copying apex/amp/lists/tensor_overrides.py -> build/lib/apex/amp/lists\n",
            "  copying apex/amp/lists/__init__.py -> build/lib/apex/amp/lists\n",
            "  copying apex/amp/lists/functional_overrides.py -> build/lib/apex/amp/lists\n",
            "  copying apex/amp/lists/torch_overrides.py -> build/lib/apex/amp/lists\n",
            "  creating build/lib/apex/pyprof/nvtx\n",
            "  copying apex/pyprof/nvtx/__init__.py -> build/lib/apex/pyprof/nvtx\n",
            "  copying apex/pyprof/nvtx/nvmarker.py -> build/lib/apex/pyprof/nvtx\n",
            "  creating build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/loss.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/dropout.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/softmax.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/usage.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/output.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/conv.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/__main__.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/base.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/utility.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/embedding.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/recurrentCell.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/prof.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/pointwise.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/reduction.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/activation.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/__init__.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/pooling.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/normalization.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/misc.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/linear.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/randomSample.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/data.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/convert.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/blas.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/optim.py -> build/lib/apex/pyprof/prof\n",
            "  creating build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/db.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/kernel.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/nvvp.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/__main__.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/__init__.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/parse.py -> build/lib/apex/pyprof/parse\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/apex\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
            "  copying build/lib/apex/contrib/xentropy/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
            "  copying build/lib/apex/contrib/xentropy/softmax_xentropy.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/distributed_fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/distributed_fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  copying build/lib/apex/contrib/sparsity/sparse_masklib.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  copying build/lib/apex/contrib/sparsity/asp.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  copying build/lib/apex/contrib/sparsity/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
            "  copying build/lib/apex/contrib/groupbn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
            "  copying build/lib/apex/contrib/groupbn/batch_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n",
            "  copying build/lib/apex/contrib/fmha/fmha.py -> build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n",
            "  copying build/lib/apex/contrib/fmha/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
            "  copying build/lib/apex/contrib/bottleneck/bottleneck.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
            "  copying build/lib/apex/contrib/bottleneck/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
            "  copying build/lib/apex/contrib/bottleneck/test.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n",
            "  copying build/lib/apex/contrib/layer_norm/layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n",
            "  copying build/lib/apex/contrib/layer_norm/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n",
            "  copying build/lib/apex/contrib/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/self_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
            "  copying build/lib/apex/contrib/transducer/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
            "  copying build/lib/apex/contrib/transducer/transducer.py -> build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib/apex/fp16_utils/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib/apex/fp16_utils/loss_scaler.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib/apex/fp16_utils/fp16util.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib/apex/fp16_utils/__init__.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/_initialize.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/wrap.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/__version__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/amp.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/_process_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/_amp_state.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/handle.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/utils.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/opt.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/rnn_compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/scaler.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/lists/tensor_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/lists/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/lists/functional_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/lists/torch_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/frontend.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/mlp\n",
            "  copying build/lib/apex/mlp/mlp.py -> build/bdist.linux-x86_64/wheel/apex/mlp\n",
            "  copying build/lib/apex/mlp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/mlp\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_adagrad.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_novograd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib/apex/RNN/RNNBackend.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib/apex/RNN/cells.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib/apex/RNN/__init__.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib/apex/RNN/models.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/multiproc.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/optimized_sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/optimized_sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/__init__.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/distributed.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/LARC.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/__init__.py -> build/bdist.linux-x86_64/wheel/apex\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/normalization\n",
            "  copying build/lib/apex/normalization/fused_layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n",
            "  copying build/lib/apex/normalization/__init__.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
            "  copying build/lib/apex/multi_tensor_apply/multi_tensor_apply.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
            "  copying build/lib/apex/multi_tensor_apply/__init__.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/pyprof\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n",
            "  copying build/lib/apex/pyprof/nvtx/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n",
            "  copying build/lib/apex/pyprof/nvtx/nvmarker.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/loss.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/dropout.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/softmax.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/usage.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/index_slice_join_mutate.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/output.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/conv.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/__main__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/base.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/utility.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/embedding.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/recurrentCell.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/prof.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/pointwise.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/reduction.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/activation.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/pooling.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/normalization.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/misc.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/linear.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/randomSample.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/data.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/convert.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/blas.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/optim.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/db.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/kernel.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/nvvp.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/__main__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/parse.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
            "  copying build/lib/apex/reparameterization/__init__.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
            "  copying build/lib/apex/reparameterization/reparameterization.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
            "  copying build/lib/apex/reparameterization/weight_norm.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  creating apex.egg-info\n",
            "  writing apex.egg-info/PKG-INFO\n",
            "  writing dependency_links to apex.egg-info/dependency_links.txt\n",
            "  writing top-level names to apex.egg-info/top_level.txt\n",
            "  writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "  adding license file 'LICENSE' (matched pattern 'LICEN[CS]E*')\n",
            "  writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "  Copying apex.egg-info to build/bdist.linux-x86_64/wheel/apex-0.1-py3.7.egg-info\n",
            "  running install_scripts\n",
            "  adding license file \"LICENSE\" (matched pattern \"LICEN[CS]E*\")\n",
            "  creating build/bdist.linux-x86_64/wheel/apex-0.1.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-mrulw5uy/apex-0.1-cp37-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'apex/__init__.py'\n",
            "  adding 'apex/RNN/RNNBackend.py'\n",
            "  adding 'apex/RNN/__init__.py'\n",
            "  adding 'apex/RNN/cells.py'\n",
            "  adding 'apex/RNN/models.py'\n",
            "  adding 'apex/amp/__init__.py'\n",
            "  adding 'apex/amp/__version__.py'\n",
            "  adding 'apex/amp/_amp_state.py'\n",
            "  adding 'apex/amp/_initialize.py'\n",
            "  adding 'apex/amp/_process_optimizer.py'\n",
            "  adding 'apex/amp/amp.py'\n",
            "  adding 'apex/amp/compat.py'\n",
            "  adding 'apex/amp/frontend.py'\n",
            "  adding 'apex/amp/handle.py'\n",
            "  adding 'apex/amp/opt.py'\n",
            "  adding 'apex/amp/rnn_compat.py'\n",
            "  adding 'apex/amp/scaler.py'\n",
            "  adding 'apex/amp/utils.py'\n",
            "  adding 'apex/amp/wrap.py'\n",
            "  adding 'apex/amp/lists/__init__.py'\n",
            "  adding 'apex/amp/lists/functional_overrides.py'\n",
            "  adding 'apex/amp/lists/tensor_overrides.py'\n",
            "  adding 'apex/amp/lists/torch_overrides.py'\n",
            "  adding 'apex/contrib/__init__.py'\n",
            "  adding 'apex/contrib/bottleneck/__init__.py'\n",
            "  adding 'apex/contrib/bottleneck/bottleneck.py'\n",
            "  adding 'apex/contrib/bottleneck/test.py'\n",
            "  adding 'apex/contrib/fmha/__init__.py'\n",
            "  adding 'apex/contrib/fmha/fmha.py'\n",
            "  adding 'apex/contrib/groupbn/__init__.py'\n",
            "  adding 'apex/contrib/groupbn/batch_norm.py'\n",
            "  adding 'apex/contrib/layer_norm/__init__.py'\n",
            "  adding 'apex/contrib/layer_norm/layer_norm.py'\n",
            "  adding 'apex/contrib/multihead_attn/__init__.py'\n",
            "  adding 'apex/contrib/multihead_attn/encdec_multihead_attn.py'\n",
            "  adding 'apex/contrib/multihead_attn/encdec_multihead_attn_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/mask_softmax_dropout_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/self_multihead_attn.py'\n",
            "  adding 'apex/contrib/multihead_attn/self_multihead_attn_func.py'\n",
            "  adding 'apex/contrib/optimizers/__init__.py'\n",
            "  adding 'apex/contrib/optimizers/distributed_fused_adam.py'\n",
            "  adding 'apex/contrib/optimizers/distributed_fused_adam_v2.py'\n",
            "  adding 'apex/contrib/optimizers/distributed_fused_adam_v3.py'\n",
            "  adding 'apex/contrib/optimizers/distributed_fused_lamb.py'\n",
            "  adding 'apex/contrib/optimizers/fp16_optimizer.py'\n",
            "  adding 'apex/contrib/optimizers/fused_adam.py'\n",
            "  adding 'apex/contrib/optimizers/fused_lamb.py'\n",
            "  adding 'apex/contrib/optimizers/fused_sgd.py'\n",
            "  adding 'apex/contrib/sparsity/__init__.py'\n",
            "  adding 'apex/contrib/sparsity/asp.py'\n",
            "  adding 'apex/contrib/sparsity/sparse_masklib.py'\n",
            "  adding 'apex/contrib/transducer/__init__.py'\n",
            "  adding 'apex/contrib/transducer/transducer.py'\n",
            "  adding 'apex/contrib/xentropy/__init__.py'\n",
            "  adding 'apex/contrib/xentropy/softmax_xentropy.py'\n",
            "  adding 'apex/fp16_utils/__init__.py'\n",
            "  adding 'apex/fp16_utils/fp16_optimizer.py'\n",
            "  adding 'apex/fp16_utils/fp16util.py'\n",
            "  adding 'apex/fp16_utils/loss_scaler.py'\n",
            "  adding 'apex/mlp/__init__.py'\n",
            "  adding 'apex/mlp/mlp.py'\n",
            "  adding 'apex/multi_tensor_apply/__init__.py'\n",
            "  adding 'apex/multi_tensor_apply/multi_tensor_apply.py'\n",
            "  adding 'apex/normalization/__init__.py'\n",
            "  adding 'apex/normalization/fused_layer_norm.py'\n",
            "  adding 'apex/optimizers/__init__.py'\n",
            "  adding 'apex/optimizers/fused_adagrad.py'\n",
            "  adding 'apex/optimizers/fused_adam.py'\n",
            "  adding 'apex/optimizers/fused_lamb.py'\n",
            "  adding 'apex/optimizers/fused_novograd.py'\n",
            "  adding 'apex/optimizers/fused_sgd.py'\n",
            "  adding 'apex/parallel/LARC.py'\n",
            "  adding 'apex/parallel/__init__.py'\n",
            "  adding 'apex/parallel/distributed.py'\n",
            "  adding 'apex/parallel/multiproc.py'\n",
            "  adding 'apex/parallel/optimized_sync_batchnorm.py'\n",
            "  adding 'apex/parallel/optimized_sync_batchnorm_kernel.py'\n",
            "  adding 'apex/parallel/sync_batchnorm.py'\n",
            "  adding 'apex/parallel/sync_batchnorm_kernel.py'\n",
            "  adding 'apex/pyprof/__init__.py'\n",
            "  adding 'apex/pyprof/nvtx/__init__.py'\n",
            "  adding 'apex/pyprof/nvtx/nvmarker.py'\n",
            "  adding 'apex/pyprof/parse/__init__.py'\n",
            "  adding 'apex/pyprof/parse/__main__.py'\n",
            "  adding 'apex/pyprof/parse/db.py'\n",
            "  adding 'apex/pyprof/parse/kernel.py'\n",
            "  adding 'apex/pyprof/parse/nvvp.py'\n",
            "  adding 'apex/pyprof/parse/parse.py'\n",
            "  adding 'apex/pyprof/prof/__init__.py'\n",
            "  adding 'apex/pyprof/prof/__main__.py'\n",
            "  adding 'apex/pyprof/prof/activation.py'\n",
            "  adding 'apex/pyprof/prof/base.py'\n",
            "  adding 'apex/pyprof/prof/blas.py'\n",
            "  adding 'apex/pyprof/prof/conv.py'\n",
            "  adding 'apex/pyprof/prof/convert.py'\n",
            "  adding 'apex/pyprof/prof/data.py'\n",
            "  adding 'apex/pyprof/prof/dropout.py'\n",
            "  adding 'apex/pyprof/prof/embedding.py'\n",
            "  adding 'apex/pyprof/prof/index_slice_join_mutate.py'\n",
            "  adding 'apex/pyprof/prof/linear.py'\n",
            "  adding 'apex/pyprof/prof/loss.py'\n",
            "  adding 'apex/pyprof/prof/misc.py'\n",
            "  adding 'apex/pyprof/prof/normalization.py'\n",
            "  adding 'apex/pyprof/prof/optim.py'\n",
            "  adding 'apex/pyprof/prof/output.py'\n",
            "  adding 'apex/pyprof/prof/pointwise.py'\n",
            "  adding 'apex/pyprof/prof/pooling.py'\n",
            "  adding 'apex/pyprof/prof/prof.py'\n",
            "  adding 'apex/pyprof/prof/randomSample.py'\n",
            "  adding 'apex/pyprof/prof/recurrentCell.py'\n",
            "  adding 'apex/pyprof/prof/reduction.py'\n",
            "  adding 'apex/pyprof/prof/softmax.py'\n",
            "  adding 'apex/pyprof/prof/usage.py'\n",
            "  adding 'apex/pyprof/prof/utility.py'\n",
            "  adding 'apex/reparameterization/__init__.py'\n",
            "  adding 'apex/reparameterization/reparameterization.py'\n",
            "  adding 'apex/reparameterization/weight_norm.py'\n",
            "  adding 'apex-0.1.dist-info/LICENSE'\n",
            "  adding 'apex-0.1.dist-info/METADATA'\n",
            "  adding 'apex-0.1.dist-info/WHEEL'\n",
            "  adding 'apex-0.1.dist-info/top_level.txt'\n",
            "  adding 'apex-0.1.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "\u001b[?25hdone\n",
            "  Created wheel for apex: filename=apex-0.1-cp37-none-any.whl size=204691 sha256=e7c6676cdc712c713df137aeb27cfbbf76927b7762e518beaa4ac212bd4bc669\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-aqfjwfv7/wheels/b1/3a/aa/d84906eaab780ae580c7a5686a33bf2820d8590ac3b60d5967\n",
            "  Removing source in /tmp/pip-req-build-hx5ewj1q\n",
            "Successfully built apex\n",
            "Installing collected packages: apex\n",
            "\n",
            "Successfully installed apex-0.1\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-3rvsto29'\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsmxZM0-x7fF",
        "outputId": "442cfff0-3f52-45d4-ea71-88ff849e40d5"
      },
      "source": [
        "import os\n",
        "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
        "# mount the google drive to colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3gLMKblgV2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0d783c0-ec87-4a11-b890-793a0582ab2b"
      },
      "source": [
        "# data preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import json\n",
        "import h5py\n",
        "\n",
        "# control\n",
        "import argparse\n",
        "import logging\n",
        "from tqdm import trange\n",
        "\n",
        "# pytorch\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# transformers\n",
        "from transformers import GPT2Config\n",
        "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "from transformers import BartForCausalLM, BartTokenizer,BartConfig"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.8.1+cu101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.5) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01D6sWx9azlq"
      },
      "source": [
        "# data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dr3GLmeRgslI"
      },
      "source": [
        "# the original dataframe\n",
        "df_ori = pd.read_csv(\"./gdrive/MyDrive/COMP0087/full_dataset.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wajqYvcFedhK"
      },
      "source": [
        "np.random.seed(7)\n",
        "train_len = 200000\n",
        "test_len = 200\n",
        "subset_idx = np.random.choice(range(len(df_ori)),train_len+test_len,replace=False)\n",
        "train_idx = subset_idx[0:train_len]\n",
        "test_idx = subset_idx[train_len:]\n",
        "df = df_ori.loc[subset_idx ,:]\n",
        "# df_test = df_ori.loc[subset_idx[-100:],:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxIQiIoQobMb"
      },
      "source": [
        "# data preprocessing\n",
        "remove1 = df.loc[df.title.map(lambda x: len(x)<4 )]\n",
        "remove2 = df.loc[df.ingredients.map(lambda x: len(x)<2)]\n",
        "remove3 = df.loc[df.directions.map(lambda x: len(x) < 2 or len(''.join(x)) < 30)]\n",
        "remove4 = df.loc[df.directions.map(lambda x: re.search('(step|mix all)', ''.join(str(x)), re.IGNORECASE)!=None)]\n",
        "len(remove3)+len(remove2)+len(remove1)+len(remove4)\n",
        "df.drop(df[df.title.map(lambda x: len(x)<4)].index, inplace=True)\n",
        "df.drop(df[df.ingredients.map(lambda x: len(x)<2)].index, inplace=True)\n",
        "df.drop(df[df.directions.map(lambda x: len(x) < 2 or len(''.join(x)) < 30)].index, inplace=True)\n",
        "df.drop(df[df.directions.map(lambda x: re.search('(step|mix all)', ''.join(str(x)), re.IGNORECASE)!=None)].index, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vogi-NsDgd1z"
      },
      "source": [
        "df.drop(df[df.title.map(lambda x: len(x)<4)].index, inplace=True)\n",
        "df.drop(df[df.ingredients.map(lambda x: len(x)<2)].index, inplace=True)\n",
        "df.drop(df[df.directions.map(lambda x: len(x) < 2 or len(''.join(x)) < 30)].index, inplace=True)\n",
        "df.drop(df[df.directions.map(lambda x: re.search('(step|mix all)', ''.join(str(x)), re.IGNORECASE)!=None)].index, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyIpD-Apgh7s"
      },
      "source": [
        "df.reset_index(inplace=True)\n",
        "train, test = train_test_split(df, test_size=0.05) #use 5% for test set\n",
        "# we only want first 10000 and 100 for train/test\n",
        "# this has an error: train[75400:75600]\n",
        "# train = train[50000:400000]\n",
        "test = test[0:100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuytage9gjzH"
      },
      "source": [
        "def df_to_plaintext_file(input_df, output_file, train = True):\n",
        "    print(\"Writing to\", output_file)\n",
        "    \n",
        "    with open(output_file, 'w') as f:\n",
        "        for index, row in input_df.iterrows():\n",
        "            if index%100000==0:\n",
        "                print(index)\n",
        "                print(res)\n",
        "            if type(row.NER)!=str:\n",
        "                continue\n",
        "            title = row.title\n",
        "            directions = json.loads(row.directions)\n",
        "            if len(directions) <= 1 and train:\n",
        "              continue\n",
        "            # print(len(directions))\n",
        "            ingredients = json.loads(row.ingredients)\n",
        "            ner = json.loads(row.NER)\n",
        "            # print(ner)\n",
        "            res = \"<RECIPE_START> <INPUT_START> \" + \" <NEXT_INPUT> \".join(ner) + \" <INPUT_END> <INGR_START> \" + \\\n",
        "              \" <NEXT_INGR> \".join(ingredients) + \" <INGR_END> <INSTR_START> \" + \\\n",
        "              \" <NEXT_INSTR> \".join(directions) + \" <INSTR_END> <TITLE_START> \" + title + \" <TITLE_END> <RECIPE_END>\"\n",
        "            # print(res)\n",
        "            f.write(\"{}\\n\".format(res))\n",
        "\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mpW4paENyVv",
        "outputId": "c72816db-1a23-441a-b5b0-785ee2923c7b"
      },
      "source": [
        "df_to_plaintext_file(train, 'control_tokens_train.txt')\n",
        "df_to_plaintext_file(test, 'control_tokens_test.txt',train = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing to control_tokens_train.txt\n",
            "100000\n",
            "<RECIPE_START> <INPUT_START> bread <NEXT_INPUT> Barrel cheese <NEXT_INPUT> sausage <NEXT_INPUT> eggs <NEXT_INPUT> milk <NEXT_INPUT> dry mustard <NEXT_INPUT> lemon pepper <NEXT_INPUT> cream of mushroom <NEXT_INPUT> milk <INPUT_END> <INGR_START> 8 slices bread, with crusts cut off <NEXT_INGR> 2 c. grated sharp Cracker Barrel cheese <NEXT_INGR> 2 lb. hot (bulk) sausage, well cooked and well drained <NEXT_INGR> 6 large eggs <NEXT_INGR> 2 1/2 c. milk <NEXT_INGR> 3/4 tsp. dry mustard <NEXT_INGR> 1 tsp. lemon pepper <NEXT_INGR> 1 can cream of mushroom, celery or chicken soup <NEXT_INGR> 1/2 c. milk <INGR_END> <INSTR_START> Place bread slices in bottom of baking dish. <NEXT_INSTR> Mix together eggs, milk, dry mustard and lemon pepper. <NEXT_INSTR> Place the sausage next (over bread), grated sharp cheese and then egg ingredients. Refrigerate overnight. <NEXT_INSTR> Next morning, turn oven to 300°. <NEXT_INSTR> Add cream of mushroom, celery or chicken soup <NEXT_INSTR> mixed with milk. <NEXT_INSTR> Bake 1 1/2 hours. <INSTR_END> <TITLE_START> Sausage Casserole <TITLE_END> <RECIPE_END>\n",
            "0\n",
            "<RECIPE_START> <INPUT_START> bread crumbs <NEXT_INPUT> Parmesan <NEXT_INPUT> leaf oregano <NEXT_INPUT> garlic <NEXT_INPUT> salt <NEXT_INPUT> chicken parts <NEXT_INPUT> oleo <NEXT_INPUT> flour <NEXT_INPUT> pepper <NEXT_INPUT> milk <INPUT_END> <INGR_START> 1/4 c. bread crumbs <NEXT_INGR> 1/4 c. grated Parmesan <NEXT_INGR> 1/4 tsp. leaf oregano <NEXT_INGR> dash of garlic powder <NEXT_INGR> dash of salt <NEXT_INGR> 1 3/4 lb. chicken parts <NEXT_INGR> 2 Tbsp. oleo <NEXT_INGR> 2 Tbsp. flour <NEXT_INGR> dash of pepper <NEXT_INGR> 1 c. milk <INGR_END> <INSTR_START> Heat oven to 400°. <NEXT_INSTR> Mix crumbs, Parmesan, oregano, garlic powder, salt and pepper. <NEXT_INSTR> Roll chicken in mixture until well coated. <NEXT_INSTR> Place in a 10 x 10-inch baking pan, skin side up. <NEXT_INSTR> Bake, uncovered, for 20 minutes, then turn chicken and bake 20 minutes more. <INSTR_END> <TITLE_START> Chicken Parmesan <TITLE_END> <RECIPE_END>\n",
            "Writing to control_tokens_test.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzINFGF4JnrG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "f17bca08e8944c50bd881858e5069a48",
            "3c258992b77c4b1385f814a17906940e",
            "0f1592204d7d47338f31d7cf76f8312f",
            "c437a7d8ea424f51b11515d697b404ef",
            "8c7c9318ada641368ac95da2e422a9c8",
            "9f680ff84d6343579c25bf0dbe413639",
            "3c70adccee1e4ab9afaec73f4cb13e32",
            "cd66650853eb43be956d8b4f39e6bbe6",
            "7316f30992ab488f8bb955d61a842644",
            "00521e72d0f74c3cb2239046f67224d2",
            "08421bef70544c8c9ef217ac49cfa897",
            "d174c701e29e42cd96e6b6c1f5871773",
            "bac54a5036a64f11803654a5d6988a06",
            "87141aec1727497a9b15c01b2cf5ae18",
            "22b6d6e8e7294e94813f8b1d97c432a4",
            "4fc50e32bebf41a7b1b9b2fb6f2a56dd",
            "319b3dd7e4f94d7596e1d512a9eff1cf",
            "a9fe2bc59af441878bda2e7c78d288cf",
            "c139a51b70ad42edb36e77f80ed14550",
            "bb83a0eb06744ee2a02e9f4e638acd8f",
            "1dc8f4700a8e4dd2b90e11034543dd0d",
            "4e2c04b3835e4b72ad49c00f0c29588b",
            "42c28e6548d541d9822a90fb5e07ba64",
            "ca65089b4ef94cf881f9bd83e0948e31"
          ]
        },
        "outputId": "48f60af9-a8b3-4bdc-87d7-46f953c6a20f"
      },
      "source": [
        "def init_tokenizer(): \n",
        "  tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n",
        "  # tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "  special_tokens = {\n",
        "    \"additional_special_tokens\": [\n",
        "        \"<TITLE_START>\",\n",
        "        \"<TITLE_END>\",\n",
        "        \"<INSTR_START>\",\n",
        "        \"<NEXT_INSTR>\",\n",
        "        \"<INSTR_END>\",\n",
        "        \"<INGR_START>\",\n",
        "        \"<NEXT_INGR>\",\n",
        "        \"<INGR_END>\",\n",
        "        \"<RECIPE_START>\",\n",
        "        \"<RECIPE_END>\",\n",
        "        \"<INPUT_START>\",\n",
        "        \"<INPUT_END>\",\n",
        "        \"<NEXT_INPUT>\"\n",
        "      ]\n",
        "  }\n",
        "  tokenizer.add_special_tokens(special_tokens)\n",
        "  return tokenizer\n",
        "\n",
        "tokenizer = init_tokenizer()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f17bca08e8944c50bd881858e5069a48",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7316f30992ab488f8bb955d61a842644",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "319b3dd7e4f94d7596e1d512a9eff1cf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355863.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wqzp-seoHsw",
        "outputId": "fb0fd000-8e63-4e32-f891-8f56853b3fcf"
      },
      "source": [
        "from collections import OrderedDict\n",
        "train_size = 150000\n",
        "test_size = 100\n",
        "\n",
        "\n",
        "end_token_id = tokenizer.convert_tokens_to_ids([\"<RECIPE_END>\"])[0]\n",
        "ing_token_id = tokenizer.convert_tokens_to_ids([\"<INPUT_END>\"])[0]\n",
        "\n",
        "next_input_token_id = tokenizer.convert_tokens_to_ids([\"<NEXT_INPUT>\"])[0]\n",
        "\n",
        "directions_size = 512\n",
        "hf = h5py.File(\"unsupervised.h5\", \"w\")\n",
        "for filename in [\"test\", \"train\"]:\n",
        "    out_np = []\n",
        "    data = open(\"control_tokens_\"+filename+\".txt\", \"r\")\n",
        "    num = 0\n",
        "    rows = 0\n",
        "    last=[]\n",
        "    for line in data:\n",
        "        num+=1\n",
        "        if num%10000 == 0:\n",
        "            print(\"Process \"+str(num)+\"; Valid: \"+str(rows))\n",
        "        text_tokens = tokenizer(line)['input_ids']\n",
        "\n",
        "        # generate the encoder input\n",
        "        if ing_token_id in text_tokens:\n",
        "          ing_idx = text_tokens.index(ing_token_id)\n",
        "          temp_list = list(OrderedDict.fromkeys(text_tokens[3:ing_idx]))\n",
        "\n",
        "          # if <NEXT_INPUT> not in list, do not need to process\n",
        "          if next_input_token_id in temp_list:\n",
        "            temp_list.remove(next_input_token_id)\n",
        "          else:\n",
        "            continue\n",
        "          text_tokens = temp_list+text_tokens\n",
        "        else:\n",
        "          continue\n",
        "        \n",
        "        # error in one recipe\n",
        "        if len(text_tokens) > directions_size or (50273 not in text_tokens): \n",
        "            continue\n",
        "\n",
        "        # text_tokens_ids = tokenizer.convert_tokens_to_ids(text_tokens)\n",
        "        text_tokens_ids = text_tokens\n",
        "\n",
        "        # append <RECIPDE_END> token to the end\n",
        "        while len(text_tokens_ids) < directions_size :\n",
        "          text_tokens_ids.append(end_token_id)\n",
        "        out_np.append(text_tokens_ids)\n",
        "        rows+=1\n",
        "\n",
        "\n",
        "        if rows == train_size and filename == 'train':\n",
        "          print(\"training sample enough:\",train_size)\n",
        "          break\n",
        "        if rows == test_size and filename == 'test':\n",
        "          print(\"testing sample enough\",test_size)\n",
        "          break\n",
        "    out_mat = np.matrix(out_np)\n",
        "    print(out_mat.shape)\n",
        "    hf.create_dataset(filename, data=out_mat)\n",
        "hf.close()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(95, 512)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 1024). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Process 10000; Valid: 9206\n",
            "Process 20000; Valid: 18479\n",
            "Process 30000; Valid: 27772\n",
            "Process 40000; Valid: 36945\n",
            "Process 50000; Valid: 46239\n",
            "Process 60000; Valid: 55560\n",
            "Process 70000; Valid: 64822\n",
            "Process 80000; Valid: 74060\n",
            "Process 90000; Valid: 83364\n",
            "Process 100000; Valid: 92558\n",
            "Process 110000; Valid: 101805\n",
            "Process 120000; Valid: 111029\n",
            "Process 130000; Valid: 120278\n",
            "Process 140000; Valid: 129528\n",
            "Process 150000; Valid: 138694\n",
            "Process 160000; Valid: 147968\n",
            "training sample enough: 150000\n",
            "(150000, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdAk4Kh1McgZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e35813bc-71c3-4bec-a68d-3a79b9463529"
      },
      "source": [
        "tokenizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreTrainedTokenizer(name_or_path='facebook/bart-base', vocab_size=50265, model_max_len=1024, is_fast=False, padding_side='right', special_tokens={'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'sep_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'cls_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True), 'additional_special_tokens': ['<TITLE_START>', '<TITLE_END>', '<INSTR_START>', '<NEXT_INSTR>', '<INSTR_END>', '<INGR_START>', '<NEXT_INGR>', '<INGR_END>', '<RECIPE_START>', '<RECIPE_END>', '<INPUT_START>', '<INPUT_END>', '<NEXT_INPUT>']})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9ZBTWh6hKqa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b849f15a-2845-4c4c-8c7e-d9bdb0f1a761"
      },
      "source": [
        "toke_result = tokenizer(\"<RECIPE_START> <INPUT_START> water <NEXT_INPUT> butter\")\n",
        "toke_result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [0, 50273, 50275, 5412, 50277, 4297, 1334, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nNMjzxKhx8R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6d537a85-a451-4bf6-c0b0-38170cff6c35"
      },
      "source": [
        "tokenizer.decode([50274])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<RECIPE_END>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnVQ59V4FdiF"
      },
      "source": [
        "# fine-tune with BART"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kz7e2PoybaiE"
      },
      "source": [
        "# fine-tuning model with bart\n",
        "# logging info\n",
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "import glob\n",
        "import logging\n",
        "import random\n",
        "import gc\n",
        "import boto3\n",
        "import shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5MKxGg8bhj4"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset, SequentialSampler, RandomSampler\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm import tqdm, trange\n",
        "import logging\n",
        "import math\n",
        "import os\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Optional\n",
        "from torch.utils.data import Dataset\n",
        "import h5py\n",
        "import torch\n",
        "\n",
        "from transformers import WEIGHTS_NAME, AdamW, get_linear_schedule_with_warmup\n",
        "from transformers import BartForCausalLM, BartTokenizer,BartConfig,BartForConditionalGeneration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dm4SBl8hbqj3"
      },
      "source": [
        "# data loading\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, tokenizer, file_path='train', block_size=512):\n",
        "        cached_features_file = \"unsupervised.h5\"\n",
        "\n",
        "        logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
        "        with h5py.File(cached_features_file, 'r') as f:\n",
        "            if file_path=='test':\n",
        "                self.examples = f[file_path][:] #this is a dev set, 10% of a test set\n",
        "            else:\n",
        "                self.examples = f[file_path][:]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return torch.tensor(self.examples[item])\n",
        "\n",
        "def load_and_cache_examples(args, tokenizer, evaluate=False):\n",
        "    dataset = TextDataset(tokenizer, file_path=\"test\" if evaluate else \"train\", block_size=args.block_size)\n",
        "    print(dataset[0:5])\n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6grSGLbPb4Cm"
      },
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "## Required parameters\n",
        "parser.add_argument(\"--train_data_file\", default=\"unsupervised.h5\", type=str, required=False,\n",
        "                        help=\"The input training data file (a text file).\")\n",
        "parser.add_argument(\"--output_dir\", default=\"./gdrive/MyDrive/COMP0087/Bart2_GRU_CP_0528_v1\", type=str, required=False,\n",
        "                        help=\"The output directory where the model predictions and checkpoints will be written.\")\n",
        "\n",
        "## Other parameters\n",
        "parser.add_argument(\"--model_type\", default=\"facebook/bart-base\" ,type=str,   #\"facebook/bart-base\"\n",
        "                        help=\"The model architecture to be fine-tuned.\")\n",
        "parser.add_argument(\"--model_name_or_path\", default=\"facebook/bart-base\", type=str,\n",
        "                        help=\"The model checkpoint for weights initialization.\")\n",
        "\n",
        "parser.add_argument(\"--eval_data_file\", default=None, type=str,\n",
        "                        help=\"An optional input evaluation data file to evaluate the perplexity on (a text file).\")\n",
        "\n",
        "parser.add_argument(\"--config_name\", default=\"\", type=str,\n",
        "                        help=\"Optional pretrained config name or path if not the same as model_name_or_path\")\n",
        "parser.add_argument(\"--tokenizer_name\", default=\"\", type=str,\n",
        "                        help=\"Optional pretrained tokenizer name or path if not the same as model_name_or_path\")\n",
        "parser.add_argument(\"--cache_dir\", default=\"\", type=str,\n",
        "                        help=\"Optional directory to store the pre-trained models downloaded from s3 (instread of the default one)\")\n",
        "parser.add_argument(\"--block_size\", default=-1, type=int,\n",
        "                        help=\"Optional input sequence length after tokenization.\"\n",
        "                             \"The training dataset will be truncated in block of this size for training.\"\n",
        "                             \"Default to the model max input length for single sentence inputs (take into account special tokens).\")\n",
        "parser.add_argument(\"--do_train\", action='store_true',\n",
        "                        help=\"Whether to run training.\")\n",
        "parser.add_argument(\"--do_eval\", action='store_true',\n",
        "                        help=\"Whether to run eval on the dev set.\")\n",
        "parser.add_argument(\"--evaluate_during_training\", action='store_true',\n",
        "                        help=\"Run evaluation during training at each logging step.\")\n",
        "parser.add_argument(\"--do_lower_case\", action='store_true',\n",
        "                        help=\"Set this flag if you are using an uncased model.\")\n",
        "\n",
        "parser.add_argument(\"--per_gpu_train_batch_size\", default=8, type=int,\n",
        "                        help=\"Batch size per GPU/CPU for training.\")\n",
        "parser.add_argument(\"--per_gpu_eval_batch_size\", default=4, type=int,\n",
        "                        help=\"Batch size per GPU/CPU for evaluation.\")\n",
        "parser.add_argument('--gradient_accumulation_steps', type=int, default=1,\n",
        "                        help=\"Number of updates steps to accumulate before performing a backward/update pass.\")\n",
        "parser.add_argument(\"--learning_rate\", default=5e-4, type=float,\n",
        "                        help=\"The initial learning rate for Adam.\")\n",
        "parser.add_argument(\"--weight_decay\", default=0.0, type=float,\n",
        "                        help=\"Weight deay if we apply some.\")\n",
        "parser.add_argument(\"--adam_epsilon\", default=1e-7, type=float,\n",
        "                        help=\"Epsilon for Adam optimizer.\")\n",
        "parser.add_argument(\"--max_grad_norm\", default=1.0, type=float,\n",
        "                        help=\"Max gradient norm.\")\n",
        "parser.add_argument(\"--num_train_epochs\", default=2, type=float,\n",
        "                        help=\"Total number of training epochs to perform.\")\n",
        "parser.add_argument(\"--max_steps\", default=-1, type=int,\n",
        "                        help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\")\n",
        "parser.add_argument(\"--warmup_steps\", default=0, type=int,\n",
        "                        help=\"Linear warmup over warmup_steps.\")\n",
        "\n",
        "parser.add_argument('--logging_steps', type=int, default=50,\n",
        "                        help=\"Log every X updates steps.\")\n",
        "parser.add_argument('--save_steps', type=int, default=50,\n",
        "                        help=\"Save checkpoint every X updates steps.\")\n",
        "parser.add_argument(\"--eval_all_checkpoints\", action='store_true',\n",
        "                        help=\"Evaluate all checkpoints starting with the same prefix as model_name_or_path ending and ending with step number\")\n",
        "parser.add_argument(\"--no_cuda\", action='store_true',\n",
        "                        help=\"Avoid using CUDA when available\")\n",
        "parser.add_argument('--overwrite_output_dir', action='store_true',\n",
        "                        help=\"Overwrite the content of the output directory\")\n",
        "parser.add_argument('--overwrite_cache', action='store_true',\n",
        "                        help=\"Overwrite the cached training and evaluation sets\")\n",
        "parser.add_argument(\"--aws_bucket\", default=\"\", type=str,\n",
        "                        help=\"Whether to upload to specified bucket.\")\n",
        "args, unknown = parser.parse_known_args()\n",
        "\n",
        "def setup_args_for_model(args):\n",
        "  args.model_type =\"facebook/bart-base\" # \"facebook/bart-base\"\n",
        "  args.model_type = \"\"\n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8yhJigCwuTM"
      },
      "source": [
        "import random\n",
        "\n",
        "def shuffle_instruction(this_batch,ins_element_id,recipe_end_id):\n",
        "  end_index = (this_batch == recipe_end_id).nonzero()[0]\n",
        "  # ins_element_id = tokenizer.convert_tokens_to_ids([\"<NEXT_INSTR>\"])[0]\n",
        "  ing_index = (this_batch == ins_element_id).nonzero()\n",
        "  ing_index = ing_index[ing_index<end_index]\n",
        "  if len(ing_index) > 1:\n",
        "    split_result = torch.tensor_split(this_batch, ing_index.squeeze())\n",
        "    split_list = list(split_result[1:-1])\n",
        "    random.shuffle(split_list)\n",
        "    shuffle_batch = torch.cat((split_result[0],torch.cat(split_list),split_result[-1]))\n",
        "    return shuffle_batch\n",
        "  else: \n",
        "    return this_batch\n",
        "\n",
        "\n",
        "def ins_token_idf(this_batch,ins_element_id,recipe_end_id):\n",
        "  if (this_batch == recipe_end_id).nonzero().size()[0] == 0:\n",
        "    return None\n",
        "  end_index = (this_batch == recipe_end_id).nonzero()[0]\n",
        "  ing_index = (this_batch == ins_element_id).nonzero()\n",
        "  # print(torch.hstack((torch.full_like(ing_index,0),ing_index)))\n",
        "  ing_index = ing_index[ing_index<end_index]\n",
        "  if len(ing_index) > 0:\n",
        "    return ing_index\n",
        "  else: \n",
        "    return None\n",
        "\n",
        "\n",
        "def split_ing_dirs(this_batch):\n",
        "  token_list = tokenizer.convert_tokens_to_ids([\"<INSTR_START>\",\n",
        "                                                \"<INGR_START>\",\n",
        "                                                \"<NEXT_INSTR>\",\n",
        "                                                \"<RECIPE_END>\",\n",
        "                                                \"<INPUT_END>\",\n",
        "                                                \"<RECIPE_START>\"])\n",
        "  ins_start_id = token_list[0]\n",
        "  ing_start_id = token_list[1]\n",
        "  ins_element_id = token_list[2]\n",
        "  recipe_end_id = token_list[3]\n",
        "  input_end_id = token_list[4]\n",
        "  recipe_start_id = token_list[5]\n",
        "\n",
        "  sample = this_batch.clone()\n",
        "  # ingredients size\n",
        "  ing_size = 48\n",
        "  ins_size = 512\n",
        "  # the start index of ingredients\n",
        "  # ing_index = (batch[i] == ing_start_id).nonzero()[0]\n",
        "  # the start index of instruction\n",
        "            \n",
        "  # move the non-zero elements of ingredients vector to left\n",
        "  ins_index = (sample == recipe_start_id).nonzero()[0]-1\n",
        "  # print(ins_index)\n",
        "  ingredients = torch.zeros(ing_size)\n",
        "  # ingredients = torch.full_like(ingredients,input_end_id)\n",
        "  # print(this_batch)\n",
        "  if ins_index > ing_size:\n",
        "    print(\"size overflow\")\n",
        "    ingredients[0:ing_size] = this_batch[0:ing_size]\n",
        "  else:\n",
        "    ingredients[0:ins_index] = this_batch[0:ins_index]\n",
        "  sample[0:ins_index-1] = 0\n",
        "  nz = sample.nonzero().squeeze()\n",
        "  # move the non-zero elements of instructions vector to left\n",
        "  directions = torch.zeros(sample.numel() - nz.numel())\n",
        "  directions = torch.full_like(directions,recipe_end_id)\n",
        "  # directions = this_batch[-1]\n",
        "  directions = torch.cat((sample[nz], directions))\n",
        "  directions[0] = 0\n",
        "  # print(ins_subvector.shape)\n",
        "  del sample\n",
        "  return ingredients, directions\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhM1mHTCgaqf"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "# from transformer import AlbertTokenizer, AlbertForMultipleChoice\n",
        "from transformers import BartForConditionalGeneration, BartTokenizer, BartConfig\n",
        "from torch.nn import CrossEntropyLoss, MSELoss, GRU\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "\n",
        "class bartWithGRU(nn.Module):\n",
        "    def __init__(self, tokenizer, token_size=512):\n",
        "        super(bartWithGRU, self).__init__()\n",
        "\n",
        "        # device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
        "        self.bart = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\")\n",
        "        self.bart.resize_token_embeddings(len(tokenizer))\n",
        "        # self.lm_head = nn.Linear(self.bart.config.d_model, self.bart.config.vocab_size, bias=False)\n",
        "\n",
        "        # add an module for consistency checking\n",
        "        self.gru = torch.nn.GRU(self.bart.config.d_model, 32 , 1 ,batch_first = False)\n",
        "        self.gru_head = nn.Linear(32, 1)\n",
        "        self.linear_activation = nn.Sigmoid()\n",
        "        self.cuda()\n",
        "\n",
        "    def forward(self,encoder_batch, batch, inst_pos):\n",
        "        # inst_pos: the position of token <NEXT_INSTR>, as a index list.\n",
        "        # print(batch.shape)\n",
        "        \n",
        "        outputs = self.bart(input_ids = encoder_batch,\n",
        "                            decoder_input_ids = batch,\n",
        "                            output_hidden_states=True)\n",
        "        last_hidden = outputs[\"decoder_hidden_states\"][-1]\n",
        "        # gru_input = torch.zeros(batch.size()[0],max_length,self.bart.config.d_model)\n",
        "        tokens_list = []\n",
        "        for i in range(batch.size()[0]):\n",
        "          batch_hidden = last_hidden[inst_pos[i][:,0],inst_pos[i][:,1],:]\n",
        "          tokens_list.append(batch_hidden)\n",
        "        gru_input = pad_sequence(tokens_list)\n",
        "        gru_output,_ = self.gru(gru_input)\n",
        "        \n",
        "\n",
        "        # print(ins_subvector.shape)\n",
        "        # consist_output = self.consist_logit(ins_subvector.half().to(args.device))\n",
        "        consist_output = self.gru_head(gru_output[-1])\n",
        "        # print(consist_output.shape)\n",
        "        consist_output = self.linear_activation(consist_output)\n",
        "\n",
        "        logits = outputs[\"logits\"]\n",
        "\n",
        "        return logits, consist_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg5IblFRBET8"
      },
      "source": [
        "def save_model(args,model,tokenizer,model_class,tokenizer_class):\n",
        "  # Create output directory if neede\n",
        "  if not os.path.exists(args.output_dir):\n",
        "    os.makedirs(args.output_dir)\n",
        "\n",
        "  logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n",
        "  # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "  # They can then be reloaded using `from_pretrained()`\n",
        "  model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "  model_to_save.save_pretrained(args.output_dir)\n",
        "  tokenizer.save_pretrained(args.output_dir)\n",
        "\n",
        "  # Good practice: save your training arguments together with the trained model\n",
        "  torch.save(args, os.path.join(args.output_dir, 'training_args.bin'))\n",
        "\n",
        "  # Load a trained model and vocabulary that you have fine-tuned\n",
        "  model = model_class.from_pretrained(args.output_dir)\n",
        "  tokenizer = tokenizer_class.from_pretrained(args.output_dir, do_lower_case=args.do_lower_case)\n",
        "  # model.to(args.device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcMyNMy_3gUO"
      },
      "source": [
        "from torch.nn import CrossEntropyLoss, BCELoss\n",
        "\n",
        "def train_seq(args, train_dataset, model, tokenizer):\n",
        "    \"\"\" Train the model \"\"\"\n",
        "\n",
        "    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n",
        "    train_sampler = RandomSampler(train_dataset)\n",
        "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.train_batch_size)\n",
        "\n",
        "    if args.max_steps > 0:\n",
        "        t_total = args.max_steps\n",
        "        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n",
        "    else:\n",
        "        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
        "\n",
        "    # Prepare optimizer and schedule (linear warmup and decay)\n",
        "    no_decay = ['bias', 'LayerNorm.weight']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay': args.weight_decay},\n",
        "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "    ]\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=args.warmup_steps,\n",
        "                                                num_training_steps=t_total)\n",
        "\n",
        "    try:\n",
        "        from apex import amp\n",
        "    except ImportError:\n",
        "        raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
        "\n",
        "    model, optimizer = amp.initialize(model, optimizer, opt_level=\"O2\")\n",
        "\n",
        "    # Train!\n",
        "    global_step = 0\n",
        "    epoch = 0\n",
        "    tr_loss, logging_loss = 0.0, 0.0\n",
        "    model.zero_grad()\n",
        "\n",
        "    train_iterator = trange(int(args.num_train_epochs), desc=\"Epoch\", disable=True)\n",
        "    for _ in train_iterator:\n",
        "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=True)\n",
        "        \n",
        "        alpha = 1.3\n",
        "        lmbda = 0.5\n",
        "        if epoch == 1:\n",
        "          lmbda = 1.5\n",
        "          # print(\"start discriminative part\")\n",
        "          # second step: fix the discriminative part \n",
        "          fix_layers = [model.gru, model.gru_head, model.linear_activation]\n",
        "                # mybart.units_logit, mybart.units_activation]\n",
        "          for layer in fix_layers:\n",
        "            for parameter in layer.parameters():\n",
        "              parameter.requires_grad = False\n",
        "\n",
        "\n",
        "        epoch +=1\n",
        "        for step, batch in enumerate(epoch_iterator):\n",
        "\n",
        "            batch_drop = 0\n",
        "            token_list = tokenizer.convert_tokens_to_ids([\"<INSTR_START>\",\n",
        "                                                          \"<INGR_START>\",\n",
        "                                                          \"<NEXT_INSTR>\",\n",
        "                                                          \"<RECIPE_END>\"])\n",
        "            ins_start_id = token_list[0]\n",
        "            ing_start_id = token_list[1]\n",
        "            ins_element_id = token_list[2]\n",
        "            recipe_end_id = token_list[3]\n",
        "\n",
        "            random_shuffle = torch.randint(2, (batch.size()[0], 1),device = args.device)\n",
        "            # print(random_shuffle)\n",
        "            \n",
        "            # shuffle_instruction(batch[1],ins_element_id,recipe_end_id).shape\n",
        "\n",
        "            # ins_tokens_list = []\n",
        "            tokens_list = []\n",
        "            max_length = 0\n",
        "\n",
        "            encoder_batch = torch.empty(0,48)\n",
        "            decoder_batch = torch.empty(0,512)\n",
        "            for batch_no in range(len(batch)):\n",
        "              \n",
        "              if (batch[batch_no] == ins_start_id).nonzero().size()[0] == 0:\n",
        "                print(\"An error happens, break\")\n",
        "                batch_drop = 1\n",
        "                break\n",
        "\n",
        "              if random_shuffle[batch_no] == 1:\n",
        "                shuffle_batch = shuffle_instruction(batch[batch_no],\n",
        "                                                      ins_start_id,ing_start_id)\n",
        "              else:\n",
        "                shuffle_batch = batch[batch_no]\n",
        "              \n",
        "              # split the encoder & decoder input\n",
        "              encoder_input, decoder_input = split_ing_dirs(shuffle_batch)\n",
        "              \n",
        "              # encoder & decoder input list\n",
        "              encoder_batch = torch.cat((encoder_batch, encoder_input.unsqueeze(0)))\n",
        "              decoder_batch = torch.cat((decoder_batch, decoder_input.unsqueeze(0)))\n",
        "                \n",
        "              ins_pos = ins_token_idf(batch[batch_no],\n",
        "                                      ins_element_id, recipe_end_id)\n",
        "              if ins_pos == None:\n",
        "                batch_drop = 1\n",
        "                break\n",
        "\n",
        "              # reshape for stacking\n",
        "              ins_pos = ins_pos.reshape(-1,1)\n",
        "\n",
        "              if ins_pos.size()[0] > max_length:\n",
        "                max_length = ins_pos.size()[0]\n",
        "              ins_idx = torch.hstack((torch.full_like(ins_pos,batch_no),ins_pos))\n",
        "              tokens_list.append(ins_idx)\n",
        "              \n",
        "            if batch_drop == 1:\n",
        "              print(\"An error in this batch, break\")\n",
        "              torch.cuda.empty_cache()\n",
        "              continue\n",
        "\n",
        "            # prepare the batch for GPU training\n",
        "            encoder_batch = encoder_batch.long().to(args.device)\n",
        "            decoder_batch = decoder_batch.long().to(args.device)\n",
        "            inputs, labels = (decoder_batch[:, 0:-1], decoder_batch[:, 1:])\n",
        "            inputs = inputs.to(args.device)\n",
        "            labels = labels.to(args.device)\n",
        "\n",
        "            # print(encoder_batch[0,0:15])\n",
        "            # print(decoder_batch[0,0:15])\n",
        "            # print(inputs[0,0:15])\n",
        "            # print(labels[0,0:15])\n",
        "\n",
        "            model.train()\n",
        "\n",
        "            loss_CE = CrossEntropyLoss(reduction = \"sum\")\n",
        "            loss_BCE = BCELoss()\n",
        "\n",
        "            # model feed-forward\n",
        "            logits, consist_output = model(encoder_batch, inputs, tokens_list)\n",
        "\n",
        "\n",
        "\n",
        "            # loss adjustment\n",
        "            bart_vocab_size = 50278\n",
        "            loss1 = 0\n",
        "            loss2 = 0\n",
        "\n",
        "            # hyperparameter in multi-task training\n",
        "            \n",
        "            # print(logits.shape, labels.shape)\n",
        "\n",
        "            for i in range(len(batch)):\n",
        "              ing_end_index = (inputs[i] == ins_start_id).nonzero()[0]\n",
        "              # print(logits[i,:ing_end_index].reshape(-1, bart_vocab_size).shape)\n",
        "              # print(labels[i,:ing_end_index].reshape(-1).shape)\n",
        "              loss1 += alpha * loss_CE(logits[i,:ing_end_index].reshape(-1, bart_vocab_size), \n",
        "                               labels[i,:ing_end_index].reshape(-1))\n",
        "              loss1 += loss_CE(logits[i,ing_end_index:].reshape(-1, bart_vocab_size), \n",
        "                               labels[i,ing_end_index:].reshape(-1))\n",
        "\n",
        "            loss1 = loss1/(len(batch)*511)\n",
        "\n",
        "            loss2 = loss_BCE(consist_output, random_shuffle.float())\n",
        "            loss = loss1 + lmbda * loss2\n",
        "\n",
        "            if global_step % 100 == 0:\n",
        "              logger.info(step)\n",
        "              print(\"step\", global_step)\n",
        "              print(\"loss:\",loss.item())\n",
        "\n",
        "            if global_step % 10000 == 0 and global_step !=0:\n",
        "              model_checkpoint = model.bart\n",
        "              model_class = BartForConditionalGeneration\n",
        "              tokenizer_class = BartTokenizer\n",
        "              save_model(args,model_checkpoint,tokenizer,model_class,tokenizer_class)\n",
        "\n",
        "            if args.gradient_accumulation_steps > 1:\n",
        "                loss = loss / args.gradient_accumulation_steps\n",
        "\n",
        "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "                # print(scaled_loss)\n",
        "                scaled_loss.backward()\n",
        "\n",
        "            tr_loss += loss.item()\n",
        "            if (step) % args.gradient_accumulation_steps == 0:\n",
        "                torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\n",
        "                optimizer.step()\n",
        "                scheduler.step()  # Update learning rate schedule\n",
        "                model.zero_grad()\n",
        "                global_step += 1\n",
        "\n",
        "                # if args.logging_steps > 0 and global_step % args.logging_steps == 0:\n",
        "                    # Log metrics\n",
        "                    # tb_writer.add_scalar('lr', scheduler.get_lr()[0], global_step)\n",
        "                    # tb_writer.add_scalar('loss', (tr_loss - logging_loss) / args.logging_steps, global_step)\n",
        "                    # logging_loss = tr_loss\n",
        "\n",
        "            if args.max_steps > 0 and global_step > 2:\n",
        "                epoch_iterator.close()\n",
        "                break\n",
        "            del inputs, labels,logits,consist_output , loss1, loss2, loss, encoder_batch, decoder_batch\n",
        "            torch.cuda.empty_cache()\n",
        "            # break\n",
        "\n",
        "    return global_step, tr_loss / global_step, batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRCAG6cGh-oc"
      },
      "source": [
        "def model_init(args,logger, model_class, tokenizer):\n",
        "  if args.eval_data_file is None and args.do_eval:\n",
        "    raise ValueError(\"Cannot do evaluation without an evaluation data file. Either supply a file to --eval_data_file \"\n",
        "                         \"or remove the --do_eval argument.\")\n",
        "  if os.path.exists(args.output_dir) and os.listdir(args.output_dir) and args.do_train and not args.overwrite_output_dir:\n",
        "    raise ValueError(\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(args.output_dir))\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
        "  args.n_gpu = torch.cuda.device_count()\n",
        "  args.device = device\n",
        "\n",
        "  # Setup logging\n",
        "  logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
        "                        datefmt = '%m/%d/%Y %H:%M:%S',\n",
        "                        level = logging.INFO)\n",
        "\n",
        "  model = bartWithGRU(tokenizer)\n",
        "\n",
        "  if args.block_size <= 0:\n",
        "    args.block_size = tokenizer.max_len_single_sentence  # Our input block size will be the max possible for the model\n",
        "  args.block_size = min(args.block_size, tokenizer.max_len_single_sentence)\n",
        "  model.to(args.device)\n",
        "\n",
        "  logger.info(\"Training/evaluation parameters %s\", args)\n",
        "  return model, logger"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOAth1Vp5ucw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1f80a3b9dd744b78ae017678f1d91ad9",
            "2aecbaa837894f638b007ac92cef2636",
            "23bd9134d6744c39b354bd4677316ae7",
            "71cb13b9fdc34d06b408fcdc03466db5",
            "c1c7c32024224094b05bc8b2ac1aa2c2",
            "12cf0a1350bd4a2aa559049e88cb5dd1",
            "8bbd9473079a40cc832dab20acc1b744",
            "b8f8532d77cb43a4b9586f35e07572f2",
            "853f30bd4fa54d63988e864d29a7885b",
            "4d5873c3b6a445b4869b4181a8f3dfd7",
            "0957ce4e345047c8b0d4ccff3b0d4008",
            "ad5103df3778474ea89c0424e1ac8955",
            "152d0a39007f4241a5109f2722043b16",
            "1060d389b60b4a0b8446aa6bc4e8387e",
            "9af798dc82cf4290b542c12027c4c040",
            "d2055c700db943908d16c97b872ea8a9"
          ]
        },
        "outputId": "9a6776c0-1759-4fbe-8fa5-7824d135a214"
      },
      "source": [
        "torch.manual_seed(7)\n",
        "train_dataset = load_and_cache_examples(args, tokenizer, evaluate=False)\n",
        "mybart, logger = model_init(args,logger,BartForConditionalGeneration,tokenizer)\n",
        "global_step, tr_loss, batch = train_seq(args, train_dataset, mybart, tokenizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[38299,    29, 20115,  ..., 50274, 50274, 50274],\n",
            "        [11613,  4104, 10332,  ..., 50274, 50274, 50274],\n",
            "        [14447,  4104, 22781,  ..., 50274, 50274, 50274],\n",
            "        [ 1610,  4550, 24571,  ..., 50274, 50274, 50274],\n",
            "        [  261,  1499, 14189,  ..., 50274, 50274, 50274]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 10:40:21 - INFO - filelock -   Lock 139914556946832 acquired on /root/.cache/huggingface/transformers/f5310d276a6d1648d00c32fadc8bf7b4607e0fbd5b404fc4a0045960aa2bdfdb.3c4e938c08a46506ff9a4be12e0f858cd714b9a5c76090d571e7a4aa95cae853.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f80a3b9dd744b78ae017678f1d91ad9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1553.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 10:40:22 - INFO - filelock -   Lock 139914556946832 released on /root/.cache/huggingface/transformers/f5310d276a6d1648d00c32fadc8bf7b4607e0fbd5b404fc4a0045960aa2bdfdb.3c4e938c08a46506ff9a4be12e0f858cd714b9a5c76090d571e7a4aa95cae853.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 10:40:23 - INFO - filelock -   Lock 139914509132496 acquired on /root/.cache/huggingface/transformers/486355ec722ef05fd480e999d4c763be56549ae930f6a3742ee721a5d2a05647.9faea28a6782a9589c09b1942c039943df02232d83d2ac288a69ddfa928eae22.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "853f30bd4fa54d63988e864d29a7885b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=557941479.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 10:40:33 - INFO - filelock -   Lock 139914509132496 released on /root/.cache/huggingface/transformers/486355ec722ef05fd480e999d4c763be56549ae930f6a3742ee721a5d2a05647.9faea28a6782a9589c09b1942c039943df02232d83d2ac288a69ddfa928eae22.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 10:40:41 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-07, aws_bucket='', block_size=1022, cache_dir='', config_name='', device=device(type='cuda'), do_eval=False, do_lower_case=False, do_train=False, eval_all_checkpoints=False, eval_data_file=None, evaluate_during_training=False, gradient_accumulation_steps=1, learning_rate=0.0005, logging_steps=50, max_grad_norm=1.0, max_steps=-1, model_name_or_path='facebook/bart-base', model_type='facebook/bart-base', n_gpu=1, no_cuda=False, num_train_epochs=2, output_dir='./gdrive/MyDrive/COMP0087/Bart2_GRU_CP_0528_v1', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=8, save_steps=50, tokenizer_name='', train_data_file='unsupervised.h5', warmup_steps=0, weight_decay=0.0)\n",
            "/usr/local/lib/python3.7/dist-packages/apex/amp/_initialize.py:25: UserWarning: An input tensor was not cuda.\n",
            "  warnings.warn(\"An input tensor was not cuda.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
            "\n",
            "Defaults for this optimization level are:\n",
            "enabled                : True\n",
            "opt_level              : O2\n",
            "cast_model_type        : torch.float16\n",
            "patch_torch_functions  : False\n",
            "keep_batchnorm_fp32    : True\n",
            "master_weights         : True\n",
            "loss_scale             : dynamic\n",
            "Processing user overrides (additional kwargs that are not None)...\n",
            "After processing overrides, optimization options are:\n",
            "enabled                : True\n",
            "opt_level              : O2\n",
            "cast_model_type        : torch.float16\n",
            "patch_torch_functions  : False\n",
            "keep_batchnorm_fp32    : True\n",
            "master_weights         : True\n",
            "loss_scale             : dynamic\n",
            "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 10:40:42 - INFO - __main__ -   0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 0\n",
            "loss: 10.247666358947754\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:125: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 10:41:51 - INFO - __main__ -   100\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 100\n",
            "loss: 1.9444445371627808\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 10:42:59 - INFO - __main__ -   200\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 200\n",
            "loss: 1.5584073066711426\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 10:44:07 - INFO - __main__ -   302\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 300\n",
            "loss: 1.7294623851776123\n",
            "size overflow\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 10:45:15 - INFO - __main__ -   402\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 400\n",
            "loss: 1.4381208419799805\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 10:46:22 - INFO - __main__ -   503\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 500\n",
            "loss: 2.0193400382995605\n",
            "size overflow\n",
            "size overflow\n",
            "An error happens, break\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 10:47:29 - INFO - __main__ -   604\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 600\n",
            "loss: 1.1264344453811646\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 10:48:37 - INFO - __main__ -   705\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 700\n",
            "loss: 1.5002655982971191\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 10:49:46 - INFO - __main__ -   805\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 800\n",
            "loss: 1.3524281978607178\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 10:50:54 - INFO - __main__ -   905\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 900\n",
            "loss: 1.1877049207687378\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 10:52:03 - INFO - __main__ -   1008\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 1000\n",
            "loss: 1.4353916645050049\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 10:53:11 - INFO - __main__ -   1108\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 1100\n",
            "loss: 1.210768222808838\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 10:54:20 - INFO - __main__ -   1208\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 1200\n",
            "loss: 0.9041608572006226\n",
            "size overflow\n",
            "An error happens, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 10:55:28 - INFO - __main__ -   1309\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 1300\n",
            "loss: 1.1046198606491089\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 10:56:37 - INFO - __main__ -   1411\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 1400\n",
            "loss: 1.387708306312561\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 10:57:45 - INFO - __main__ -   1513\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 1500\n",
            "loss: 1.4097437858581543\n",
            "An error happens, break\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 10:58:53 - INFO - __main__ -   1614\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 1600\n",
            "loss: 1.3001298904418945\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:00:02 - INFO - __main__ -   1715\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 1700\n",
            "loss: 1.21689772605896\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:01:10 - INFO - __main__ -   1817\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 1800\n",
            "loss: 1.0306975841522217\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:02:17 - INFO - __main__ -   1917\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 1900\n",
            "loss: 1.2822151184082031\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:03:25 - INFO - __main__ -   2020\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 2000\n",
            "loss: 1.0768897533416748\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:04:32 - INFO - __main__ -   2120\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 2100\n",
            "loss: 1.4768662452697754\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:05:39 - INFO - __main__ -   2221\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 2200\n",
            "loss: 1.368633508682251\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:06:47 - INFO - __main__ -   2322\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 2300\n",
            "loss: 1.1414191722869873\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:07:54 - INFO - __main__ -   2423\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 2400\n",
            "loss: 1.0939408540725708\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:09:01 - INFO - __main__ -   2526\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 2500\n",
            "loss: 0.9945950508117676\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:10:09 - INFO - __main__ -   2627\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 2600\n",
            "loss: 1.1455752849578857\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:11:16 - INFO - __main__ -   2729\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 2700\n",
            "loss: 0.9800719618797302\n",
            "size overflow\n",
            "size overflow\n",
            "size overflow\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:12:24 - INFO - __main__ -   2832\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 2800\n",
            "loss: 1.2679896354675293\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:13:32 - INFO - __main__ -   2932\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 2900\n",
            "loss: 1.3186911344528198\n",
            "size overflow\n",
            "size overflow\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:14:39 - INFO - __main__ -   3033\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 3000\n",
            "loss: 1.1294541358947754\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:15:46 - INFO - __main__ -   3134\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 3100\n",
            "loss: 1.1964750289916992\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:16:53 - INFO - __main__ -   3236\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 3200\n",
            "loss: 1.3356174230575562\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:18:00 - INFO - __main__ -   3339\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 3300\n",
            "loss: 1.0939664840698242\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:19:08 - INFO - __main__ -   3440\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 3400\n",
            "loss: 1.0167820453643799\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:20:16 - INFO - __main__ -   3542\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 3500\n",
            "loss: 1.447878122329712\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:21:24 - INFO - __main__ -   3645\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 3600\n",
            "loss: 0.8411595225334167\n",
            "size overflow\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:22:32 - INFO - __main__ -   3745\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 3700\n",
            "loss: 1.4538896083831787\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:23:40 - INFO - __main__ -   3849\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 3800\n",
            "loss: 1.2280170917510986\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:24:49 - INFO - __main__ -   3951\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 3900\n",
            "loss: 1.0679337978363037\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:25:56 - INFO - __main__ -   4051\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 4000\n",
            "loss: 1.0074775218963623\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:27:04 - INFO - __main__ -   4152\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 4100\n",
            "loss: 1.0275304317474365\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:28:12 - INFO - __main__ -   4253\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 4200\n",
            "loss: 1.19640052318573\n",
            "size overflow\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:29:21 - INFO - __main__ -   4353\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 4300\n",
            "loss: 1.148608684539795\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 512.0\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:30:29 - INFO - __main__ -   4456\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 4400\n",
            "loss: 1.1627209186553955\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 256.0\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:31:37 - INFO - __main__ -   4558\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 4500\n",
            "loss: 1.2178399562835693\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:32:45 - INFO - __main__ -   4658\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 4600\n",
            "loss: 0.912821888923645\n",
            "size overflow\n",
            "size overflow\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:33:53 - INFO - __main__ -   4759\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 4700\n",
            "loss: 0.9050341248512268\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:35:02 - INFO - __main__ -   4861\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 4800\n",
            "loss: 1.278039574623108\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:36:10 - INFO - __main__ -   4963\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 4900\n",
            "loss: 1.1575281620025635\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:37:18 - INFO - __main__ -   5063\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 5000\n",
            "loss: 1.191104769706726\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:38:26 - INFO - __main__ -   5164\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 5100\n",
            "loss: 1.0424081087112427\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:39:34 - INFO - __main__ -   5266\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 5200\n",
            "loss: 1.1506109237670898\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:40:42 - INFO - __main__ -   5368\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 5300\n",
            "loss: 0.8833001852035522\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:41:51 - INFO - __main__ -   5468\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 5400\n",
            "loss: 1.2151048183441162\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:42:58 - INFO - __main__ -   5568\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 5500\n",
            "loss: 1.2111563682556152\n",
            "An error in this batch, break\n",
            "An error happens, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:44:06 - INFO - __main__ -   5670\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 5600\n",
            "loss: 1.3559273481369019\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:45:15 - INFO - __main__ -   5771\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 5700\n",
            "loss: 1.3938872814178467\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:46:23 - INFO - __main__ -   5874\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 5800\n",
            "loss: 0.9663918614387512\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:47:31 - INFO - __main__ -   5974\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 5900\n",
            "loss: 1.3884453773498535\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 128.0\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:48:40 - INFO - __main__ -   6078\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 6000\n",
            "loss: 0.9318506717681885\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:49:48 - INFO - __main__ -   6180\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 6100\n",
            "loss: 1.0805338621139526\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:50:56 - INFO - __main__ -   6280\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 6200\n",
            "loss: 0.9703891277313232\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:52:04 - INFO - __main__ -   6382\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 6300\n",
            "loss: 1.21565580368042\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:53:12 - INFO - __main__ -   6483\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 6400\n",
            "loss: 1.050084114074707\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:54:20 - INFO - __main__ -   6583\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 6500\n",
            "loss: 1.1457550525665283\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:55:28 - INFO - __main__ -   6683\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 6600\n",
            "loss: 1.5650032758712769\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:56:37 - INFO - __main__ -   6786\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 6700\n",
            "loss: 1.0322346687316895\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:57:45 - INFO - __main__ -   6886\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 6800\n",
            "loss: 1.1964666843414307\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 11:58:53 - INFO - __main__ -   6987\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 6900\n",
            "loss: 1.1829495429992676\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:00:02 - INFO - __main__ -   7089\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 7000\n",
            "loss: 1.1058812141418457\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:01:09 - INFO - __main__ -   7190\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 7100\n",
            "loss: 0.973159670829773\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:02:17 - INFO - __main__ -   7292\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 7200\n",
            "loss: 1.108586072921753\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:03:24 - INFO - __main__ -   7395\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 7300\n",
            "loss: 1.0575933456420898\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:04:32 - INFO - __main__ -   7497\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 7400\n",
            "loss: 1.1827894449234009\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:05:39 - INFO - __main__ -   7597\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 7500\n",
            "loss: 0.902165412902832\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:06:47 - INFO - __main__ -   7699\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 7600\n",
            "loss: 0.9381464719772339\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:07:55 - INFO - __main__ -   7801\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 7700\n",
            "loss: 1.2393176555633545\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:09:02 - INFO - __main__ -   7901\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 7800\n",
            "loss: 0.9488370418548584\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:10:09 - INFO - __main__ -   8002\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 7900\n",
            "loss: 1.28678297996521\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:11:17 - INFO - __main__ -   8103\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 8000\n",
            "loss: 1.3019908666610718\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:12:24 - INFO - __main__ -   8203\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 8100\n",
            "loss: 1.000417947769165\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:13:31 - INFO - __main__ -   8305\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 8200\n",
            "loss: 3.9156408309936523\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 128.0\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:14:39 - INFO - __main__ -   8406\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 8300\n",
            "loss: 1.3858551979064941\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:15:47 - INFO - __main__ -   8509\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 8400\n",
            "loss: 0.8774700164794922\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:16:55 - INFO - __main__ -   8612\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 8500\n",
            "loss: 1.0932927131652832\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:18:04 - INFO - __main__ -   8713\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 8600\n",
            "loss: 1.2488560676574707\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:19:12 - INFO - __main__ -   8813\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 8700\n",
            "loss: 0.991929292678833\n",
            "size overflow\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:20:20 - INFO - __main__ -   8914\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 8800\n",
            "loss: 1.2939324378967285\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:21:28 - INFO - __main__ -   9015\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 8900\n",
            "loss: 1.1592525243759155\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:22:36 - INFO - __main__ -   9117\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 9000\n",
            "loss: 1.4447219371795654\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:23:44 - INFO - __main__ -   9217\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 9100\n",
            "loss: 1.2920972108840942\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:24:52 - INFO - __main__ -   9319\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 9200\n",
            "loss: 1.353277325630188\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:26:00 - INFO - __main__ -   9419\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 9300\n",
            "loss: 1.184086799621582\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:27:08 - INFO - __main__ -   9519\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 9400\n",
            "loss: 0.9520097970962524\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:28:16 - INFO - __main__ -   9619\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 9500\n",
            "loss: 1.3645131587982178\n",
            "An error happens, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:29:24 - INFO - __main__ -   9721\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 9600\n",
            "loss: 1.081190824508667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:30:32 - INFO - __main__ -   9821\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 9700\n",
            "loss: 1.1784164905548096\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:31:40 - INFO - __main__ -   9921\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 9800\n",
            "loss: 1.0324362516403198\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:32:48 - INFO - __main__ -   10022\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 9900\n",
            "loss: 1.4331254959106445\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:33:56 - INFO - __main__ -   10123\n",
            "05/31/2021 12:33:56 - INFO - __main__ -   Saving model checkpoint to ./gdrive/MyDrive/COMP0087/Bart2_GRU_CP_0528_v1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 10000\n",
            "loss: 1.0873162746429443\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:35:29 - INFO - __main__ -   10225\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 10100\n",
            "loss: 1.2264740467071533\n",
            "size overflow\n",
            "size overflow\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:36:37 - INFO - __main__ -   10325\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 10200\n",
            "loss: 1.2140913009643555\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:37:45 - INFO - __main__ -   10426\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 10300\n",
            "loss: 1.1567710638046265\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:38:53 - INFO - __main__ -   10526\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 10400\n",
            "loss: 1.6210917234420776\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:40:02 - INFO - __main__ -   10628\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 10500\n",
            "loss: 1.0879204273223877\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:41:10 - INFO - __main__ -   10728\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 10600\n",
            "loss: 1.1379284858703613\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:42:18 - INFO - __main__ -   10828\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 10700\n",
            "loss: 1.0587862730026245\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:43:26 - INFO - __main__ -   10928\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 10800\n",
            "loss: 1.1488416194915771\n",
            "An error happens, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:44:33 - INFO - __main__ -   11029\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 10900\n",
            "loss: 1.0000768899917603\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:45:42 - INFO - __main__ -   11130\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 11000\n",
            "loss: 0.9745174050331116\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:46:50 - INFO - __main__ -   11230\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 11100\n",
            "loss: 0.9266895651817322\n",
            "An error happens, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:47:58 - INFO - __main__ -   11331\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 11200\n",
            "loss: 1.057185411453247\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:49:07 - INFO - __main__ -   11433\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 11300\n",
            "loss: 1.2769801616668701\n",
            "size overflow\n",
            "size overflow\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:50:15 - INFO - __main__ -   11533\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 11400\n",
            "loss: 1.3294363021850586\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:51:23 - INFO - __main__ -   11634\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 11500\n",
            "loss: 1.1361093521118164\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:52:31 - INFO - __main__ -   11737\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 11600\n",
            "loss: 1.0946792364120483\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:53:39 - INFO - __main__ -   11837\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 11700\n",
            "loss: 1.1964186429977417\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:54:46 - INFO - __main__ -   11938\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 11800\n",
            "loss: 0.8841606378555298\n",
            "size overflow\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:55:53 - INFO - __main__ -   12039\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 11900\n",
            "loss: 1.2308876514434814\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:57:01 - INFO - __main__ -   12142\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 12000\n",
            "loss: 0.9700773358345032\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:58:09 - INFO - __main__ -   12244\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 12100\n",
            "loss: 0.9515226483345032\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 12:59:17 - INFO - __main__ -   12344\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 12200\n",
            "loss: 1.1546339988708496\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:00:26 - INFO - __main__ -   12445\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 12300\n",
            "loss: 1.089707374572754\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:01:35 - INFO - __main__ -   12545\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 12400\n",
            "loss: 1.1578868627548218\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:02:43 - INFO - __main__ -   12645\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 12500\n",
            "loss: 1.178481101989746\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:03:52 - INFO - __main__ -   12746\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 12600\n",
            "loss: 1.0540493726730347\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:05:00 - INFO - __main__ -   12849\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 12700\n",
            "loss: 1.0613722801208496\n",
            "An error in this batch, break\n",
            "An error happens, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:06:08 - INFO - __main__ -   12951\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 12800\n",
            "loss: 1.2453583478927612\n",
            "An error happens, break\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:07:17 - INFO - __main__ -   13052\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 12900\n",
            "loss: 1.156348466873169\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:08:25 - INFO - __main__ -   13152\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 13000\n",
            "loss: 1.1625113487243652\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:09:33 - INFO - __main__ -   13252\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 13100\n",
            "loss: 1.1279654502868652\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:10:40 - INFO - __main__ -   13354\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 13200\n",
            "loss: 1.125633955001831\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:11:48 - INFO - __main__ -   13456\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 13300\n",
            "loss: 0.9738695025444031\n",
            "size overflow\n",
            "An error happens, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:12:57 - INFO - __main__ -   13559\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 13400\n",
            "loss: 1.3205204010009766\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error happens, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:14:05 - INFO - __main__ -   13664\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 13500\n",
            "loss: 1.013958215713501\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:15:13 - INFO - __main__ -   13767\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 13600\n",
            "loss: 1.0795345306396484\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:16:21 - INFO - __main__ -   13868\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 13700\n",
            "loss: 1.350280523300171\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:17:29 - INFO - __main__ -   13969\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 13800\n",
            "loss: 1.0396819114685059\n",
            "An error in this batch, break\n",
            "An error happens, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:18:37 - INFO - __main__ -   14072\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 13900\n",
            "loss: 1.087634563446045\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:19:46 - INFO - __main__ -   14173\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 14000\n",
            "loss: 0.8025864958763123\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:20:54 - INFO - __main__ -   14276\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 14100\n",
            "loss: 0.9005681276321411\n",
            "size overflow\n",
            "An error happens, break\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:22:02 - INFO - __main__ -   14378\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 14200\n",
            "loss: 1.2396175861358643\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:23:11 - INFO - __main__ -   14479\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 14300\n",
            "loss: 1.2520524263381958\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:24:19 - INFO - __main__ -   14580\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 14400\n",
            "loss: 1.5950208902359009\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:25:28 - INFO - __main__ -   14681\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 14500\n",
            "loss: 1.1257094144821167\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:26:36 - INFO - __main__ -   14783\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 14600\n",
            "loss: 0.8882222771644592\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:27:45 - INFO - __main__ -   14884\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 14700\n",
            "loss: 1.433330774307251\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:28:53 - INFO - __main__ -   14985\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 14800\n",
            "loss: 1.131685495376587\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:30:02 - INFO - __main__ -   15086\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 14900\n",
            "loss: 1.2614259719848633\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:31:10 - INFO - __main__ -   15186\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 15000\n",
            "loss: 1.1695035696029663\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:32:19 - INFO - __main__ -   15289\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 15100\n",
            "loss: 1.1405547857284546\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:33:27 - INFO - __main__ -   15390\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 15200\n",
            "loss: 0.913014829158783\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:34:35 - INFO - __main__ -   15491\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 15300\n",
            "loss: 0.981124758720398\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:35:42 - INFO - __main__ -   15593\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 15400\n",
            "loss: 1.258521556854248\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:36:50 - INFO - __main__ -   15695\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 15500\n",
            "loss: 0.9758483171463013\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error happens, break\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:37:58 - INFO - __main__ -   15797\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 15600\n",
            "loss: 1.2195470333099365\n",
            "size overflow\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:39:07 - INFO - __main__ -   15897\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 15700\n",
            "loss: 1.0950310230255127\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:40:15 - INFO - __main__ -   15997\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 15800\n",
            "loss: 0.8801060914993286\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:41:23 - INFO - __main__ -   16099\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 15900\n",
            "loss: 1.165142297744751\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:42:32 - INFO - __main__ -   16199\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 16000\n",
            "loss: 1.2431461811065674\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:43:40 - INFO - __main__ -   16300\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 16100\n",
            "loss: 1.217620611190796\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:44:49 - INFO - __main__ -   16402\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 16200\n",
            "loss: 0.9700044393539429\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error happens, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:45:57 - INFO - __main__ -   16505\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 16300\n",
            "loss: 1.1810612678527832\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:47:05 - INFO - __main__ -   16607\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 16400\n",
            "loss: 1.2059040069580078\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:48:14 - INFO - __main__ -   16710\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 16500\n",
            "loss: 1.0440144538879395\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:49:22 - INFO - __main__ -   16811\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 16600\n",
            "loss: 0.8952351808547974\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:50:31 - INFO - __main__ -   16912\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 16700\n",
            "loss: 1.042597770690918\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:51:40 - INFO - __main__ -   17014\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 16800\n",
            "loss: 1.1807281970977783\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:52:48 - INFO - __main__ -   17114\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 16900\n",
            "loss: 1.1580302715301514\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:53:56 - INFO - __main__ -   17215\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 17000\n",
            "loss: 0.9328067302703857\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:55:05 - INFO - __main__ -   17315\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 17100\n",
            "loss: 0.9587534070014954\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:56:13 - INFO - __main__ -   17415\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 17200\n",
            "loss: 1.1576803922653198\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:57:22 - INFO - __main__ -   17516\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 17300\n",
            "loss: 1.1898343563079834\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:58:30 - INFO - __main__ -   17617\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 17400\n",
            "loss: 1.065332055091858\n",
            "An error happens, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 13:59:38 - INFO - __main__ -   17718\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 17500\n",
            "loss: 1.0576422214508057\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:00:47 - INFO - __main__ -   17818\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 17600\n",
            "loss: 1.2284085750579834\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:01:55 - INFO - __main__ -   17921\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 17700\n",
            "loss: 0.9866597652435303\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:03:03 - INFO - __main__ -   18022\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 17800\n",
            "loss: 1.5337927341461182\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:04:12 - INFO - __main__ -   18124\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 17900\n",
            "loss: 1.103622555732727\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:05:21 - INFO - __main__ -   18226\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 18000\n",
            "loss: 1.0254546403884888\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:06:29 - INFO - __main__ -   18330\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 18100\n",
            "loss: 1.2456003427505493\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:07:37 - INFO - __main__ -   18431\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 18200\n",
            "loss: 0.9771720767021179\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:08:45 - INFO - __main__ -   18532\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 18300\n",
            "loss: 0.9050680994987488\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:09:53 - INFO - __main__ -   18634\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 18400\n",
            "loss: 0.9797309637069702\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:11:01 - INFO - __main__ -   18734\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 18500\n",
            "loss: 1.1974517107009888\n",
            "An error in this batch, break\n",
            "An error happens, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:12:10 - INFO - __main__ -   87\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 18600\n",
            "loss: 1.7101725339889526\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:13:18 - INFO - __main__ -   190\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 18700\n",
            "loss: 1.8775116205215454\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:14:26 - INFO - __main__ -   291\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 18800\n",
            "loss: 1.8741917610168457\n",
            "size overflow\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:15:34 - INFO - __main__ -   392\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 18900\n",
            "loss: 1.6769964694976807\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:16:42 - INFO - __main__ -   492\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 19000\n",
            "loss: 1.5880100727081299\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:17:50 - INFO - __main__ -   592\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 19100\n",
            "loss: 1.8784538507461548\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:18:59 - INFO - __main__ -   695\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 19200\n",
            "loss: 2.02549147605896\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:20:07 - INFO - __main__ -   797\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 19300\n",
            "loss: 1.8465299606323242\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:21:16 - INFO - __main__ -   898\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 19400\n",
            "loss: 1.8557822704315186\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:22:24 - INFO - __main__ -   1001\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 19500\n",
            "loss: 2.0549004077911377\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:23:32 - INFO - __main__ -   1103\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 19600\n",
            "loss: 1.750767707824707\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error happens, break\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:24:40 - INFO - __main__ -   1205\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 19700\n",
            "loss: 1.865657091140747\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:25:49 - INFO - __main__ -   1306\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 19800\n",
            "loss: 1.6952192783355713\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:26:58 - INFO - __main__ -   1407\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 19900\n",
            "loss: 1.6240451335906982\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:28:06 - INFO - __main__ -   1510\n",
            "05/31/2021 14:28:06 - INFO - __main__ -   Saving model checkpoint to ./gdrive/MyDrive/COMP0087/Bart2_GRU_CP_0528_v1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 20000\n",
            "loss: 1.7984881401062012\n",
            "size overflow\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:29:21 - INFO - __main__ -   1611\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 20100\n",
            "loss: 1.8695249557495117\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:30:28 - INFO - __main__ -   1711\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 20200\n",
            "loss: 1.8461605310440063\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:31:36 - INFO - __main__ -   1811\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 20300\n",
            "loss: 1.6288959980010986\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:32:44 - INFO - __main__ -   1911\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 20400\n",
            "loss: 1.686612844467163\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:33:53 - INFO - __main__ -   2011\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 20500\n",
            "loss: 1.817232608795166\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:35:01 - INFO - __main__ -   2114\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 20600\n",
            "loss: 1.7203551530838013\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:36:09 - INFO - __main__ -   2216\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 20700\n",
            "loss: 2.1057076454162598\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:37:18 - INFO - __main__ -   2319\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 20800\n",
            "loss: 1.6863000392913818\n",
            "size overflow\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:38:26 - INFO - __main__ -   2419\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 20900\n",
            "loss: 1.9464558362960815\n",
            "size overflow\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:39:35 - INFO - __main__ -   2522\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 21000\n",
            "loss: 1.7662057876586914\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:40:43 - INFO - __main__ -   2623\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 21100\n",
            "loss: 1.9049253463745117\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:41:51 - INFO - __main__ -   2723\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 21200\n",
            "loss: 1.6894984245300293\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:43:00 - INFO - __main__ -   2826\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 21300\n",
            "loss: 1.6060822010040283\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:44:09 - INFO - __main__ -   2926\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 21400\n",
            "loss: 1.8128107786178589\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:45:17 - INFO - __main__ -   3027\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 21500\n",
            "loss: 1.8335657119750977\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:46:25 - INFO - __main__ -   3129\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 21600\n",
            "loss: 1.8757243156433105\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:47:33 - INFO - __main__ -   3229\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 21700\n",
            "loss: 1.9302793741226196\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:48:42 - INFO - __main__ -   3329\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 21800\n",
            "loss: 1.777058720588684\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:49:50 - INFO - __main__ -   3432\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 21900\n",
            "loss: 1.853804111480713\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:50:59 - INFO - __main__ -   3534\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 22000\n",
            "loss: 1.6827929019927979\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:52:07 - INFO - __main__ -   3635\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 22100\n",
            "loss: 1.9253935813903809\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:53:15 - INFO - __main__ -   3736\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 22200\n",
            "loss: 1.6806118488311768\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:54:24 - INFO - __main__ -   3836\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 22300\n",
            "loss: 1.6654078960418701\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:55:32 - INFO - __main__ -   3936\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 22400\n",
            "loss: 1.9511921405792236\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:56:40 - INFO - __main__ -   4037\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 22500\n",
            "loss: 1.6576619148254395\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:57:48 - INFO - __main__ -   4138\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 22600\n",
            "loss: 1.8605544567108154\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 14:58:57 - INFO - __main__ -   4239\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 22700\n",
            "loss: 1.814439296722412\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:00:05 - INFO - __main__ -   4340\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 22800\n",
            "loss: 1.9604597091674805\n",
            "size overflow\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:01:14 - INFO - __main__ -   4440\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 22900\n",
            "loss: 1.7939562797546387\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:02:22 - INFO - __main__ -   4542\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 23000\n",
            "loss: 2.333073139190674\n",
            "An error in this batch, break\n",
            "An error happens, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:03:31 - INFO - __main__ -   4644\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 23100\n",
            "loss: 1.7946999073028564\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:04:39 - INFO - __main__ -   4744\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 23200\n",
            "loss: 1.900219202041626\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:05:48 - INFO - __main__ -   4846\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 23300\n",
            "loss: 1.9805912971496582\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error happens, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:06:56 - INFO - __main__ -   4949\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 23400\n",
            "loss: 1.6405401229858398\n",
            "An error in this batch, break\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:08:05 - INFO - __main__ -   5050\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 23500\n",
            "loss: 1.5920743942260742\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:09:13 - INFO - __main__ -   5151\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 23600\n",
            "loss: 1.6824331283569336\n",
            "size overflow\n",
            "size overflow\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:10:21 - INFO - __main__ -   5252\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 23700\n",
            "loss: 1.7447843551635742\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:11:30 - INFO - __main__ -   5352\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 23800\n",
            "loss: 1.733492374420166\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:12:38 - INFO - __main__ -   5452\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 23900\n",
            "loss: 1.7319761514663696\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:13:46 - INFO - __main__ -   5553\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 24000\n",
            "loss: 1.6688525676727295\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:14:54 - INFO - __main__ -   5655\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 24100\n",
            "loss: 1.9598970413208008\n",
            "An error happens, break\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:16:03 - INFO - __main__ -   5756\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 24200\n",
            "loss: 1.6391358375549316\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:17:11 - INFO - __main__ -   5856\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 24300\n",
            "loss: 1.6810929775238037\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:18:19 - INFO - __main__ -   5958\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 24400\n",
            "loss: 1.6759426593780518\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:19:27 - INFO - __main__ -   6059\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 24500\n",
            "loss: 1.6833964586257935\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:20:36 - INFO - __main__ -   6163\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 24600\n",
            "loss: 1.75382661819458\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:21:44 - INFO - __main__ -   6265\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 24700\n",
            "loss: 1.671654462814331\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:22:52 - INFO - __main__ -   6367\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 24800\n",
            "loss: 1.7683333158493042\n",
            "An error happens, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:24:00 - INFO - __main__ -   6468\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 24900\n",
            "loss: 2.0461082458496094\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:25:08 - INFO - __main__ -   6571\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 25000\n",
            "loss: 1.8691132068634033\n",
            "size overflow\n",
            "An error happens, break\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:26:15 - INFO - __main__ -   6672\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 25100\n",
            "loss: 1.601606845855713\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:27:22 - INFO - __main__ -   6772\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 25200\n",
            "loss: 1.8088594675064087\n",
            "size overflow\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:28:29 - INFO - __main__ -   6874\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 25300\n",
            "loss: 1.64028000831604\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:29:37 - INFO - __main__ -   6974\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 25400\n",
            "loss: 1.842699646949768\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:30:44 - INFO - __main__ -   7074\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 25500\n",
            "loss: 2.0566000938415527\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:31:52 - INFO - __main__ -   7174\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 25600\n",
            "loss: 1.8277175426483154\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error happens, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:32:59 - INFO - __main__ -   7278\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 25700\n",
            "loss: 1.9248480796813965\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:34:07 - INFO - __main__ -   7379\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 25800\n",
            "loss: 1.8943501710891724\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:35:16 - INFO - __main__ -   7479\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 25900\n",
            "loss: 1.7861921787261963\n",
            "size overflow\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:36:24 - INFO - __main__ -   7579\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 26000\n",
            "loss: 1.9693292379379272\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:37:33 - INFO - __main__ -   7680\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 26100\n",
            "loss: 1.843344807624817\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:38:41 - INFO - __main__ -   7783\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 26200\n",
            "loss: 1.7477658987045288\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:39:49 - INFO - __main__ -   7884\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 26300\n",
            "loss: 1.597294807434082\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:40:58 - INFO - __main__ -   7984\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 26400\n",
            "loss: 1.8836824893951416\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:42:06 - INFO - __main__ -   8086\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 26500\n",
            "loss: 2.2251763343811035\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:43:15 - INFO - __main__ -   8187\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 26600\n",
            "loss: 2.1601898670196533\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:44:23 - INFO - __main__ -   8287\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 26700\n",
            "loss: 1.5863227844238281\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:45:31 - INFO - __main__ -   8389\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 26800\n",
            "loss: 1.633101224899292\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:46:40 - INFO - __main__ -   8490\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 26900\n",
            "loss: 1.9809670448303223\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:47:48 - INFO - __main__ -   8591\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 27000\n",
            "loss: 1.8155879974365234\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:48:57 - INFO - __main__ -   8693\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 27100\n",
            "loss: 1.8154735565185547\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:50:06 - INFO - __main__ -   8796\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 27200\n",
            "loss: 1.7652606964111328\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:51:14 - INFO - __main__ -   8899\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 27300\n",
            "loss: 1.6207425594329834\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:52:23 - INFO - __main__ -   8999\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 27400\n",
            "loss: 1.956848382949829\n",
            "size overflow\n",
            "size overflow\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:53:31 - INFO - __main__ -   9099\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 27500\n",
            "loss: 1.9650999307632446\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:54:40 - INFO - __main__ -   9201\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 27600\n",
            "loss: 1.9381358623504639\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:55:49 - INFO - __main__ -   9303\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 27700\n",
            "loss: 1.473881483078003\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:56:57 - INFO - __main__ -   9403\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 27800\n",
            "loss: 1.7145087718963623\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:58:05 - INFO - __main__ -   9504\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 27900\n",
            "loss: 1.6828393936157227\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 15:59:14 - INFO - __main__ -   9606\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 28000\n",
            "loss: 1.7526099681854248\n",
            "size overflow\n",
            "size overflow\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:00:22 - INFO - __main__ -   9708\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 28100\n",
            "loss: 1.7665009498596191\n",
            "An error happens, break\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:01:30 - INFO - __main__ -   9809\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 28200\n",
            "loss: 1.5994977951049805\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:02:39 - INFO - __main__ -   9910\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 28300\n",
            "loss: 1.7817633152008057\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:03:47 - INFO - __main__ -   10013\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 28400\n",
            "loss: 1.5801773071289062\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:04:56 - INFO - __main__ -   10116\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 28500\n",
            "loss: 1.897082805633545\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:06:04 - INFO - __main__ -   10216\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 28600\n",
            "loss: 1.9274237155914307\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:07:12 - INFO - __main__ -   10317\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 28700\n",
            "loss: 1.9001469612121582\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:08:20 - INFO - __main__ -   10417\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 28800\n",
            "loss: 1.5659277439117432\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:09:29 - INFO - __main__ -   10521\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 28900\n",
            "loss: 1.6048694849014282\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:10:37 - INFO - __main__ -   10624\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 29000\n",
            "loss: 1.7782527208328247\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:11:45 - INFO - __main__ -   10726\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 29100\n",
            "loss: 1.5083860158920288\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:12:53 - INFO - __main__ -   10827\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 29200\n",
            "loss: 1.6363892555236816\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:14:01 - INFO - __main__ -   10929\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 29300\n",
            "loss: 1.5943632125854492\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:15:10 - INFO - __main__ -   11030\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 29400\n",
            "loss: 1.759047269821167\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:16:18 - INFO - __main__ -   11133\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 29500\n",
            "loss: 1.6651268005371094\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:17:26 - INFO - __main__ -   11237\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 29600\n",
            "loss: 1.6725083589553833\n",
            "size overflow\n",
            "size overflow\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:18:34 - INFO - __main__ -   11339\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 29700\n",
            "loss: 1.9860880374908447\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:19:43 - INFO - __main__ -   11440\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 29800\n",
            "loss: 1.734485149383545\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:20:51 - INFO - __main__ -   11541\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 29900\n",
            "loss: 1.7484432458877563\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:22:00 - INFO - __main__ -   11642\n",
            "05/31/2021 16:22:00 - INFO - __main__ -   Saving model checkpoint to ./gdrive/MyDrive/COMP0087/Bart2_GRU_CP_0528_v1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 30000\n",
            "loss: 1.6936379671096802\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:23:15 - INFO - __main__ -   11745\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 30100\n",
            "loss: 1.8091704845428467\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:24:23 - INFO - __main__ -   11846\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 30200\n",
            "loss: 1.6719969511032104\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:25:31 - INFO - __main__ -   11946\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 30300\n",
            "loss: 1.6035645008087158\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error happens, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:26:40 - INFO - __main__ -   12049\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 30400\n",
            "loss: 1.6924059391021729\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:27:48 - INFO - __main__ -   12150\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 30500\n",
            "loss: 1.8365613222122192\n",
            "size overflow\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:28:57 - INFO - __main__ -   12251\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 30600\n",
            "loss: 1.7956970930099487\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:30:05 - INFO - __main__ -   12352\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 30700\n",
            "loss: 1.9496686458587646\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n",
            "An error happens, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:31:13 - INFO - __main__ -   12455\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 30800\n",
            "loss: 2.0690715312957764\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:32:21 - INFO - __main__ -   12556\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 30900\n",
            "loss: 1.8804550170898438\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:33:30 - INFO - __main__ -   12657\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 31000\n",
            "loss: 2.101893901824951\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:34:38 - INFO - __main__ -   12760\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 31100\n",
            "loss: 1.6787054538726807\n",
            "size overflow\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:35:46 - INFO - __main__ -   12861\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 31200\n",
            "loss: 1.6413097381591797\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:36:54 - INFO - __main__ -   12963\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 31300\n",
            "loss: 1.7280266284942627\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:38:03 - INFO - __main__ -   13065\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 31400\n",
            "loss: 1.8857073783874512\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:39:11 - INFO - __main__ -   13165\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 31500\n",
            "loss: 1.8208675384521484\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:40:19 - INFO - __main__ -   13267\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 31600\n",
            "loss: 1.8722188472747803\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:41:27 - INFO - __main__ -   13368\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 31700\n",
            "loss: 2.003106117248535\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:42:35 - INFO - __main__ -   13468\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 31800\n",
            "loss: 1.7698090076446533\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:43:43 - INFO - __main__ -   13569\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 31900\n",
            "loss: 1.7555115222930908\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:44:52 - INFO - __main__ -   13670\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 32000\n",
            "loss: 1.8583886623382568\n",
            "size overflow\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:46:00 - INFO - __main__ -   13771\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 32100\n",
            "loss: 1.7752577066421509\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:47:09 - INFO - __main__ -   13872\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 32200\n",
            "loss: 1.833027720451355\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:48:17 - INFO - __main__ -   13974\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 32300\n",
            "loss: 1.6556243896484375\n",
            "An error in this batch, break\n",
            "An error happens, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:49:26 - INFO - __main__ -   14076\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 32400\n",
            "loss: 1.4949219226837158\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:50:34 - INFO - __main__ -   14176\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 32500\n",
            "loss: 1.556462049484253\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:51:43 - INFO - __main__ -   14278\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 32600\n",
            "loss: 1.6855310201644897\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:52:51 - INFO - __main__ -   14378\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 32700\n",
            "loss: 1.9649080038070679\n",
            "An error happens, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:54:00 - INFO - __main__ -   14480\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 32800\n",
            "loss: 1.857468605041504\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:55:09 - INFO - __main__ -   14580\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 32900\n",
            "loss: 1.6732792854309082\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:56:17 - INFO - __main__ -   14680\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 33000\n",
            "loss: 1.8681082725524902\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:57:24 - INFO - __main__ -   14780\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 33100\n",
            "loss: 2.0316367149353027\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:58:32 - INFO - __main__ -   14880\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 33200\n",
            "loss: 1.9125380516052246\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 16:59:39 - INFO - __main__ -   14982\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 33300\n",
            "loss: 1.9262256622314453\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:00:48 - INFO - __main__ -   15082\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 33400\n",
            "loss: 1.7145544290542603\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:01:56 - INFO - __main__ -   15185\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 33500\n",
            "loss: 1.752909541130066\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:03:04 - INFO - __main__ -   15285\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 33600\n",
            "loss: 1.5646650791168213\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:04:12 - INFO - __main__ -   15386\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 33700\n",
            "loss: 1.8391046524047852\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:05:19 - INFO - __main__ -   15487\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 33800\n",
            "loss: 1.7420899868011475\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:06:28 - INFO - __main__ -   15588\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 33900\n",
            "loss: 1.7585093975067139\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:07:37 - INFO - __main__ -   15688\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 34000\n",
            "loss: 1.6019442081451416\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:08:45 - INFO - __main__ -   15788\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 34100\n",
            "loss: 1.7550864219665527\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:09:54 - INFO - __main__ -   15889\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 34200\n",
            "loss: 1.6160542964935303\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:11:02 - INFO - __main__ -   15989\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 34300\n",
            "loss: 1.7542624473571777\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:12:11 - INFO - __main__ -   16092\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 34400\n",
            "loss: 1.9042479991912842\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:13:19 - INFO - __main__ -   16192\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 34500\n",
            "loss: 1.7624577283859253\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:14:28 - INFO - __main__ -   16292\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 34600\n",
            "loss: 1.8070192337036133\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:15:36 - INFO - __main__ -   16392\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 34700\n",
            "loss: 1.6171045303344727\n",
            "size overflow\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:16:44 - INFO - __main__ -   16493\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 34800\n",
            "loss: 1.7613155841827393\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:17:53 - INFO - __main__ -   16593\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 34900\n",
            "loss: 1.7979469299316406\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error happens, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:19:01 - INFO - __main__ -   16695\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 35000\n",
            "loss: 1.909482717514038\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:20:09 - INFO - __main__ -   16796\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 35100\n",
            "loss: 1.6310237646102905\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:21:17 - INFO - __main__ -   16896\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 35200\n",
            "loss: 1.8151928186416626\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:22:25 - INFO - __main__ -   16996\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 35300\n",
            "loss: 1.6925125122070312\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:23:33 - INFO - __main__ -   17097\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 35400\n",
            "loss: 1.726030707359314\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "size overflow\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:24:42 - INFO - __main__ -   17199\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 35500\n",
            "loss: 1.8620648384094238\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:25:50 - INFO - __main__ -   17301\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 35600\n",
            "loss: 1.633185863494873\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:26:58 - INFO - __main__ -   17401\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 35700\n",
            "loss: 1.6231725215911865\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:28:06 - INFO - __main__ -   17504\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 35800\n",
            "loss: 1.53361976146698\n",
            "An error happens, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:29:14 - INFO - __main__ -   17608\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 35900\n",
            "loss: 1.6867198944091797\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:30:23 - INFO - __main__ -   17709\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 36000\n",
            "loss: 1.6439807415008545\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:31:31 - INFO - __main__ -   17814\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 36100\n",
            "loss: 1.7254558801651\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:32:39 - INFO - __main__ -   17914\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 36200\n",
            "loss: 1.664036512374878\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:33:48 - INFO - __main__ -   18015\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 36300\n",
            "loss: 1.4932878017425537\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:34:56 - INFO - __main__ -   18115\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 36400\n",
            "loss: 1.7721760272979736\n",
            "size overflow\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n",
            "size overflow\n",
            "An error in this batch, break\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:36:04 - INFO - __main__ -   18218\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 36500\n",
            "loss: 1.7667206525802612\n",
            "An error in this batch, break\n",
            "An error happens, break\n",
            "An error in this batch, break\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:37:12 - INFO - __main__ -   18320\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 36600\n",
            "loss: 1.908974289894104\n",
            "size overflow\n",
            "size overflow\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:38:21 - INFO - __main__ -   18420\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 36700\n",
            "loss: 1.8635380268096924\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:39:29 - INFO - __main__ -   18520\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 36800\n",
            "loss: 1.6204910278320312\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:40:38 - INFO - __main__ -   18620\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 36900\n",
            "loss: 1.6905627250671387\n",
            "size overflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 17:41:46 - INFO - __main__ -   18720\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 37000\n",
            "loss: 2.071495532989502\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXzoNYpwlYz0"
      },
      "source": [
        "## evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpKZFikiiyaE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85b4cebf-85b6-4665-abde-aad0390ec46f"
      },
      "source": [
        "args.output_dir = \"./gdrive/MyDrive/COMP0087/Bart2_GRU_CP_0528v2\"\n",
        "model = mybart.bart\n",
        "model_class = BartForConditionalGeneration\n",
        "tokenizer_class = BartTokenizer\n",
        "save_model(args,model,tokenizer,model_class,tokenizer_class)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 18:15:37 - INFO - __main__ -   Saving model checkpoint to ./gdrive/MyDrive/COMP0087/Bart2_GRU_CP_0528v2\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXpDix2yd3lB"
      },
      "source": [
        "# generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPi6Xwt5GrvO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3d2f2cb-a488-401d-b605-45d684dae063"
      },
      "source": [
        "raw_text = 'tomato,egg'\n",
        "prepared_input = ' <RECIPE_START> <INPUT_START> ' + raw_text.replace(',', ' <NEXT_INPUT> ').replace(';', ' <INPUT_END>')\n",
        "tokenizer.encode(prepared_input)[0:-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 50273, 50275, 33063, 3938, 50277, 38299]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofrfJDXw_iqf"
      },
      "source": [
        "def set_seed(args):\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    if args.n_gpu > 0:\n",
        "        torch.cuda.manual_seed_all(args.seed)\n",
        "\n",
        "\n",
        "def top_k_top_p_filtering(logits, top_k=0, top_p=0.0, filter_value=-float('Inf')):\n",
        "    \"\"\" Filter a distribution of logits using top-k and/or nucleus (top-p) filtering\n",
        "        Args:\n",
        "            logits: logits distribution shape (vocabulary size)\n",
        "            top_k > 0: keep only top k tokens with highest probability (top-k filtering).\n",
        "            top_p > 0.0: keep the top tokens with cumulative probability >= top_p (nucleus filtering).\n",
        "                Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)\n",
        "        From: https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317\n",
        "    \"\"\"\n",
        "    assert logits.dim() == 1  # batch size 1 for now - could be updated for more but the code would be less clear\n",
        "    top_k = min(top_k, logits.size(-1))  # Safety check\n",
        "    if top_k > 0:\n",
        "        # Remove all tokens with a probability less than the last token of the top-k\n",
        "        indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n",
        "        logits[indices_to_remove] = filter_value\n",
        "\n",
        "    if top_p > 0.0:\n",
        "        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
        "        cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "\n",
        "        # Remove tokens with cumulative probability above the threshold\n",
        "        sorted_indices_to_remove = cumulative_probs > top_p\n",
        "        # Shift the indices to the right to keep also the first token above the threshold\n",
        "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
        "        sorted_indices_to_remove[..., 0] = 0\n",
        "\n",
        "        indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
        "        logits[indices_to_remove] = filter_value\n",
        "    return logits\n",
        "\n",
        "\n",
        "def sample_sequence(model, length, raw_text, tokenizer, num_samples=1, temperature=1, top_k=0, top_p=0.0, device='cpu'):\n",
        "    end_token = tokenizer.convert_tokens_to_ids([\"<RECIPE_END>\"])[0]\n",
        "    ing_token_id = tokenizer.convert_tokens_to_ids([\"<INPUT_END>\"])[0]\n",
        "    input_token = tokenizer.convert_tokens_to_ids([\"<NEXT_INPUT>\"])[0]\n",
        "\n",
        "    prepared_input = ' <RECIPE_START> <INPUT_START> ' + raw_text.replace(',', ' <NEXT_INPUT> ').replace(';', ' <INPUT_END>')\n",
        "    # print(prepared_input)\n",
        "\n",
        "    context_tokens = tokenizer.encode(prepared_input)[:-1]\n",
        "    context_len = len(context_tokens)\n",
        "    \n",
        "    encoder_tokens = torch.tensor(context_tokens[3:], dtype=torch.long, device=device)\n",
        "    encoder_tokens = encoder_tokens[encoder_tokens != input_token]\n",
        "\n",
        "    context = torch.tensor(context_tokens, dtype=torch.long, device=device)\n",
        "    # the encoder condition\n",
        "    raw_text_tokens = encoder_tokens\n",
        "    context = context.unsqueeze(0).repeat(num_samples, 1)\n",
        "    raw_text_tokens = raw_text_tokens.unsqueeze(0).repeat(num_samples, 1)\n",
        "    \n",
        "    # genereated token\n",
        "    start_token =  tokenizer.convert_tokens_to_ids([\"<RECIPE_START>\"])[0]\n",
        "    # generated = torch.tensor(start_token, dtype=torch.long, device=device).reshape(1).unsqueeze(0)\n",
        "    generated = context\n",
        "    # print(generated.shape)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for _ in range(length):\n",
        "            # inputs = {'input_ids': generated}\n",
        "            outputs = model(input_ids = raw_text_tokens, decoder_input_ids = generated)\n",
        "            # outputs = model(**inputs)  # Note: we could also use 'past' with GPT-2/Transfo-XL/XLNet (cached hidden-states)\n",
        "            # print(outputs)\n",
        "            next_token_logits = outputs[\"logits\"][0, -1, :] / temperature\n",
        "            \n",
        "            filtered_logits = top_k_top_p_filtering(next_token_logits, top_k=top_k, top_p=top_p)\n",
        "            next_token = torch.multinomial(F.softmax(filtered_logits, dim=-1), num_samples=1)\n",
        "            generated = torch.cat((generated, next_token.unsqueeze(0)), dim=1)\n",
        "            #print(next_token)\n",
        "            if next_token.item() == end_token:\n",
        "                break\n",
        "    return generated, context_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6VNmuOzd4vW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70de9ce2-a9fc-4050-c85e-f5394dc5caa7"
      },
      "source": [
        "# raw_text = args.prompt if args.prompt else input(\"Comma-separated ingredients, semicolon to close the list >>> \")\n",
        "model.to(\"cuda\")\n",
        "raw_text = 'potato,beef;'\n",
        "\n",
        "out,context_len = sample_sequence(\n",
        "            model=model,\n",
        "            raw_text=raw_text,\n",
        "            tokenizer=tokenizer,\n",
        "            length=512,\n",
        "            device = \"cuda\"\n",
        "        )\n",
        "out = out[0, context_len:].tolist()\n",
        "text = tokenizer.decode(out, clean_up_tokenization_spaces=True)\n",
        "if \"<RECIPE_END>\" not in text:\n",
        "  print(text)\n",
        "  print(\"Failed to generate, recipe's too long\")\n",
        "  full_text = prepared_input + text\n",
        "  print(full_text)\n",
        "else:\n",
        "  full_text = prepared_input + text\n",
        "  print(full_text)\n",
        "  markdown = re.sub(\"<RECIPE_(START|END)>\", \"\", full_text)\n",
        "  recipe_n_title = markdown.split(\"<TITLE_START>\")\n",
        "  # title = \"# \" + recipe_n_title[1].replace(\"<TITLE_END>\", \"\") + \" #\\n\"\n",
        "  markdown = recipe_n_title[0].replace(\"<INPUT_START>\", \"## Input ingredients ##\\n`\").replace(\"<INPUT_END>\", \"`\\n\")\n",
        "  markdown = markdown.replace(\"<NEXT_INPUT>\", \"`\\n`\").replace(\"<INGR_START>\", \"## Ingredients ##\\n* \").replace(\"<NEXT_INGR>\", \"\\n* \").replace(\"<INGR_END>\", \"\\n\")\n",
        "  markdown = markdown.replace(\"<INSTR_START>\", \"## Instructions ##\\n1) \").replace(\"<NEXT_INSTR>\", \"\\n1) \").replace(\"<INSTR_END>\", \"\\n\")\n",
        "  markdown = re.sub(\"$ +#\", \"#\", markdown)\n",
        "  markdown = re.sub(\"( +`|` +)\", \"`\", markdown)\n",
        "  print(markdown)#\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " <RECIPE_START> <INPUT_START> tomato <NEXT_INPUT> egg<INGR_START> 1 potato <NEXT_INGR> 1 bun beef <INGR_END> <INSTR_START> Bake beef for 2 hours at 375. <NEXT_INSTR> Chooke up.ALT. <NEXT_INSTR> Stuff up moon puffed bag onto cooked olives. <INSTR_END> <TITLE_START> Steak Bake Stuffed Walnut Caps <TITLE_END> <RECIPE_END>\n",
            "  ## Input ingredients ##\n",
            "`tomato`\n",
            "`egg## Ingredients ##\n",
            "*  1 potato \n",
            "*  1 bun beef \n",
            " ## Instructions ##\n",
            "1)  Bake beef for 2 hours at 375. \n",
            "1)  Chooke up.ALT. \n",
            "1)  Stuff up moon puffed bag onto cooked olives. \n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KoPaCB2vVej"
      },
      "source": [
        "# gold standard\n",
        "#df_eval = gold_st\n",
        "model.to(args.device)\n",
        "test_input = test.reset_index()\n",
        "df_eval_ner = test_input[\"NER\"]  #NER\n",
        "df_eval_dir = test_input[\"directions\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TY78AVj4vcEU"
      },
      "source": [
        "def get_raw_input(NER):\n",
        "    test_str = NER\n",
        "    test_str = test_str.replace(\"[\",\"\")\n",
        "    test_str = test_str.replace(\"]\",\"\")\n",
        "    test_str = test_str.replace(\"\\\"\",\"\")\n",
        "\n",
        "    return test_str\n",
        "\n",
        "def get_instr(markdown):\n",
        "  markdown = markdown.split(\"\\n\")\n",
        "  if ' ## Instructions ##' in markdown:\n",
        "    instr_index = markdown.index(' ## Instructions ##')\n",
        "    \n",
        "    output = [i for i in markdown[instr_index+1:]]\n",
        "\n",
        "    if \" \" in output:\n",
        "        output.remove(\" \")\n",
        "\n",
        "    if \"\" in output:\n",
        "        output.remove(\"\")    \n",
        "    \n",
        "    return output\n",
        "\n",
        "  elif '## Instructions ##' in markdown:\n",
        "    instr_index = markdown.index('## Instructions ##')\n",
        "\n",
        "    output = [i for i in markdown[instr_index+1:]]\n",
        "\n",
        "    if \" \" in output:\n",
        "        output.remove(\" \")\n",
        "        \n",
        "    if \"\" in output:\n",
        "        output.remove(\"\")    \n",
        "\n",
        "    return output\n",
        "    \n",
        "  else:\n",
        "    return [\"failed to generate\"]\n",
        "\n",
        "\n",
        "def generate_recipe(raw_text):\n",
        "    prepared_input = ' <RECIPE_START> <INPUT_START> ' + raw_text.replace(',', ' <NEXT_INPUT> ').replace(';', ' <INPUT_END>')\n",
        "    # print(prepared_input)\n",
        "\n",
        "    out, context_len = sample_sequence(\n",
        "            model=model,\n",
        "            raw_text=raw_text,\n",
        "            tokenizer=tokenizer,\n",
        "            length=512,\n",
        "            device = \"cuda\"\n",
        "        )\n",
        "    out = out[0, context_len:].tolist()\n",
        "    text = tokenizer.decode(out, clean_up_tokenization_spaces=True)\n",
        "    if \"<RECIPE_END>\" not in text:\n",
        "      print(\"Failed to generate, recipe's too long\")\n",
        "      full_text = prepared_input + text\n",
        "      # print(full_text)\n",
        "      return generate_recipe(raw_text)\n",
        "    else:\n",
        "      full_text = prepared_input + text\n",
        "      # print(full_text)\n",
        "      markdown = re.sub(\"<RECIPE_(START|END)>\", \"\", full_text)\n",
        "      recipe_n_title = markdown.split(\"<TITLE_START>\")\n",
        "      if len(recipe_n_title)<=1:\n",
        "        return generate_recipe(raw_text)\n",
        "      title = \"# \" + recipe_n_title[1].replace(\"<TITLE_END>\", \"\") + \" #\\n\"\n",
        "      markdown = recipe_n_title[0].replace(\"<INPUT_START>\", \"## Input ingredients ##\\n`\").replace(\"<INPUT_END>\", \"`\\n\")\n",
        "      markdown = markdown.replace(\"<NEXT_INPUT>\", \"`\\n`\").replace(\"<INGR_START>\", \"## Ingredients ##\\n* \").replace(\"<NEXT_INGR>\", \"\\n* \").replace(\"<INGR_END>\", \"\\n\")\n",
        "      #markdown = markdown.replace(\"<INSTR_START>\", \"## Instructions ##\\n\\\"\").replace(\"<NEXT_INSTR>\", \"\\n\\\"\").replace(\"<INSTR_END>\", \"\\n\")\n",
        "      markdown = markdown.replace(\"<INSTR_START>\", \"## Instructions ##\\n\").replace(\"<NEXT_INSTR>\", \"\\n\").replace(\"<INSTR_END>\", \"\\n\")\n",
        "      markdown = re.sub(\"$ +#\", \"#\", markdown)\n",
        "      markdown = re.sub(\"( +`|` +)\", \"`\", markdown)\n",
        "  \n",
        "      return markdown"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h84dStu7vegL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43f2daa8-cda0-4bce-fed3-da823826248b"
      },
      "source": [
        "df_eval_dir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     [\"Place raspberries in a small bowl; mash with...\n",
              "1     [\"Whisk sour cream together with mustard in a ...\n",
              "2     [\"Mix together and pour over meat.\", \"Roast fo...\n",
              "3     [\"Saute onion, olives, capers and bacon or ham...\n",
              "4     [\"Mix brownies according to the directions on ...\n",
              "                            ...                        \n",
              "95    [\"Blend together both of the flours and set as...\n",
              "96    [\"Shake one or two drops of bitters into a coc...\n",
              "97    [\"Wash each of the five varieties of lettuce i...\n",
              "98    [\"In a large bowl, toss together the apples an...\n",
              "99    [\"Dissolve yeast in warm water in warmed bowl....\n",
              "Name: directions, Length: 100, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w_xrYOqvgkE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1e57724-5fc5-4dc5-8df4-466ddbfdecca"
      },
      "source": [
        "torch.manual_seed(1)\n",
        "# generate recipes derived from gold standard ones\n",
        "test_size = 100\n",
        "replicated_size = 10\n",
        "directions =  [[] for i in range(test_size)]\n",
        "\n",
        "for i in range(test_size):\n",
        "  raw_text = get_raw_input(df_eval_ner[i])\n",
        "  print(\"\\n Generating the recipe: \",i)\n",
        "\n",
        "  for j in range(replicated_size):\n",
        "    print(\"recipe: \",j)\n",
        "    md = generate_recipe(raw_text)\n",
        "    directions[i].append(get_instr(md))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Generating the recipe:  0\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  1\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  2\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  3\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  4\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  5\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  6\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  7\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  8\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  9\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  10\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  11\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  12\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  13\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  14\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  15\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  16\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  17\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  18\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  19\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  20\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  21\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  22\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "Failed to generate, recipe's too long\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  23\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  24\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  25\n",
            "recipe:  0\n",
            "Failed to generate, recipe's too long\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  26\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  27\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "Failed to generate, recipe's too long\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  28\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  29\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  30\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  31\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  32\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  33\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  34\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  35\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  36\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  37\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  38\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  39\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  40\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  41\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  42\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  43\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "Failed to generate, recipe's too long\n",
            "\n",
            " Generating the recipe:  44\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  45\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  46\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "Failed to generate, recipe's too long\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  47\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  48\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  49\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  50\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  51\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  52\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  53\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  54\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  55\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "Failed to generate, recipe's too long\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  56\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  57\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  58\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  59\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  60\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  61\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  62\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  63\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  64\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  65\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  66\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "Failed to generate, recipe's too long\n",
            "recipe:  2\n",
            "Failed to generate, recipe's too long\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  67\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  68\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  69\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  70\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  71\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  72\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "Failed to generate, recipe's too long\n",
            "\n",
            " Generating the recipe:  73\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  74\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  75\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  76\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  77\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  78\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  79\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  80\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  81\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  82\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  83\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  84\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "Failed to generate, recipe's too long\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  85\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "Failed to generate, recipe's too long\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  86\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  87\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  88\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "Failed to generate, recipe's too long\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  89\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  90\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  91\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  92\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  93\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "Failed to generate, recipe's too long\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "Failed to generate, recipe's too long\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  94\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  95\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  96\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  97\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  98\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n",
            "\n",
            " Generating the recipe:  99\n",
            "recipe:  0\n",
            "recipe:  1\n",
            "recipe:  2\n",
            "recipe:  3\n",
            "Failed to generate, recipe's too long\n",
            "recipe:  4\n",
            "recipe:  5\n",
            "recipe:  6\n",
            "recipe:  7\n",
            "recipe:  8\n",
            "recipe:  9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY7IJP1tvtDY"
      },
      "source": [
        "#func of cos_sim\n",
        "import re\n",
        "import math\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "def get_cosine(vec1, vec2):\n",
        "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
        "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
        "\n",
        "    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
        "    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
        "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
        "\n",
        "    if not denominator:\n",
        "        return 0.0\n",
        "    else:\n",
        "        return float(numerator) / denominator\n",
        "\n",
        "\n",
        "def text_to_vector(text):\n",
        "    word = re.compile(r'\\w+')\n",
        "    words = word.findall(text)\n",
        "    return Counter(words)\n",
        "\n",
        "\n",
        "def get_result(content_a, content_b):\n",
        "    text1 = content_a\n",
        "    text2 = content_b\n",
        "\n",
        "    vector1 = text_to_vector(text1)\n",
        "    vector2 = text_to_vector(text2)\n",
        "\n",
        "    cosine_result = get_cosine(vector1, vector2)\n",
        "    return cosine_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RA6mX6-bvzes"
      },
      "source": [
        "#cosine_similarity\n",
        "\n",
        "def COS_SIM(df_eval_dir,directions):\n",
        "  \"\"\"\n",
        "  df_eval_dir := gold_standard recipes\n",
        "  directions  := corresponding recipes \"\"\"\n",
        "\n",
        "  avg = 0\n",
        "\n",
        "  for i in range(len(directions)):\n",
        "    best = 0\n",
        "    for j in range(len(directions[i])):\n",
        "      cos = get_result(\" \".join(eval(df_eval_dir[i])),\n",
        "                      \" \".join(directions[i][j]))\n",
        "      best = max(best, cos)\n",
        "\n",
        "    avg += best\n",
        "\n",
        "  avg = avg/len(directions)\n",
        "\n",
        "  print(\"avg:\", avg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8nbUd8qvzqd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd23c3a0-370f-4e00-cd5b-3660c143e56d"
      },
      "source": [
        "COS_SIM(df_eval_dir,directions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "avg: 0.5311078449518194\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhmPW8Jvv4Oq"
      },
      "source": [
        "import nltk\n",
        "import nltk.translate.bleu_score as bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "\n",
        "import nltk.translate.gleu_score as gleu\n",
        "import nltk.translate.meteor_score as meteor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39CPJFonv4SC"
      },
      "source": [
        "# Helper Func.\n",
        "def list_to_words(recipe):\n",
        "  words = []\n",
        "  for i in recipe:\n",
        "    words += i.split()\n",
        "\n",
        "  return words\n",
        "\n",
        "# New BLEU/GLEU\n",
        "def bleu_score(recipe, refer):\n",
        "    hyp = list_to_words(eval(recipe))\n",
        "    refs = []\n",
        "    for i in refer:\n",
        "        # print(list_to_words(i))\n",
        "        refs.append(list_to_words(i))\n",
        "\n",
        "    smoothie = SmoothingFunction().method5\n",
        "    score_ref_a = bleu.sentence_bleu(refs, hyp, smoothing_function=smoothie, weights=(1,0,0,0))\n",
        "    return score_ref_a\n",
        "\n",
        "def gleu_score(recipe, refer):\n",
        "    hyp = list_to_words(eval(recipe))\n",
        "    refs = []\n",
        "    for i in refer:\n",
        "        refs.append(list_to_words(i))\n",
        "\n",
        "    score_ref_a = gleu.sentence_gleu(refs, hyp)\n",
        "    return score_ref_a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjOFqH23v4Um",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be7fbaa5-ac4d-4406-e121-b5793ff64e0c"
      },
      "source": [
        "bleu_avg = []\n",
        "gleu_avg = []\n",
        "\n",
        "for i in range(len(directions)):\n",
        "  # print(bleu_score(df_eval_dir[i], directions[i]))\n",
        "  bleu_avg.append(bleu_score(df_eval_dir[i], directions[i]))\n",
        "\n",
        "for i in range(len(directions)):\n",
        "  gleu_avg.append(gleu_score(df_eval_dir[i], directions[i]))\n",
        "print(np.mean(bleu_avg))\n",
        "print(np.mean(gleu_avg))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7885782453010589\n",
            "0.08522751470462167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFxAgVNc0zOO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ae156c94-6e5b-46fc-9ac6-b9e2e920e28e"
      },
      "source": [
        "!sudo apt-get install git-lfs\n",
        "!pip install huggingface_hub\n",
        "!transformers-cli login\n",
        "!git config --global user.email \"uclqjia@ucl.ac.uk\"\n",
        "!git config --global user.name \"jky594176\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  git-lfs\n",
            "0 upgraded, 1 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 2,129 kB of archives.\n",
            "After this operation, 7,662 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 git-lfs amd64 2.3.4-1 [2,129 kB]\n",
            "Fetched 2,129 kB in 2s (880 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package git-lfs.\n",
            "(Reading database ... 160706 files and directories currently installed.)\n",
            "Preparing to unpack .../git-lfs_2.3.4-1_amd64.deb ...\n",
            "Unpacking git-lfs (2.3.4-1) ...\n",
            "Setting up git-lfs (2.3.4-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.7/dist-packages (0.0.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (4.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (3.0.12)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (4.41.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->huggingface_hub) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->huggingface_hub) (3.4.1)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/aa/4ef5aa67a9a62505db124a5cb5262332d1d4153462eb8fd89c9fa41e5d92/urllib3-1.25.11-py2.py3-none-any.whl (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (3.0.4)\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: urllib3\n",
            "  Found existing installation: urllib3 1.26.5\n",
            "    Uninstalling urllib3-1.26.5:\n",
            "      Successfully uninstalled urllib3-1.26.5\n",
            "Successfully installed urllib3-1.25.11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2021-05-31 19:39:14.618209: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "\n",
            "        _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "        _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "        _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "        _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "        _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "        \n",
            "Username: jky594176\n",
            "Password: \n",
            "Login successful\n",
            "Your token: wFlaWwkzYsLYQJZVfUieRigrdDLeDnTTZyiVhPAaIgeOELnnojbdQUAzHcSqpkgfkfKmxjkzOAmXBRTuYACjeYBoMzLFYVQgxRPnCXlpkACwUKifzsfRoihlcNWIGVgn \n",
            "\n",
            "Your token has been saved to /root/.huggingface/token\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xLLGEEo78yh",
        "outputId": "e70183a2-1437-4fa7-df98-801824c96800"
      },
      "source": [
        "model_type = [\"recipe_GPT2\",\"recipe_BART1\",\"recipe_BART2\",\"recipe_BART1_NN\",\"recipe_BART1_GRU\",\"BART2_GRU\"]\n",
        "# output_dir = \"./gdrive/MyDrive/COMP0087/Bart1Gru_CP_350k\"\n",
        "# model = BartForConditionalGeneration.from_pretrained(output_dir)\n",
        "model.push_to_hub(model_type[5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "05/31/2021 19:41:01 - INFO - huggingface_hub.repository -   git version 2.17.1\n",
            "Sorry, no usage text found for \"git-lfs\"\n",
            "05/31/2021 19:42:34 - INFO - huggingface_hub.repository -   \n",
            "Git LFS: (0 of 1 files) 0 B / 974.07 MB                                        \n",
            "Git LFS: (0 of 1 files) 0 B / 974.07 MB                                        \n",
            "Git LFS: (0 of 1 files) 0 B / 974.07 MB                                        \n",
            "Git LFS: (0 of 1 files) 43.45 KB / 974.07 MB                                   \n",
            "Git LFS: (0 of 1 files) 103.45 KB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 151.45 KB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 267.45 KB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 483.45 KB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 1.01 MB / 974.07 MB                                    \n",
            "Git LFS: (0 of 1 files) 4.94 MB / 974.07 MB                                    \n",
            "Git LFS: (0 of 1 files) 6.71 MB / 974.07 MB                                    \n",
            "Git LFS: (0 of 1 files) 8.71 MB / 974.07 MB                                    \n",
            "Git LFS: (0 of 1 files) 12.41 MB / 974.07 MB                                   \n",
            "Git LFS: (0 of 1 files) 15.44 MB / 974.07 MB                                   \n",
            "Git LFS: (0 of 1 files) 18.48 MB / 974.07 MB                                   \n",
            "Git LFS: (0 of 1 files) 21.51 MB / 974.07 MB                                   \n",
            "Git LFS: (0 of 1 files) 24.55 MB / 974.07 MB                                   \n",
            "Git LFS: (0 of 1 files) 27.58 MB / 974.07 MB                                   \n",
            "Git LFS: (0 of 1 files) 30.62 MB / 974.07 MB                                   \n",
            "Git LFS: (0 of 1 files) 33.65 MB / 974.07 MB                                   \n",
            "Git LFS: (0 of 1 files) 36.69 MB / 974.07 MB                                   \n",
            "Git LFS: (0 of 1 files) 39.72 MB / 974.07 MB                                   \n",
            "Git LFS: (0 of 1 files) 42.76 MB / 974.07 MB                                   \n",
            "Git LFS: (0 of 1 files) 47.82 MB / 974.07 MB                                   \n",
            "Git LFS: (0 of 1 files) 50.90 MB / 974.07 MB                                   \n",
            "Git LFS: (0 of 1 files) 54.33 MB / 974.07 MB                                   \n",
            "Git LFS: (0 of 1 files) 57.84 MB / 974.07 MB                                   \n",
            "Git LFS: (0 of 1 files) 60.19 MB / 974.07 MB                                   \n",
            "Git LFS: (0 of 1 files) 62.51 MB / 974.07 MB                                   \n",
            "Git LFS: (0 of 1 files) 64.99 MB / 974.07 MB                                   \n",
            "Git LFS: (0 of 1 files) 68.02 MB / 974.07 MB                                   \n",
            "Git LFS: (0 of 1 files) 71.06 MB / 974.07 MB                                   \n",
            "Git LFS: (0 of 1 files) 74.09 MB / 974.07 MB                                   \n",
            "Git LFS: (0 of 1 files) 77.13 MB / 974.07 MB                                   \n",
            "Git LFS: (0 of 1 files) 80.16 MB / 974.07 MB                                   \n",
            "Git LFS: (0 of 1 files) 83.20 MB / 974.07 MB                                   \n",
            "Git LFS: (0 of 1 files) 86.23 MB / 974.07 MB                                   \n",
            "Git LFS: (0 of 1 files) 89.27 MB / 974.07 MB                                   \n",
            "Git LFS: (0 of 1 files) 93.88 MB / 974.07 MB                                   \n",
            "Git LFS: (0 of 1 files) 98.37 MB / 974.07 MB                                   \n",
            "Git LFS: (0 of 1 files) 101.41 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 104.44 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 107.48 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 110.52 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 113.55 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 116.59 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 119.62 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 122.66 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 125.69 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 128.73 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 131.76 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 134.80 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 137.83 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 142.52 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 146.94 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 149.97 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 153.01 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 155.03 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 157.09 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 160.12 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 163.16 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 165.34 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 167.87 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 170.07 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 173.85 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 177.68 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 180.72 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 183.75 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 186.79 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 189.82 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 192.86 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 195.89 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 198.93 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 201.96 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 205.00 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 208.03 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 211.07 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 214.10 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 217.98 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 222.15 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 226.25 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 229.28 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 232.32 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 235.35 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 238.39 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 241.42 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 244.46 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 247.49 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 250.53 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 253.56 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 256.60 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 259.63 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 262.67 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 266.82 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 270.87 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 272.97 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 275.18 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 277.51 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 279.83 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 282.21 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 284.49 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 286.66 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 289.17 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 292.68 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 297.35 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 300.38 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 303.42 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 306.45 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 309.49 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 312.52 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 315.56 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 318.59 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 321.63 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 324.66 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 327.70 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 330.73 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 333.77 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 336.80 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 341.41 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 345.91 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 348.65 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 350.97 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 353.28 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 355.54 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 358.00 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 360.32 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 362.53 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 364.68 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 367.99 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 372.21 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 375.25 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 378.28 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 381.32 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 384.12 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 387.15 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 390.19 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 393.22 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 395.32 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 397.37 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 399.40 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 402.95 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 407.73 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 409.98 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 412.18 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 414.56 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 416.83 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 419.11 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 421.36 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 423.64 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 426.68 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 428.98 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 434.26 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 437.29 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 439.45 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 441.64 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 444.68 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 446.84 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 449.88 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 452.91 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 455.95 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 458.98 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 462.02 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 465.05 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 469.00 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 473.27 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 476.31 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 479.34 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 482.38 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 485.41 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 487.75 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 490.79 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 492.99 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 492.99 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 492.99 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 492.99 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 492.99 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 492.99 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 492.99 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 492.99 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 494.49 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 496.34 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 498.65 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 502.56 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 506.98 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 509.11 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 512.15 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 515.18 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 518.22 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 520.29 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 523.32 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 526.36 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 529.39 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 532.43 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 535.46 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 537.66 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 542.26 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 544.46 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 546.67 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 548.75 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 551.05 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 553.12 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 555.35 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 558.39 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 560.65 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 564.10 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 568.17 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 571.21 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 574.24 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 577.28 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 580.31 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 583.35 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 586.38 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 589.42 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 592.45 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 595.49 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 598.52 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 601.56 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 604.59 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 607.63 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 612.25 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 616.73 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 619.77 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 622.80 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 625.84 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 627.87 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 630.90 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 633.94 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 636.80 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 639.83 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 642.87 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 645.90 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 648.94 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 651.97 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 656.57 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 661.08 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 664.11 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 667.15 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 670.18 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 673.22 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 676.25 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 679.29 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 682.32 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 684.48 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 686.59 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 688.64 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 691.68 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 696.30 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 700.78 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 702.92 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 705.12 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 707.19 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 710.23 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 713.26 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 715.35 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 717.48 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 720.52 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 723.55 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 726.59 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 731.19 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 735.69 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 738.80 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 741.84 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 744.87 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 747.91 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 750.94 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 753.98 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 757.02 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 760.05 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 763.09 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 766.12 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 769.16 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 771.32 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 775.88 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 779.53 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 782.57 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 784.62 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 787.66 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 790.69 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 793.73 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 796.76 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 799.80 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 801.84 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 803.90 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 806.94 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 810.46 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 814.87 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 819.08 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 822.11 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 825.15 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 828.18 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 831.22 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 834.25 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 837.29 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 840.32 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 843.36 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 845.76 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 848.79 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 851.83 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 854.86 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 859.64 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 863.02 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 866.06 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 869.09 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 871.32 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 873.41 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 876.45 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 878.54 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 880.65 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 883.68 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 886.72 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 889.77 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 894.38 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 898.86 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 901.89 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 904.93 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 907.96 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 911.00 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 913.03 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 916.07 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 919.10 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 922.14 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 925.18 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 928.21 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 931.25 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 934.28 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 939.03 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 943.39 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 945.04 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 945.04 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 948.13 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 951.02 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 954.06 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 957.09 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 960.13 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 962.19 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 965.22 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 968.26 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 971.57 MB / 974.07 MB                                  \n",
            "Git LFS: (0 of 1 files) 974.07 MB / 974.07 MB                                  \n",
            "Git LFS: (1 of 1 files) 974.07 MB / 974.07 MB                                  \n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFJCX0jx8Yon"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}